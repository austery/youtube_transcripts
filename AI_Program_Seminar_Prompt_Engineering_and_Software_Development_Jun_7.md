---
title: "AI Program Seminar (Jun 7) - 逐字稿整理报告"
layout: "post.njk"  
date: "2025-07-10"
tags:
  - "视频笔记"
data:
  author: "Lei"
  podcast_program: ""
  speaker: "独行"
  guest: "Vincent, Jay, Thomas" 
  source: ""
---



# AI Program Seminar (Jun 7) - 逐字稿整理报告

## 引言与常用AI工具分享

**独行:**
欢迎来到AI知识管理program，我是独行。我们今天在场的有Vincent、Jay，还有Thomas。

**独行:**
好的，我们今天要讨论两个主题。第一个主题是大家分享平常怎么写prompt
(提示词：与AI交互的指令)，有没有写出更好prompt的经验跟小技巧可以分享。第二个主题是在大家利用AI去开发app的时候，有没有什么经验跟技巧可以分享。好，我们先来进行第一个主题：prompt
engineering (提示词工程)。

**独行:**
我很好奇，先调查一下，大家现在常用的AI产品有哪些？就是你平常工作或生活中经常在用的。

**Jay:** 我用ChatGPT的GPT-4o，我感觉这个GPT-4o太好使了，天天用。

**Vincent:**
我现在基本上也只用，应该说大部分时间都是用ChatGPT，90%几都是。只有在其他情况下才会移到其他平台去。至于模型，我好像是GPT-4o跟另一个模型，就是两个轮流用。

**Jay:** 是4.1，他反正出了个4.1。

**Vincent:**
一个比较快，一个会推理，就是这两个轮流用，看情况。然后偶尔再根据topic
(主题) 去用Deep Research (深度研究：ChatGPT中的一种高级分析功能)。

**Jay:**
天啊，GPT-4o太好用了，它这个功能是怎么实现的？我的天，感觉比以前聪明了十倍。

**独行:** 对，就是有一种从小学生变成大学生的感觉。

**Jay:** 不止，他真有一种给人agent (智能体：能自主执行任务的AI程序)
的感觉。我不光问他问题，我天天问他。比如说我怎么买这个东西，哪个登山装备好，就问这些问题，他答得可全了，而且他引经据典，可信度非常高。

**独行:** Thomas你自己会用哪些？

**Thomas:**
最近真的比较忙，我没有去尝试新的。不过我先前用的是ChatGPT，听了这次分享以后，我应该就会再去看GPT-4o。我之前是ChatGPT跟Fellow.app交替使用，使用的比例其实应该各占一半。因为我觉得，虽然还没比较过GPT-4o，但是那时候Fellow.app让我觉得非常的好用。他也能很好地帮你收集资源。坦白说，我先前在做一些程式课程教学的时候，都是用Fellow.app来备课的。

**独行:** 哦，Fellow怎么拼？

**Thomas:** F-E-L-L-O-W。

**独行:** 好的，我等一下去看一下。

**Thomas:** 但听说GPT-4o就更好使，也不一定。

**独行:**
说不定可以试试看。我自己是ChatGPT的重度使用者。但因为我们公司用的是微软全家桶，所以我最近才发现，其实我可以用它的Copilot
Studio。我发现它的Copilot还不错用，因为它可以直接支援微软内部的工具。我可以直接叫它根据我的需求给我一个PPT档案，内容都会帮我填好。

**独行:** Cursor (一个专为AI编程设计的代码编辑器)
我也很频繁地使用，会去变换不同的model
(模型)。我也感受到，就算不用GPT-4o，它的GPT-4也不错用。可是我GPT-4只有在coding的时候会用来问问题，或者写一点code
(代码)。在Cursor里，我通常都是用Sonnet
4或者3.5。我真的是重度使用者，我觉得我人生大概现在每天至少有20%到30%的时间都花在这些AI上面。它根本就成为我的second
brain (第二大脑)，甚至是第二伴侣了。

**Thomas:**
Fellow.app现在可以自己设定，它有agent的概念。你可以针对，比方说你现在要投资理财，它就帮你调试一些投资理财的agent；或者你要做什么深度研究，它就会帮你抓取资料。比方说我用中文来问，它可能会同时搜寻英文和日文的内容，最后再用中文来回复你，当然会附上一些来源链接。它也可以生成简报。前阵子，大概前一两个月，它又推出了一个即时生成网页的功能，按一下，它立刻就做成网页，你想分享就分享，这也蛮有趣的。

**独行:** 还蛮酷的。

**Jay:** tomorrow (可能是口误，指Thomas)
这简直太好了，我现在就想搜一下。

**独行:** 看得到它的code吗？它是作为一个网页存在的？

**Thomas:**
他是直接生成文件给你。但是在生成过程中，你可以看到它的步骤，因为它就是用，如果前段时间有听过的话，就是用Tailwind
CSS之类的技术帮你做出一个网页。

**独行:** 哦，Fellow.app。

**Jay:** AI不寸。

**Thomas:** 拼FEL...OFE...ER。

**独行:** 可以来试试看。

**Vincent:** 这个是美国公司吗？

**Thomas:** 日本，日本。

**Vincent:** 忘了。

**Jay:** 日本，很神奇，我之前甚至不知道还有这个东西。

**独行:**
它其实还有一个很不错的地方，是他有很多小工具可以用，比如什么utilization
(利用)。

**Jay:** 还有PDF阅读。

**独行:** 它有点像一个叫Airtable的产品，就是有很多很多template
(模板)，很方便。

**Vincent:** 真的好像。它有很多小工具，就是它做的agent吗？

**Thomas:**
就是你在搜寻，新的讨论出来的时候，他左下角就有一些搜寻源，还有一个Fellow
Agent，你就可以选择各种不同的agent。什么学习与研究、新创品牌、成立投资理财、管理策略等等。

**Vincent:** 这个是要收费的吗？

**Thomas:**
免费版可以用。如果只是普通搜寻，没有要用agent的话，就可以用免费版。如果要用agent，它好像有一个点数机制。如果你没有订阅，点数是有限的。我记得他给的点数可能做一两次深度搜寻就差不多了。因为agent可能拆成十个步骤，你可以选择只做其中几个，我记得是用点数来执行。如果点数扣完了，就可能得等明天了。

**独行:**
我现在有看到这个，分享一下，就是你可以去制定这个步骤。对，它自己已经有一些预设步骤在这里，我觉得还蛮好的。

**Thomas:**
对，你也可以自己添加。等于说它帮你预设好了，你也可以直接搜寻看看，然后你就会看见他推理的步骤，就是他先思考了什么，找了什么，然后再继续。他大概也会让你有一个概念，就是进一步你可以问哪些问题，他都会提供一些发展的方向给你。

**Jay:** 这个也很好。

**独行:** 它现在列了九个问题。

**Jay:** 这跟那个Copilot Studio有点像。

**独行:** Copilot Studio它就是一个low-code (低代码)
工具，可以让你自己设定步骤。比如这一步要AI来做，那一步要调用微软的什么工具之类的。而且它有很多厂商提供不同的插件，Adobe也有。我觉得现在的趋势可能就是要让你自己制定步骤。

**Jay:**
可问题是我们怎么知道哪个步骤好啊？我觉得OpenAI它有一个好处，就是你看到它的那根疯狂的思考线，你什么问题都给它，它自己能想出来。但是这种自己制定的，你就不知道该怎么制定了，我突然有点慌。

## 第一部分：Prompt Engineering 的艺术与实践

### “Deep Research” vs. GPT-4o：场景与选择

**独行:**
我觉得要看你的使用情境。如果是写报告，譬如说我刚刚那个情境是“竞争者产品分析”，它当时列了一些分析方法，你那时候可以先提前想一下要用什么分析方法。我记得用Deep
Research的时候，它会问你问题。如果你用Deep
Research来查，它会问你一些问题，那些东西其实就是步骤了。譬如我之前做好几次竞争者分析，它就问我：“请问你是要专注在化妆品的领域，还是你要扩大到食品？你的竞争者是只有软件的竞争者，还是类似服务的竞争者都要？”它会问得很细，然后你把那些参数给它之后，Deep
Research才会开始。

**Vincent:** 说到这个Deep
Research，我发现如果问题要一次问得全会比较好。因为原本Deep
Research不是要200美金才能用吗？后来它变成20美元也能用。那时候我就想说，问一个问题的成本很高，所以我都会先单独开一个对话，先去准备这个问题。

**Vincent:**
比如说你刚刚讲的那个分析，我先开一个对话，跟它说我现在要做Deep
Research，我想问一个这样那样的问题，请你帮我准备这个prompt。它就先准备一版，然后我就觉得好像还缺什么。比如说竞争分析还不够，我可能要增加哪个地区的，然后我就说我要再增加这个部分，请你再帮我生成这个prompt。就这样一直调，调到一版我觉得这个问题够全了之后，我再把这个prompt复制起来，开另外一个对话，再把它贴进去，叫它跑一次Deep
Research。这样子的结果，会跟你直接丢一个问题进去，两边出来的成果差异蛮大的。所以我刚刚想说，像刚刚那个可以自己制定步骤的功能，你可以一次就叫它去把结果跑出来，也可以分两个阶段，先用一个对话去把问题问全，然后再把这个问题丢到下一个去，让它的分析范围能够符合你的预期。这样它自己就是两个阶段了。

**独行:**
我觉得很像做菜，有些东西你要先预处理一下。你先给它一点预处理的东西，这样它就比较有资源去深度处理你的需求。

**Jay:** 我想问问你们在什么情况下会使用Deep
Research？我最近感觉我都没有碰这个功能了，自从GPT-4o出来以后，我对他满意度有点过高，基本上什么问题都能在GPT-4o里解决。

**独行:** 是真的需要一个完整的分析研究时。我的工作会需要一些solution
(解决方案)，我可能要先请它分析说，目前在你找得到的资料里，最好的best
practice (最佳实践)
是什么。这个东西我真的会叫它分析，然后它分析来的结果，我就会再用其他的模型把它简化成一个document
(文件)。但我觉得Deep
Research最大的作用是，它会帮你爬非常多的资料，这是最重要的功能。但是它写出来的东西非常生硬，就像一个非常严谨的学者模型。

**Jay:**
Okay，那和GPT-4o的本质区别在哪？GPT-4o也是从网上给你爬很多资料。

**独行:** 我觉得资料的量还是不一样的。而且GPT-4o的步骤会比较少，Deep
Research的步骤其实非常多，可以到二十几个步骤。它的reasoning (推理过程)
可以有二十几个步骤。我那时候盯着它看，发现这步骤也太多了。Perplexity
AI也有类似Deep
Research的功能，可是Perplexity的步骤其实没有那么多，它比较接近GPT-4o。虽然它也叫Deep
Research，但我觉得它们做的事情是有差异的。

**Jay:** 你们有没有什么example (例子)，就是你们最近问的一个Deep
Research的问题？我倒想看看。

**独行:**
我就是请它做竞争者分析。因为竞争者分析，我们以前在学行销的时候，要看非常多的资料，那个很耗时。

**Jay:** Okay，我能理解，竞争力分析确实，我之前也做过。

**独行:** 所有的行销分析，我觉得都可以用Deep Research。

**Jay:** 这个其实还是挺有优势的。

**独行:** 确实。还有就是strategy
(策略)，所有的商业策略相关的。但是我最近很多时候是在找软件的解决方案，因为我们也在开发app，然后软件的解决方案我还是用GPT-4o比较多。

## 第二部分：AI与软件开发的共生关系

### Cursor的使用心得与框架陷阱

**Jay:**
我最近倒是把Cursor给删了。对，因为我上个月吃了很多亏，用Cursor写了一堆我自己看不懂的代码，这个月我就痛定思痛了。

**独行:**
痛定思痛，我现在变成重度使用者了。我可以等一下跟你讲，我跟Amy遇到什么一样的问题，那我后来怎么解决的。

**Jay:**
我感觉Amy说的那个问题我也遇到了，但是我没解决，然后我现在就老老实实去翻书了。

**Vincent:** 是不是因为上一次我们讨论的关系？

**Jay:** 对啊对啊。我非常老实地找了本书叫做《Software
Engineering》(软件工程)。然后我就开始看什么是架构，一步一步去了解。我觉得我没办法省略这一步，省略可能只会让我这步变得更慢。

**独行:**
对，因为Cursor的确在架构问题上比较不擅长，我只能这么说。它毕竟是一个coding的工具，不是一个帮你发明架构的工具。

**Vincent:**
那你看了这本书之后有什么感觉？我是说，因为你跟我们不一样，我们至少是先学这个再有AI。像你这样子反过来的话，我好奇你是什么感觉？

**Jay:**
我实话实说，我现在这本书只是刚找到，我搜了很多不同的书。然后由于这个原因，我不光得学这个，我还有一门机器人的课程，好像这个月就全在学机器人了。机器人又有很多新型的编程语言和操作系统，但是这些过程我现在都不敢用Cursor，全部都是自己翻书，然后我就觉得踏实了很多。但是有一种感觉就是信息量很大，我不知道我要学到什么时候才能逐步开始使用Cursor，这个基础我要补很多。

**独行:**
我可以推荐你一个YouTube频道吗？我最近补很多就是从那个频道补的，我觉得他讲的还蛮有用的。

**Jay:** 他讲什么？

**独行:**
我现在贴那个链接给你，它叫“原子能”。他就是……我不知道他住哪里，但是听口音就是在中国。他反正就是一个很资深的developer
(开发者)，我发现他讲的东西真的都是很有经验的人才讲得出来的。

**Jay:** 我可能看过他的视频，因为我学Linux的时候可能看过一些。

**独行:** 其实你可以去看一下，他有一个系列叫“让编程再度伟大”。

**Jay:** 他的B站应该也有。

**独行:** 对。我觉得他讲得很好。他讲基本上就是三步骤：Make it work, make
it right, and make it fast
(先让它能跑，再让它正确，最后让它变快)。他说大部分人只会到“make it
right”，因为“make it
fast”这件事，其实不太值得你花那么多时间。我后来真的去查这三个开发的philosophy
(哲学)，它是真的有来源的。然后有一个新的版本叫“Make it work, and then
make it better”。

**Jay:** 他的系统是新版的。

**独行:**
是这样子。他就是有一些取舍，譬如说你得要先搞懂业务逻辑。你的业务逻辑都还没搞懂，就开始去优化一些有的没的，其实还蛮多东西可以优化的，什么软件结构、速度、架构，还有连注释都可以优化。我几年前学过一个概念叫“premature
optimization”
(过早优化)，就是软件工程最大的陷阱。就是你根本功能都还没做好，然后就在那边优化一些有的没的。我也是遇到这个状况，因为我其实很喜欢技术，很喜欢去读这些东西，很有兴趣，然后我就会花很多功夫在钻研。

**Jay:**
没错，这其实你不停学，会发现优化东西越来越多。随着你的知识扩展，你会发现越来越多东西可以优化，但是这没有一个头。

**独行:**
就是没有一个终点。我大概两三年前就是因为这样，完全放弃前端开发。因为前端开发那一堆东西太可怕了。

**独行:**
首先，你到底是要先学React、Angular还是Vue？这是两三年前就会一直有的问题。然后你学了某一个之后，它会一直很频繁地更新。更新的时候，你总会有些东西坏掉，然后坏掉之后你又看不懂，这是很可怕的事情。你可能读了他的文件，也看不懂他到底在里面做了什么导致这个错误，这个非常痛苦。我之前就是因为这个状况完全放弃前端。最近开始又重写前端的时候，我发现用Cursor慢慢写，有套件跟没用套件的差别很大。Cursor在有套件的时候，他就会写很多错误出来，在没有套件的时候做得比较好。

**独行:** 我发现他只要是原生的code
(代码)，他都可以写得很好。可是一牵扯到要相互依赖的套件，或者这边import那边import，他就会变得一团糟。就是你怎么样叫他测试，他都测试不出结果。

**Jay:** Okay，有意思了。

**独行:**
对，这个是我最近发现的问题。然后“原子能”他有在讲，到底为什么我们要用这些框架(framework)呢？如果他没有帮你省时间的话。其实现在很多功能是程式语言本身就内建的，那你干嘛还要用那些框架？我自己因为现在是一人开发，就发现一人开发最好是不要去用React这种前端框架，因为它会让你的开发变得很复杂，加上我也其实看不懂。

**Jay:** Okay，我觉得对，如果这个东西看不懂，它的危险系数就非常高。

**独行:**
对，而且他不是说你叫AI帮你解释就可以解决的。他有太多自己发明的东西，他并不是说很多东西就是浏览器它自己原生的一些程式，因为浏览器原生的程式就是JavaScript。但他有时候有些很多东西是自己发明的，像什么virtual
DOM (虚拟DOM)，那个我到现在都还没搞懂，我决定不去搞懂他了。

**Jay:** 跳过了。

**独行:** 我觉得跳过了。

**独行:**
所以我下了一个很好的prompt，我真的有把这个prompt留起来，我觉得我下得非常好。就是一句话，我记得我好像是叫他说：“请你去开发XX东西，然后用JavaScript，尽量不要安装套件。”然后Cursor写出来的code就是又干净又漂亮，又没有错误。接下来我每完成的一个小功能，就把它commit
(提交)存起来。再请他加一点东西。我像我昨天已经完成到一个段落了，我写一个处理PDF的程式，就是PDF转图片跟PDF转文字。那个东西我在前端把它做完，我发现其实就只是用JavaScript这些东西都做完了，我完全不用去用React。原来现在Web上简单的东西，已经用JavaScript就可以解决了，我非常的惊讶，因为这是两三年前我没有想象到的。

**Vincent:**
像你刚刚讲的这个，因为像这些套件或者是说这些封装，本质上它大部分是为了解决这种易用性、兼容性的问题。他解决这个问题的目的，其实是为了给下游的人去使用。所以人要看、要用人看得懂的语言、人熟悉的方式。所以他把底层的这些步骤，用人比较好懂的逻辑去把它封装起来，人会比较容易使用。但是这个是因为这是给人看的。今天反过来说，你实际上是要透过AI来写的话，其实他没有这个问题，没有所谓的理解人的语言比较容易这件事情。

**独行:** 对。

**Vincent:** 所以听起来反而你dependency (依赖)
越少，你用的语言越底层，你出错率反而越低。你反正不要去用那些别人更早就发展出来的平台、框架、技术封装，这都不要用。你就用最底层的东西去让AI去跑就好了。

### 回归基础：计算机科学原理的重要性

**独行:** 我以前在读CS (Computer
Science，计算机科学)快毕业的时候听了一个演讲。那个教授讲了一句话，到现在我还记得。他说，以前机器学习Python有一个很有名的套件叫scikit-learn，用那个套件就可以很轻易地做machine
learning
(机器学习)，所有的演算法都写在里面了，你根本不用自己写。可是那个教授反而有点anti
(反对)那个潮流，他讲说：“其实你可以自己打造自己的框架，你不需要去受他的限制。”

**独行:**
我到了今年才了解那个道理，非常多年之后我才了解为什么。套在AI这个场景下，很多时候你的确最好是了解他到底在做什么。你不用会写，但你要了解他在干嘛。所以我现在就是把那个code复制到ChatGPT，问了很多问题。比如说这个控制信息的顺序，他怎么样相互依赖，这里面用了什么样的技术，他做了什么处理，为什么你要这样做之类的，顺便问一问。我觉得现在coding的方式真的改变了。我现在就是用一个重新学习的方式，因为现在的场景变成我要跟Cursor一起协作，所以我也在学习怎么样重新当一个software
developer (软件开发者)。

**Thomas:**
你这样也提醒了我。其实一开始用框架，当然是为了解决一些问题，比方说元件的复用性，一些复杂的东西别人开发好你就不用再做了。但是如果现在AI写程式写这么快，其实你根本就不用担心这个问题了。而且你甚至可以请他写单元测试。这一整个时间其实是很快的。用这种底层东西来做，后来衍生了一大堆什么client-side
rendering (客户端渲染)，根本就不用管那些问题，什么SEO
(搜索引擎优化)问题也不用自己处理了。

**独行:** 因为最厉害的东西是优化，你都可以自己做。

**Thomas:** 对，都回到最原本的做法，其实就没那么复杂了。

**独行:**
对，我觉得这个有点像3D建模，就是你现在可以自己发明玩具给自己玩了。

**Thomas:**
对。所以现在搞不好最底层的技术最重要。框架的出现让大家忽略了这个问题。我上个月在教最底层的HTML部分时，就跟他们说，我自己认为底层技术会越来越重要。

**Thomas:**
因为以后像我们在用ChatGPT或者是用Fellow.app搜寻，你不能否认说很大部分的人是不会直接去读网页的，他依赖的是AI先读。那SEO就更重要，因为你必须让AI知道我们这边要讲什么。在这种情况下，SEO就非常重要。所以这就是HTML反而越来越重要的原因，我自己是这样判断。

**独行:** 其实我还蛮enjoy (享受)
学这些东西的。因为以前我还在念研究所的时候，我做的实验室是计算机网络
(Computer
Networking)，超痛苦。因为我们要开发相关的程式，你在那个环境设定，就是Operations
(运维)
部分会把你搞死。因为那些东西是直接针对作业系统的部分，你根本就是花非常多时间在解决那边的问题，然后你根本没有时间写主程式。

**独行:**
现在我会变Cursor的重度使用者，是因为我可以跟他讲说我环境要怎么样设定，我就丢着去泡茶，回来他就设定好了。可是你还是要很确定说，这个东西你确定要有吗？用了之后它有没有副作用？我一开始都没有给它其他的指令，它就很可怕，它会用NPM
(Node.js的包管理器)
安装一些很奇怪的东西，安装一大堆。Cursor解决问题的概念是，这边有错误，我就赶快去安装别的东西去补这个错误。

**独行:**
然后他就会安装越来越多的东西，思路就变成“挖东墙补西墙”。有点像是医生要治你的毛病，结果你吃的药从一颗变成十几颗，最后还是生病的感觉。所以我后来去看完“原子能”的影片，做了很多调查研究，我发现应该是从流程一开始就错了。所以我就是直接开一个新的GitHub
project，然后重启。用AI重写已经很快了，重写了两天而已。

**Vincent:** 你这个问题就好像，有时候你遇到一个全新的领域，按照那个SOP
(标准作业程序)
安装的时候，发现有个错误讯息一直过不去。你查了，好像是缺乏这个，就装一下，还是不行，又缺了那个。等你装了一大堆之后，发现还是不行，最后才发现原来是权限问题，整个傻眼。你解决的都不是最重要的问题，那些都是杂讯。

**独行:** 所以我现在觉得，反而懂Computer Science或Software
Engineering，去了解计算机，反而是比以前更有价值。真的要会用AI，不是说跑去念AI或Data
Science，反而是真的要先搞懂电脑在干嘛。

**Jay:** 你们说的“搞懂电脑在干嘛”，是指那种硬件层面、驱动、Operation
System (操作系统)和C这种底层语言吗？

**独行:**
看你的场景。譬如说如果你是在前端，你真的要稍微搞懂浏览器在干嘛，搞懂一点点Computer
Networking的概念。

**Jay:** 可以理解，这种本质。以前最不屑于学的就是这种东西。

**独行:** 现在发现很重要。所以我现在跟我的老师正式说一声，对不起。

**Jay:**
我以前有这种计算机编程课，刚开始就给你讲这些大道理和故事，然后考试完全不考，直接就是各种code。所以大家都不屑于学这玩意儿。

**独行:** 我是觉得，像Computer
Science有时候会教一些真的很底层的东西，比如什么指令集，那个真的不一定有用。但如果说你对你开发的东西有一点了解，比如说对浏览器、server
(服务器)或资料库有一些了解，我觉得是非常有用的。

**Vincent:** 你讲的是“白算盘”那本吗？(指经典的计算机体系结构教材)

**独行:** 对，那一本我放弃了。

**Vincent:**
我老师教到哪我就一页一页精读那本书，因为那时候学分很重要。但是你后来会了解到，大家那个就是为了考试用的。可是如果你读熟了那本书的基础部分，你会发现大到AI这么抽象的事情，小到真的每一个运算器，其实你是可以把它连起来的。它最后其实都是电流在那些逻辑闸里面穿梭的结果而已。但是在不同的层次上，你对它的理解是不同的。比如说在电流的层面上是这样，在CPU的层面上是这样，在memory
(内存) 层面上又是这样，在data (数据)
的层面上又是另外一个。你一层一层叠上去，它可能是手机、server，它会有不同的应用。可是它本质上就是零跟一的运算。所以老师说的没有错，就是零跟一而已。

### Thomas分享：高级Prompt技巧——角色工厂与概念对齐

**Thomas:**
我想我可以稍微分享一下之前说的一些prompt。我不确定大家能不能用，但我分享一下。我现在要说的东西，是我们这边师范大学有一个叫“业师”(业界专家担任的教师)助理教授，叫做尹相志。我上了一些他的AI课程，我觉得他讲的东西很实用，也帮他推广一下，他的课太实用太便宜了。他自己就做了很多ChatGPT的插件，像这种提示范本产生器。如果你要做简报，它有办法让你去ChatGPT产图，然后帮你产生简报拼在一起。不过现在能产生简报的东西太多了，但是他这个“伪代码”是真的蛮有意思的。

**Thomas:** 就像这样子，他用了pseudo-code
(伪代码：一种非正式、类似自然语言的算法描述语言)
的概念来写prompt。像是这个“生成虚拟的宝可梦角色设计”，它用\`let animals
=
山海经的一种特殊神兽\`，然后这边指定好它每一个变数的含义，再来用回圈的方式来写，你看\`for
a in
animals\`，然后写“请基于A在三横线分隔的内容...”，用写程式的方式来做。我觉得这样可以做到很多我们没想过的事情。

**Thomas:**
他讲的一个概念是，为什么我们跟AI讨论事情以前很常会有幻觉？他说这个叫“概念对齐”。我们必须先把我们想要问的东西，AI的理解跟我们的理解是不是一致的，先请它做概念对齐。比方说我们现在想要了解一个……我们说“资产配置”好了。我们说“概念
=
资产配置”，然后它就开始去想，什么叫做资产配置，它的定义是什么，让AI去想我们现在到底想知道什么。

**Thomas:**
然后他说，接下来我们讨论这个情况需要一个团队，所以他做了一个叫“角色工厂”的GPT。比如说：“请依据上列讨论的资产配置概念，产生专家团队。”然后它就会设定十个角色，像是资深顾问、量化策略师、退休理财规划师等等。

**Vincent:** 他怎么连名字都有啊？

**Thomas:**
就是这样。然后我们就随便抓一个角色，比如说资深顾问。接下来我们在做一些决策的时候，实际上是需要基于角色扮演技术，透过自我批评提升任务完成度。就是让AI不断地去反思。我们就用了这个GPT，然后说：“请担任主席，对年收十万美元的……提供资产配置建议。”

**Jay:** 真的可以这样搞。

**Thomas:**
对，然后你就可以看他的讨论过程，你会增加给它发表意见的，因为它会给予可行的建议。

**独行:** 他感觉做得不太好，有趣的话好像广播剧。

### 实战对比：专家团队模拟 vs. 直接提问

**Jay:**
天哪，Thomas你能不能再开一个GPT-4o，然后你把那个问题丢给GPT-4o让他直接回答一下，咱对比一下。

**Thomas:** 没问题。

**Jay:**
我说你那个“十万美金的资产配置”的问题，能不能让GPT-4o也回答一下？可以对比一下。

**独行:** 那个宝可梦好可怕，但是他像恐怖小说。

**Thomas:**
这边主要是展示他可以用伪代码的方式写出回圈，所以可以一次产生很多。

**独行:**
因为你是用仿真图片，难怪会这么恐怖。如果是动画风格应该就比较可爱。

**Jay:** 我建议直接让GPT-4o回答，我们可以把它的思考过程点开看。

**Jay:** “与会专家”是什么鬼？他是不是把你的记忆全都给……

**独行:** 我觉得是因为他有那个……

**Thomas:**
对，他看到我前面设定了“担任主席”，然后又要“与会专家”，所以他推导出他要找人一起来。好酷。

**Jay:** 他要找人。

**Vincent:** 他又找了一些虚拟的专家进来吗？

**Thomas:**
对。所以曾经有一个技巧，就是说如果我们做一个东西要深度理解，我们一样把专家都抓出来，最后再设一个人叫做“记者”，然后叫记者写成报导。

**独行:** 我觉得学东西用这个方式还蛮聪明的。

**Jay:** 仔细读一下这个答案，我们怎么才能判断它是好的还是坏的？

**Thomas:**
当然要看。你可以先试着用你的专业，用你掌握的、有办法了解他回答深度的方式来检视。

**独行:**
我会开网络搜寻，我会按那个加号开网络搜寻，他至少会先去找一些文章。但是我自已会尽量限制他只找英文的。

**Jay:**
你可以直接修改prompt，把前面那些“担任主席”、“资产配置顾问”都不要，就直接写：“对年收10万的男性提供资产配置建议。”

**独行:** 对，我们好像在做pair programming (结对编程)。

**Jay:**
之前真是被污染了。他现在应该会告诉你……对，有时候他真的就靠谱了。

**独行:** 因为平常GPT-4o通常会搜寻。

**Jay:** 而且会给你贴很多很多的资料。

**独行:** 就跟Deep Research差不多，只是资料量大概是两三倍。

**Jay:** Okay，他还会补充“与会专家”的意见。

**独行:** 写的还蛮详细的，连公式都帮你列出来了。以后都不用找理专了。

**Jay:** 因为现在ChatGPT，我看到他的通告里说，现在他的memory
(记忆)不再局限于单个对话，他扩展了。

**Thomas:** Okay。

**Jay:** 我不觉得这是好事，我倒希望他只局限于单个对话。

**独行:**
他现在会帮你加到全域的记忆。我之前有跑去那个记忆区，把他所有记忆都删掉，不然他每一次的东西都会混乱。

**Vincent:**
我感觉刚刚那种找顾问团的形式，跟现在这个问题很直白的形式，其实两个目的不一样。你刚刚讲找顾问团的那种形式，你的角色比较像是一个director
(总监)，你是叫你下面的人去布置、去团队合作完成一件事情。这个事情需要有不同的角色，你要听的是不同角色之间的意见。所以你需要这样子的一个排兵布阵。可是后面的那种直接问的方式，比较像是一般人他真的有这个问题的时候会去问的。所以他两种感觉是不同的，我觉得是不同的目的。

**Thomas:**
应该说，我用的话都是这样。在这些GPT工具之前，我本来就买了一个叫Axton的课程，它里面也有类似的做法。我之前也试过，比方说我今天要编写一个程式语言的课程讲义，我的TA
(目标受众)
是转职的人，那我就会有一个资深工程师、一个转职成功的工程师，还有一些顾问，这样一个团体来跟我一起写讲义。他们当中就会给出一些feedback
(反馈)。比如说我要教一个样式library
(库)，我就会请他们讨论要教Bootstrap还是Tailwind。他们就会分析说，对于转职生来说哪一个比较简单，可是长期来讲哪一个比较好。资深工程师有不一样的看法，那转职成功的就有不一样的看法。

**Vincent:**
所以你刚刚那个做法就有点像是，你是这个课程的director，你要设计这个课程，所以你需要多面向的建议。但如果你现在只是一般人，你只是想要寻求一个十万美金要怎么投资的建议，那你就直接问就好了，不需要找专家团队来模拟。

**独行:** 这个可以帮助做决定。

**Thomas:**
应该说，如果你想要看看不同的角度。比方说同样是在做规划，如果你有特别提到说，我不只是想要做股票，也告诉我保险我要怎么cover
(覆盖)。就是我的资产配置，要比方说10%是做保险来保障我的整体，百分之几要做保守型资产，百分之多少要做积极型的。我们一看，如果直接问的话，他其实比较没有提到这一块。但是如果你的专家团队里面有处理税务问题的人，他可能就会建议保险配一点，因为有税务问题要处理。保守型资产，比方说债券也可以配一点。然后有自信以后，你就可以放心地去买个股还是买ETF。所以专家团队是给他一个这样的角色，他就有他的专长跟他的任务。

**Jay:**
他这个专家的背后逻辑是有多个GPT在给你跑，还是单个GPT一次性根据你的prompt输出？

**独行:** 一次性的，他应该都是单线程的。

**Thomas:** 他做这个GPTs (用户自定义的ChatGPT版本)
只是让你根据你的命题产生出不一样的角色定义。角色定义出来之后，GPT它本身就去跑，去跑说在它的训练资料里面，这样的人会关注到哪些点。

**独行:**
我觉得角色工厂有一个好处是，他一次就先帮你把所有角度都想到了，至少大部分的角度。你在做一个决定的时候，就有很多角度可以参考。

**Thomas:**
对，它就是一个方便的工具。像我说的，在这个工具之前，我本来就做这样的事情。另外一个就是刚才说的Axton，他也有YouTube，我有时候会看他的。他只是现在这个老师把工具都提供了，连这一部分都可以比较懒惰。他这边还有一些常见的prompt，特别是他伪代码这一块，我觉得蛮好玩的。

**独行:** 可不可以分享一下他的资源？他有链接吗？

**Thomas:** 他的资源，我不太确定叫什么，应该叫“a prompt for
all”。在Google的Play商店应该就找到了。他说五月会放出来，应该有了。

**独行:** 我有找到他的Facebook，他叫尹相志。

**Thomas:**
对。他还用ChatGPT做一些影片，因为先前好像说可以开始生成影片了。

**独行:** 好酷，我觉得他的概念很妙。

**Thomas:**
我那时候编课程讲义的时候，有了Fellow.app的帮助之后，我觉得我可以把ChatGPT的订阅费省下来了。结果一用到这个“prompt
for all”，我就决定我要继续订阅了。

**独行:**
对，我觉得用ChatGPT，你真的就不用再...很多人不是喜欢没有办法下决定，喜欢去求神问卜吗？你都不用再花钱算命了，直接去ChatGPT就帮你算好了。

**Thomas:**
这几天在写的，你看，就直接这样写：“重写这个，然后要用专业、温暖的语气...”

**独行:** 说的很有趣。

**Thomas:** 温暖的版本。好，大概就这样。

### 人机交互：角色扮演与AI的反馈

**独行:** 谢谢Thomas，我觉得还蛮新奇的。

**Vincent:**
我也是第一次听到那个“角色工厂”、“专家团队”，很酷。这让我想到周伯通，他不是很无聊，就练就一身左手跟右手互打的武功吗？现在有了这个GPT，你也可以模拟出多个人，然后让这些人互打，打出一个你想要的结果。

**Thomas:** 对，多一点，然后自己跟自己打。

**Vincent:**
对，就是有时候看一些书，他会说你要做决定，要把优势劣势分析一下。现在有这个的话，你都可以直接叫它帮你模拟出一个悲观的我和一个乐观的我来做优劣分析，然后直接给你结论。

**独行:**
这样投资还蛮重要的。比如说你可能预估最低报酬率，最烂的市场报酬率是多少，然后好景的时候是多少。如果你只预估最好的报酬，那你可能到时候会缺钱。我觉得悲观的看法还蛮重要。角色工厂就可以帮忙，悲观的投资者、乐观的投资者、投机的投资者。

**Vincent:**
对，像你刚刚只问的那个十万块美金的投资建议，他其实没有混合你个人对这件事情悲观或乐观的成分。假如说你把它模拟成两个人，让他们两个去辩论这十万块美金的投资方式，也许作为裁判的你会有不同的观点出现。

**独行:**
我发现我现在在试用这个“概念对齐”，我觉得他很不错。他就是帮你把你要了解一个概念，它相关的背景资讯都列出来了，很不错。

**Thomas:** 我补充一下，那个影像制的课程有讲，然后他在他的这个“prompt
for
all”插件里的提问技巧第一个，叫“角色互换”。我把他的prompt贴上来：“你是人类，我是ChatGPT。你希望我来协助你...请问你会如何用prompt命令我？”他就是一个角色互换，人跟ChatGPT互换过来，然后就生成了一个prompt。

**Vincent:**
角色互换，所以说他是透过这个方式来调整你的意图的描述方式吗？

**Thomas:**
就是，我现在是ChatGPT，然后ChatGPT是人类，所以人类要来命令我，然后他叫这个“人类”想出要怎么用prompt来命令我。所以我以后要命令ChatGPT时，我就可以用这个prompt了。

**独行:** 就是一个逆向工程。

**Thomas:** 对对对。

**独行:** 这个真的是蛮聪明的，我学到一课，谢谢。

**Vincent:** 我怎么觉得这很像教育小孩。

**Jay:** 这个和直接让他帮你修改prompt的区别是什么？

**Thomas:**
应该说是一个想法，都可以试试看。同样的事情，你直接给他一个任务说明，如果你会担心说要怎么问可以更精确，那他可能就可以提供一个修改的建议。我觉得都是不错的，就当参考。

**独行:**
我觉得就是看哪一个方式比较高机率可以达到你要的结果，你就用那个。

**Vincent:**
但这个有点像一面镜子一样反射你的人格。比如说都是一句话，你可以有两种回应。一种是“你叫你做你就做”，另一种方式是“可以请你帮个忙吗？”两种都是请人家做事，可是在语气上有很大差异。你这样的回答会被他记忆起来，然后他回答你的方式就会是这样子。他就会知道你是一个强硬语气的，或者认为你是一个有礼貌的人，他会按照你给他的回答去反过来变成你想要的那个样子。

**Thomas:**
可以观察看看。因为他prompt说“你是人类”，他也不是说“你是我”，我觉得他用“人类”是刻意用的一个通用性的称呼。但如果你说“你是川普”，那结果可能就不一样。当然因为它的记忆效果会不会带来一些这样的结果，是可以观察的。理论上我们对AI不客气都是可以的。

**Vincent:**
但我很好奇，如果你这个prompt下去，用一个比较不礼貌的语气回复他，那他记住了。是不是反过来，以后你就要用不礼貌的语气他才比较听得懂？

**Thomas:**
我觉得特别是刚才提到全局记忆的话，可能这也要担心。因为我有一些朋友他们的确是觉得ChatGPT完全是在做智商咨询了，你知道吧？就是再找那个身份认同，或者是一些不顺遂的事。他的案例是告诉我，他的确受到全局记忆很大的鼓励。如果这么一玩，确实就鼓励不了他了，这样也不太好。

**Vincent:** ChatGPT现在好像变成每个人的同温层了。

**独行:**
对，其实也不是每个人都用到那么深。有的人大概就只是想到去问一下问题，把它当搜寻引擎。

**Vincent:**
但是如果你从之前的技术原理来看，他是有机率的往下推。所以他大部分情况下他不会反对你。无论你怎么说，他都会出现你想要的内容，这机率是比较高的。所以慢慢的，你如果真的找ChatGPT做心理咨询的话，我觉得他都会顺着你的话往下讲，这机率比较高。

**Jay:** 一定会。

**Thomas:**
但我觉得，我对他有风险的朋友给我看，我觉得他会很受感动的原因可能是，因为它是一个很long
term
(长期)的了解。ChatGPT在回答他的时候会引经据典，他会说“因为你以前发生什么事情，你跟我讲过什么，所以你是一个什么样的人”。

**Jay:** 特别容易被他忽悠。

**Thomas:**
就是特别会觉得说：“你很在意我，你是真的用我发生过的事情来跟我谈。”

**独行:** 真的是像远端情侣。

**Jay:** 你没有问过ChatGPT在他眼中的你是什么样的，或者让他画一个你自己？

**独行:** 我现在来问。

**Jay:**
这会得到一些很有意思的东西。我很想知道，你可以让他画一下，比如说你在工作的时候的自己。

**Vincent:**
我没有请他画过，但是我有问过“在你眼中的我”，他们描述的内容大概就是我问过他的问题的总和。

**Vincent:**
比如说我说我几岁，我在创业，我家庭状况怎么样，帮我做财务分析等等。他就把我这一堆内容全部融合起来，做一个总结。就没有超出我问他的问题以外的东西。

**Jay:** 他从来没有说你的任何缺点，没有吧？

**Vincent:** 除非我问他说：“那你觉得我缺点是什么？”

**独行:**
我觉得他给我列出来的缺点还蛮不错的。有一些很细微的他有观察到，因为我跟他互动，我每天都用。

**Jay:** 我怎么觉得我问他的缺点，他现在在夸我？

**独行:**
你要说“缺点都要列出来”。他讲一个是我“容易陷入过度思考”，这个还蛮常发生的。因为我在问一个问题的时候，我常常会重复问。就是A问完，他可能讲了B讲了C之后，我又重复问A，我又觉得不确定。所以我大概同一个问题会在同一个对话里问好几次。

**Jay:** 他对我也说了这个点，他说“不愿意轻易接受模糊的解释”。

**独行:** 他是直接跟我说，对模糊回应不耐烦，我是真的不耐烦，都没错。

### ChatGPT新功能：Code Interpreter

**独行:** 我刚刚在背景跑了一个ChatGPT的新功能，叫Code Interpreter
(代码解释器)。我不知道大家有没有发现。

**Jay:** 我听说了，他是干嘛的？

**独行:** 他就是你可以把你的project (项目)
放到GitHub，然后他可以直接读你整个GitHub的repo
(仓库)。他会帮你做测试，然后他会告诉我哪里的code有问题。他就是给你读整个project。我不知道它的token
(代币：模型处理文本的单位)
数量有没有到更多。譬如说如果你的专案是中型project，他的运作方式会不会不太一样。但因为我这个是小型project，所以他读得非常快。

**Vincent:** 那像在这之前，你是没有办法一次给他整包你的codebase
(代码库)的吗？

**独行:**
之前有几个麻烦的点。我们之所以用Cursor，是因为Cursor可以读你本地的档案，他可以全部档案都帮你读一遍。可是没有Cursor的话，你就要一个个贴。假设你写前端，你至少有HTML、CSS还有JavaScript三个档案，如果你分开贴，我比较偏向于一次就让他读完整个codebase，这样他理解成一个prompt，就不会说是分开的。

**Vincent:**
但是像我们这种，如果你不把整个codebase给他，只是想找片段的问题的话，你就贴那些你觉得可疑的片段给他就好了。

**独行:** 对啊，大概就是这样子。新产品试用分享。

## 第三部分：AI的局限性与学习方法的反思

### AI在专业领域（医疗、历史）的局限

**Vincent:**
那像刚刚那个角色扮演，是不是也蛮适合做那个……比如说我们现在新产品需要找用户来使用，那我们也可以建立一个用户试用团队，就像你刚刚列出专家那样，列出十个不同年龄层、不同职业的试用者，来试用你的产品，然后给出他的试用心得，是不是也行？

**Jay:**
我总是担心这个不靠谱，因为他不是真实的数据，他不是真正的人，他的问题能摸到什么程度？

**独行:**
我也觉得这样会不准，因为真实人的回馈会很不一样。我做过使用者测试和survey
(调查)，我发现很多时候会跟在网络上找资料得出来的结果不太一样。因为ChatGPT他找的都是过去的资料，他不知道这个人当下他面对你这个产品，他会回应是什么。

**Jay:** GPT-4o现在不是主要过去资料，我以为他现在搞得还挺即时的。

**独行:**
但问题是他也是网络上的资料。一个人类物理的回馈，尤其是如果你的产品又跟物理回馈有关，你就没有办法这样做。例如说食物，你总是要吃吧，可是AI没办法帮你吃。

**Vincent:**
我是说一些真实的经验，和一些没有在网络资料库的资料。他都没有办法模拟，但是这些却恰好又是真实世界中很重要的一部分。就比如说你刚刚讲的吃、味道这些。

**独行:**
对。还有一些东西，我用了这一两年来发现最大的困难在于医药的东西。医疗资料网络上不缺乏，但是准确的资料是缺乏的。譬如说我失眠了该吃什么维他命？网络上会给你推荐很多东西，你用GPT-4o他也会推荐很多，可是他没有办法告诉你说哪些是真正医学证实的，证实到什么程度。你就要用特定的资料库。ChatGPT里面有一个app叫Consensus，它有连结学术资料库。但我直接给大家那个连结，你去搜寻这个关键词。它有连资料库，但我觉得他还是有一点缺点，就是说他并不是纯医学资料库。所以可能之后要等等看有没有其他的部门去想办法把医学的资料库都上线给AI，让他变成一个agent帮你查。

**独行:**
因为医疗的资料是这个领域最困难的。反而现在我以前觉得很难的一件事情变容易了，就是法规。现在查法规变得越来越容易，因为法规的资料在网络上全部都有，没有那么封闭。但是医学的问题，我不知道你们有没有用AI问过？我发现医学的问题，AI处理都有一个缺点，就是说就算他引经据典，他不会知道那个实验做得到底准不准或对不对。有时候实验设计本身是有问题的，但AI读的资料可能只限于读论文的abstract
(摘要)，他没有深度去看那个论文，去思考说这个实验到底准不准确，是不是真的可以用在我身上，证据力够不够？这个是我觉得现在有待改善的部分。所以比较专业的领域，我还是建议读专书，不要全信AI。

**Vincent:**
你的意思是说，你是没有办法从AI整理出来的研究报告里面去找到这些研究的问题？

**独行:**
我觉得你要怀疑。不是说不能信，而是你要怀疑一下，还是要去确认一下这个事情的准确度到底有多少。我最近做了一个事情，跟医疗无关。我看到一个影片在批评王阳明，说他非常嗜血，以前在战争的时候让一整个村子都毁灭了。我把那个影片的字幕转成文字，然后叫GPT-4o帮我做fact
check
(事实核查)。事实确认完之后，他发现说哪些东西真的有发生，但是他没有办法证实。这件事情有趣，因为有些历史资料他并没有上网。我有朋友是做历史学家的，并不是所有的历史资料都放在网络上，很多东西只存在于论文资料库里头，但是GPT-4o他们没有办法进去，因为那个可能要付钱或有权限问题。另外一个是有些历史资料还是纸本。

**Vincent:**
对了，刚刚很多就是说，有可能其实是因为它还没上网，虽然它已经是个事实，但是它没有在网络上。

**独行:**
对，但我们现在又那么依赖网络，这个事情就很麻烦。我之前教我妈用ChatGPT，我有跟我妈讲说，如果你要问健康的问题，一定要叫他上网，但是请你尽量还是去问医生。我还是会告诉她一下，我也不太希望她真的...我觉得一个年纪的人，他们有点难判断网络上的消息的真假。

### 人机交互：Prompt Engineering的必要性与未来

**Vincent:**
对，我现在有一种感觉，像我们在学这个prompt怎么下，一个原因是因为要把脑袋里面想的东西变成文字打出来，作为AI的输入。但是这个方式其实还是有一点把你脑袋里面资料简化的过程。像你前几天不是又贴一个用语音转文字的输入吗？我在想说，假如说你给AI的输入已经可以完全透过语音来处理，有一个真的这么好用的语音转文字工具的话，你还需要学这些prompt
engineering吗？你是不是一股脑就跟他讲就好了？反正做总结是他的强项，你根本不用再学一些特殊的技巧来让他更精准。因为你就尽可能的把你想到的东西都跟他讲，没有条理也没关系，反正你就讲得详尽就可以了。

**独行:**
还是有差。因为它有点像是跟人对话一样，你还是要问对问题，他才能给你需要的答案。所以我才会觉得“概念对齐”那个功能真的很不错。至少他先帮你把相关的方向列出来，然后你比较可以问对问题。

**Vincent:**
可是这个过程就有点像是，比如说你是个顾问，你的客户来了，一股脑跟你讲一大堆。你听完之后可能就问他：“所以你现在的状况是什么样的？”针对你关心的几个点，你再问他，比如说你预算多少，你想要做什么样的事情等等。你可以这样再去反问他。然后他听到了你原来要解决这个问题关注的这几个重要因素，我就再用语音回复你。这样来回几次之后，其实我的问题也慢慢在收敛。虽然我一开始原来是一团浆糊，可是我在这个过程中也慢慢地收敛出来了。那相比我还要想得很清楚再下这个prompt，是不是用纯语音来做搞不好速度还快一些？因为你最后简化成你只要用讲的就好了。他会问你，你再讲，问题就慢慢收敛了。

**独行:**
我也是蛮常用那个语音的，不过我是用语音输入，不是像跟他打电话那样。

**Vincent:** 对对对，我是说语音输入，语音转成文字的这种输入方式。

**独行:**
我也会用。他不是会通过反问吗？通常拿他反问之后，他给你的东西就会越来越精准。但我觉得prompt
engineering有没有必要这件事情，就是说，你会有一些时候他没有办法一直反问你。譬如说像你要用Copilot做一个自动化流程，比如说它自动化帮你把最新的AI文章抓下来，然后写一篇评论。你要做这个事情的时候，它必须要整个自动化，在那个时候你真的就要用prompt
engineering了。

**独行:**
如果你要自动化一个流程，那如果说平常我们在问问题的话，当然是可以。可是当你要去自动化你的一些工作的时候，比如说我有一个agent是自动化帮我从一些销售理论生成一个PPT。我一开始就要把销售的理论给他，不是等他来问我。因为他单纯已经是一个自动化的agent了，我没有办法那样跟他一问一答。如果那个prompt真的下得好的话，你一问一答的时间可以省掉还蛮多的。我觉得这个反而是应用层面的问题，到底需不需要prompt
engineering。

### 学习新知：传统方法与AI辅助的平衡

**Thomas:**
我是另外想问一个问题。我们现在真的学一个东西的时候，直接就从AI开始吗？或者是你们也会选择去听讲座、上课程这样的形式？我想要分享的是，我还是会听讲座。前一段时间我是用录音起来以后，直接用AI转文字，然后做处理来学习。但我最近是回到用一个app叫做Notability。

**Thomas:**
它就是你可以在一边录音的同时，一边手写笔记。你在重播的时候会随着录音，画布上会显示你当时写下什么笔记。我其实这样下来后，反而比较喜欢Notability这样的做法。当然AI进步了，你现在如果去订阅它，那些录音逐字稿他都帮你打出来了，当然也可以做很多事情。但我只是分享说，我最近反而会觉得用一点传统的方式的时候，我反而会比较……不知道怎么讲，比较有效一些。大家可能领域不一样，你如果在一个要一直追新的领域的话，可能还是比较直接依赖AI。

**Jay:** 如果你是一个新领域，你就非得从书本或者是从一个讲课开始。

**Thomas:** 从AI开始太不靠谱了，是这样子吗？

**Jay:**
是的，他可以把你带到东倒西歪，而且你最后自己都不知道被他拉到哪儿去了。

**独行:** 效率非常慢。有时候用AI学那个software
engineering，会变成documentation hell
(文档地狱)，就是你一直在循环走那些文件。我真的是看了一些YouTube影片，一些专家人士出来讲过才惊觉，喔，这个是这样，那个是那样，有些东西就是不用钻研太深。所以我很同意，你还是得要从一些传统的管道去学。

**Vincent:**
这可能要看你想要了解的东西，你是想要“知道”还是要“学到”。比如说你想“知道”，那你就听讲座、看YouTube、做文字摘要，这是知道的范畴。你知道有这样的讯息。可是如果你想要“学到”，因为学到的是一个建立神经连结的过程，它这个可能没有什么捷径。像你刚刚讲用手写，你在写的过程中就通过肌肉增加了你的神经的连接、你的记忆。所以你会对这个反而比较有感觉，因为你手写过，你当然多了一些记忆，他不是这样一听过就结束了。这也是为什么我还是会拿笔记记东西，虽然我会做电子的工作日志，但我读书笔记、日记我都是一定用手写的。因为我就是喜欢这种一边写一边思考的过程。

**Vincent:**
如果相比打字，因为打字很快，你脑袋里面想的东西可以同步输出。可是它就少了那种慢慢雕琢的感觉。比如说你在想一个你今天想不透的事情，你用打字去想，跟你用写字写下来的方式去想，那个结果是大不相同的。所以我觉得你可能要定义你现在的目标是“知道”还是要“学到”。如果你要“学到”的话，我就觉得真的没有捷径，你要建立神经连结，它本来就是很缓慢的。

**Thomas:** 听了你们的分享我就放心了。
