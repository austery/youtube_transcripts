<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI研讨会：观点、用例与未来展望</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
            line-height: 1.8;
            color: #333;
            background-color: #f9f9f9;
            margin: 0;
            padding: 0;
        }
        .container {
            display: flex;
            flex-direction: row-reverse;
            max-width: 1200px;
            margin: 0 auto;
        }
        .main-content {
            flex-grow: 1;
            padding: 20px 40px;
            background-color: #ffffff;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.05);
            margin: 20px;
        }
        .toc {
            flex: 0 0 280px;
            position: -webkit-sticky;
            position: sticky;
            top: 20px;
            height: calc(100vh - 40px);
            overflow-y: auto;
            background-color: #f1f3f5;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0 20px 20px;
            border-left: 1px solid #e0e0e0;
        }
        .toc h3 {
            margin-top: 0;
            color: #0056b3;
            border-bottom: 2px solid #0056b3;
            padding-bottom: 10px;
        }
        .toc ul {
            list-style-type: none;
            padding: 0;
        }
        .toc ul li {
            margin: 10px 0;
        }
        .toc ul li a {
            text-decoration: none;
            color: #333;
            transition: color 0.3s;
        }
        .toc ul li a:hover {
            color: #0056b3;
        }
        h1, h2, h3 {
            color: #2c3e50;
            border-bottom: 1px solid #eaeaea;
            padding-bottom: 10px;
        }
        h1 {
            text-align: center;
            font-size: 2.5em;
        }
        .stats-and-actions {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
            padding: 10px;
            background-color: #e9ecef;
            border-radius: 5px;
        }
        .stats {
            font-size: 0.9em;
            color: #555;
        }
        #copy-button {
            padding: 8px 15px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        #copy-button:hover {
            background-color: #0056b3;
        }
        .lang-switch {
            text-align: center;
            margin-bottom: 20px;
        }
        .lang-switch button {
            padding: 10px 20px;
            margin: 0 5px;
            border: 1px solid #ccc;
            background-color: #f8f9fa;
            cursor: pointer;
            border-radius: 5px;
        }
        .lang-switch button.active {
            background-color: #007bff;
            color: white;
            border-color: #007bff;
        }
        .content-en, .content-zh {
            display: none;
        }
        .content-en.active, .content-zh.active {
            display: block;
        }
        strong {
            color: #2c3e50;
        }
        p {
            margin-bottom: 1.2em;
        }
        @media (max-width: 1024px) {
            .container {
                flex-direction: column;
            }
            .toc {
                position: static;
                width: auto;
                height: auto;
                margin: 20px;
                order: -1;
            }
            .main-content {
                margin: 0 20px 20px 20px;
            }
        }
    </style>
</head>
<body>

<div class="container">
    <aside class="toc" id="toc-container">
        <h3>目录</h3>
        <ul id="toc-list"></ul>
    </aside>

    <main class="main-content">
        <h1>AI研讨会：观点、用例与未来展望</h1>

        <div class="stats-and-actions">
            <div class="stats" id="stats-display"></div>
            <button id="copy-button">复制为Markdown</button>
        </div>

        <div class="lang-switch">
            <button id="lang-en-btn" class="active">English</button>
            <button id="lang-zh-btn">简体中文</button>
        </div>

        <div id="content-en" class="content-en active">
            <!-- English content will be injected here -->
        </div>
        <div id="content-zh" class="content-zh">
            <!-- Chinese content will be injected here -->
        </div>
    </main>
</div>

<script>
    const enContent = `
<h2 id="section-1">I. AI Trends and Strategic Imperatives</h2>
<p><strong>Dave Wessinger:</strong> And my two major investors are Dragonair and Hillman Friedman. They spend more time trying to get me connected with every single person that's moving well, better, or differently in AI so I can learn from that. It's a massive learning journey, and every day could be spent with yet another company understanding their journey. They tend to connect me with ones that have had some reasonable success. And so, I'll just speak to one that's actually connected to healthcare. This is a little more financial, but they do have some healthcare customers, and then I'll talk about a healthcare company.</p>
<p>The one that I saw was a really interesting concept, and I think as I talk about other organizations, I'm largely talking about solutions they deliver to the market as the priority. But invariably, I think when we think about what might be delivered to a market in our own right, our internal stuff, we're consuming others' solutions. So it's the same thing, just upside down. The thing that they've done well as an organization—they struggled to deliver AI to the market. I think what I recognized as the challenge they at least iterated on was they're moving really well in AI now, in the end market. Their revenue doubled year over year. They acquired an AI company, accelerated some of their work, and they basically have been building agents for the last six months and driving a ton of opportunity into the business. They sell it as an orchestration layer (Orchestration Layer: A system that automates and coordinates complex tasks and workflows across multiple applications or services.) for their customers. They productionized it versus giving their end customers an opportunity to build their own agents. And they've done extremely well, and I think doubling revenue in a given year is pretty incredible, actually, in terms of an outcome. So that's really positive.</p>
<p>The one takeaway for me there was he had challenged his own team—really smart, capable people—to move with agents and build it themselves. He gave them a certain amount of time before he had to go outside and acquire it, and basically they weren't able to get to the point where he thought they could have, so he had to acquire. My takeaway from that is no more than if we're not taking time to sharpen the saw and learn and grow, we're gonna be always caught up with the problems of the day and the priorities of what's gonna pull us back. I think getting focused on where we need to go takes a lot of courage from leadership and from all of us. And I think it's not what you say yes to, it's what you say no to. The one thing we hear around this organization a lot is there are a lot of priorities, and the priorities come down to leadership. If we're not really clear with where we need to go and what we need to choose, we're not gonna make that progress, no matter how much learning we do today. We need to create space, and that's gonna be hard and hard to stomach sometimes, because that will deviate from our current plans. But that's one example.</p>
<p>The other one is, and this is a little bit external, talking to some companies that are leveraging AI to drive their growth in healthcare. One example was a company that has built an orchestration layer on top of our application that does two things. One, it gives end users an ability to automate all of their manual processes. So they call it Agent Operating Procedures. And they're building a ton of them on top of our application. So what's interesting out of that is it's not human-centered design; it's machine-centered design. Kind of interesting, moving away from that. And then where they've taken some opportunity, they've gone and created Chrome extensions on top of our app to create a side-by-side workflow where customers can create a lot of intelligence in this Chrome extension on top of our application. And they're making really nice progress, to some extent pre-revenue, but starting to take off because it's obviously solving a big problem. And if it's not clear in every boardroom, the ask is more AI, more AI, more AI. So if somebody's solving that, and it's not us, that could be problematic, and so it does drive you to a sense of urgency and pace to start to deliver on that need. So, two different examples of companies leveraging more of an AI. One wasn't AI-native, and the other one is. And then the question is, you know, how do you compete against that, and how do you think about that?</p>
<p>And then internally, think about this for a moment. We're trying to deliver AI-powered solutions to our customers, which is where we would like to be. Our vendors internally that you deal with, Alan, are trying to deliver AI to us, and they tend to be in their segments, whether it's finance, or sales, or product, or services, or otherwise. But we have to put Humpty Dumpty together in some way, shape, or form to deliver a seamless experience and process for our own employees. So it's kind of hard to think about single-source AI vendors. And that's why things like Copilot or orchestration layers take off, is because they do go across so many different applications and drive a ton of efficiency in the business. So, there are just a few examples that drive a sense of urgency. These things aren't just things we're talking about in theory; they're real. They're starting to impact businesses, and it's material. So I think it's an opportunity internally, but also externally. One doesn't go without the other.</p>
<p><strong>Alan Missen:</strong> Yeah, those are great examples, Dave. I think your point around committed time to learn and that sort of ruthless prioritization, the combination of those two, I think, is a very powerful comment that we really need to take seriously on the back end of today, frankly. I think it's a great point, well made.</p>
<p><strong>Dave Wessinger:</strong> Alan, let me ask you a question as we're kind of going back and forth. As everybody here knows, or should know, we've had a meaningful effort around P2C (P2C (Product-to-Cash): A business process that covers the entire lifecycle from product creation and sales to revenue collection.). And as you think about what we're doing design-wise, business process engineering or business process modeling is a lot around how humans use a solution, and we think about Salesforce or other components that might be in there, and NetSuite. How do you think about AI as it relates to designing differently for the things that we traditionally would focus on? How does a human do X, and how do we make it better? How do you think differently about using agents or thinking differently about AI in just re-engineering the process?</p>
<p><strong>Alan Missen:</strong> Yeah, I think we're kind of at the beginning of the journey, in all honesty, but I do think that that's an area we're trying to evolve quite quickly, Dave. If we look at the traditional way to deliver those big transformational projects, you're right, you sort of scope it, you build it, you test it, you go live. And we're sort of two-thirds of the way down that journey, and all of a sudden, there's a capability available to us that wasn't when we started the project. Right now, we are actively looking at whether there are three or four areas within P2C that we can start leveraging this right away. So it's not just about this new idea that's down the road that we'll go tackle. It's like, we've got stuff that is in flight. How do we start thinking about applying it right now? So a great one is, and I think we showed it at the SLT, and I know it's a passionate one for you, is could we get an agent (Agent: An AI program designed to perform specific, autonomous tasks, such as creating a quote or analyzing data.) to build a quote for a customer for Go Live in November? Could we actually have that ready? And so we're really kind of pushing the envelope on that. And I think there are three or four sort of agentic ideas on the back end of the finance side as well, that we're starting to play around with to say, can we get those in for November 1st as well? So it's a little scary, because we're trying to change scope as we're building the plane. But those are some of the things we're thinking about within PSC around that idea.</p>
<p><strong>Dave Wessinger:</strong> Very good. Yeah, it's exciting. Your point is very interesting in that the advancements in six months, never mind 24 hours, are just unsettling. The pace of change, and I think Mike talked about a five-year time horizon. The disruption of the cloud really took 10-plus years. Disruption here is barely measured in years. I mean, two, three years out, what we see today as normal is gonna feel like it was 50 years ago history. It's pretty incredible.</p>
<p><strong>Alan Missen:</strong> Yeah. And I think the other comment you made, which is really interesting, is some of the stuff that you're seeing around the bigger platforms, it's like the attack vector for some of the innovations is actually kind of on the edges, right? It's not necessarily always the big players who are coming at you; it's the small, innovative company that's sort of hitting it around the edges of what we're doing, and that's a really interesting dynamic for us to wrap our head around. And then the other comment you made around how the vendors in our space, our platform partners, how are they playing? There's a data point that suggests right now, 80% of application software plays will have AI capabilities embedded in them by next year. So, wrapping your head around the rationalization of which ones are good, which ones can be integrated, which ones should we use. You're right, every vendor's knocking on our door right now, going, you need to look at our stuff.</p>
<p><strong>Dave Wessinger:</strong> Let me share with you the why behind that. It really starts with, if you think about enterprise value, it is a key driver for a lot of folks. You sit in a boardroom, and you talk to them. This came up a little bit, but more so after we had this conversation of, what if we do well, or what if we do poorly? Let's just play out a few scenarios. If we do poorly, we could be half the value today, six months from now. Half of our value. What's the difference if we do it well? We have AI-powered solutions showing up on market, demonstrating real revenue as it related to it, and we would do significantly better than what our shareholder value could look like. So if you just think about the economics and why you're seeing vendors show up saying, buy our AI-powered stuff, buy more of that, because their entire enterprise value is based on their ability to demonstrate they're capable of doing that. That's why it's so important for customers, us, other businesses, to kind of move into this new world. It's an existential threat to the value of their business. And so, yeah, people are pretty motivated, some a little more than others. That, to me, is where the opportunity is, but just to give you a sense of where it's coming from and why you're seeing that kind of intensity around it, especially as you get those incoming calls around, buy this, buy that, instrument this way, instrument that way, right?</p>
<p><strong>Alan Missen:</strong> I saw an interesting data point the other day on your point around valuation. At the end of '24, AI organizations were kind of valued at about, I think the valuation was something like $450 billion. And it's expected in the next six years to get to $18 trillion. It's like a 37 or 40% CAGR (CAGR (Compound Annual Growth Rate): The average annual growth rate of an investment over a specified period of time longer than one year.) year over year over year. So it's exactly to your point, it's insane, the expectation.</p>
<p><strong>Dave Wessinger:</strong> Well, I'll give you a very specific data point. Two companies recently acquired, one with two people, north of $100 million. Two people. Another company, an Israeli company, acquired for multiple hundreds of millions of dollars, probably 30 or 40 people. Neither company had any revenue. No revenue. Like, that's the appetite for AI-based companies. It's incredible. Obviously without the legacy or the history, it's easy to start fresh, but it's absolutely incredible. It reminds me of the days where I wish SaaS (SaaS (Software as a Service): A software licensing model in which software is licensed on a subscription basis and is centrally hosted.) companies back in 2002 were actually doing that. They were in '99 before it all blew up. But yeah, it's just clear and interesting, and I look in the mirror, I'm like, "Holy shit, I'm old. I'm gonna catch the second wave." Like, the first one was cloud, I'm gonna be around for another one, I can share stories. I'm kind of excited to write the next paper for Forbes about what it's like to go through two major disruptions in a lifetime. So, anyways, I digress.</p>
<p><strong>Alan Missen:</strong> Absolutely. Next quick question, then, around sort of, in the healthcare space, and you've sort of talked about it a little bit, what are the areas you see will have the most significant disruption in the next few years?</p>
<p><strong>Dave Wessinger:</strong> Well, I think the ability to augment human and replace some of the mundane tasks, absolutely without question. The other thing I would say is the ability to power folks to be a lot smarter about and prioritize the work they do, so that the little we have, we'll be able to do so much more with in healthcare. But I also would say the thing that I think is very interesting is that I believe that invariably, the entire industry will be responding to information and taking action. So if you think about sensors, and you think about the capability to ingest information, either biosensors, historical information, all of that. This kind of, "you need to enter something to have an observation to react to." Thinking about designing anything for a human to enter something is like, "What are you talking about? That's not a thing anymore." And so, when you think about that barrier being gone, we have full information now, we can kind of turn that into something we react to. I think it's a really interesting way to think about the future.</p>
<p>But I think in terms of impact, I would tell you that for any of you who were at Summit or heard me talk to Dr. Rue, what they're doing in terms of ophthalmology, the ability to kind of read a scan of an eyeball and understand your entire diagnosis, or a significant portion of it. Think about that one image that will likely work its way to a phone. Right now, it's a fairly complex piece of equipment, but it will become commoditized. That in a moment, you can understand what would otherwise take you hours of assessment, and if they're non-coherent or incapable, you might not get all of that information. To understand the human body and understand what to go do from an image in a moment, you can effectively drive an entire service plan, plan of care, what's required, what their diagnosis is, get them treated appropriately and personalize that. That will be a very interesting day, and it's very hard to get that wrong because you're not relying on a human response. You're not relying on a response they can't provide, or documentation that might not be accurate. It's crystal clear. So that advancement in terms of understanding the person and to know what to do, I think will be really instrumental in driving the quality of care that these people deserve.</p>
<p><strong>Alan Missen:</strong> Yeah, it feels very similar to some of the research I've been doing lately around healthcare and AI, and your point around AI-centric scanning technologies. The accuracy level and the speed with which they're delivering good data—you know, brain scans being twice as accurate as in the past, bone scans catching people who have broken bones who x-rays weren't catching. Triage-related activities, getting to know the right people who have to go to the hospital versus the ones that aren't versus EMSs. Yeah, there's a ton going on there, for sure.</p>
<p><strong>Dave Wessinger:</strong> Preventative early detection, obviously, is the big cost savings and quality of life aspect. But we're still human, we're still gonna vote for those wing nights and the stuff that's like, "Oh my god," so how that relates to how it extends our life or not, I'm not entirely certain, but we'll know what to do. The question is, will we do it?</p>
<p><strong>Alan Missen:</strong> Awesome. Next question. Any sort of misconceptions around AI within healthcare that are worth talking about?</p>
<p><strong>Dave Wessinger:</strong> Misconceptions. Oh. That's a good question. I don't know that there's any real misconceptions. Are they fearful of it? I think there's not a fear factor, but I think there's also a little bit of ego around it. If you think about practitioners or those that have built a profession on gaining that knowledge around how to do something, that's a pretty big thing to separate from. I don't know that it's a misnomer or misunderstood, but I do think there are areas of healthcare that will receive this faster than others. There's a huge trust component that is a real thing. So if the misconception is that, "Hey, if it demonstrates an outcome, everyone's gonna run after it," I think we're gonna see, with the responsible nature of it, the ethics, the hallucinations—if you're not 99.99999% right, and you might otherwise kill someone, that's bad. We have this today at PointClickCare, by the way, and it's not even AI. But we make recommendations based on information in meds that have a clinician go, "Oh, yeah, that makes sense," translate that to a SIG, or however that worked out. But the translation from natural language into a structured format might make a mistake. And if they have to validate that because it's right all the time, they'll go, "yep, yep, yep." And once in a while, it's wrong. Well, guess what? That actually could kill someone, for real. So now what do you do? Do you not enable them? Do you go backwards? So, there is, like, we all talk about it. I think the expectation of it just landing and working smoothly, and they just have to get over their own ego, is one thing. But the other part is, it really has to work. It really has to work, or you're actually doing harm, and none of us want to do harm. We believe that today, humans are in the middle of ensuring that we have that validation and verification. Should that become just an easy step, we're gonna lose that, and I do worry about it becoming human nature and behavior that invariably you create some of these cracks that are unintended. So I think we have to pay attention to that, and I think it's a little bit harder than we think in healthcare. There are other areas where you can have that error rate; here, I think it's going to be pretty hard in certain areas. Administrative tasks, not as much. Clinical-focused tasks, absolutely.</p>
<p><strong>Alan Missen:</strong> Yeah, I totally agree with that. It's another data point I was reading recently that comes back to the AI and trust dynamic. 75% of the public today, consumers, do not trust results from AI today. And so when you sort of apply that into something as important as healthcare, that mountain to get over in terms of trust is definitely a big one for us to deal with.</p>
<p><strong>Dave Wessinger:</strong> I think it's huge. Yeah, I think that's huge. You know, we're getting close to closing out, and I think that's why we see Marina, so hello. But for me, as we think about our business and getting back to what today is about, Alan, which I think you kicked off really nicely, I would like to ask you, what would success look like today, Alan?</p>
<p><strong>Alan Missen:</strong> For me, it kind of comes back to the comment you made earlier. To me, if we really create a much more robust list of really powerful use cases that we can actually go action and move on, that, to me, is a great outcome of today. I think you're going to see later, I know we're chatting a little bit later today, that we've got some pretty modest but decent progress across almost every function. We've got, I think, north of about 70 different use cases that are being looked at today. I'd love to see that be, you know, 200-300 that we're looking at, and then start really working towards building that skillset to be able to action them quickly. We had a really interesting conversation the other day around the investment to build an agent, and it's not software from 10, 15 years ago. Maybe you can build stuff, and maybe it's only good for 3 months, and you throw it away, but the investment to get there was so fast and so quick that that's okay. And I think getting more motion on actual action, actual product to hit these use cases and get value at a pace that we haven't necessarily seen before. That's kind of the big outcome. To me, that's the big win.</p>
<p><strong>Dave Wessinger:</strong> I like that. There are a couple of things that jump out to me in that. I think you said it on the agent side, the manual tasks, like if you take calendaring and automate some of that, where we actually create space. I mean, the amount of time we waste trying to figure things out between busy people trying to get things on a calendar, oh my gosh. But the thing that I would ask all of you to think about is to recognize that AI is an amazing thought partner and collaborator. So, if you want to write a memo about something you want to go do, that's kind of an Amazon thing. They really run by memos, not by PowerPoints. If you want to really thought partner and enhance your capability in how you think about something, your IQ goes up significantly, and you're way more prepared, way more intelligent around whatever aspect you're thinking about or trying to improve or address. And the other thing is you're not getting judged. ChatGPT or whatever product is not judging you. So you just iterate and iterate and iterate, and your ideas become stronger and more thoughtful and more appropriate. So whether that's an email or a memo, or sharing where you'd like to go, or a presentation you want to give, all of those things, to me, will allow you to perform and move a lot faster. We obviously use each other to collaborate, but I would ask you to leverage the capabilities of that to enhance how you think about things here and the problems that you do want to solve. So, I'll pause there, but that would be a good outcome for me, that people recognize that's a great opportunity for them.</p>
<p><strong>Alan Missen:</strong> Awesome. I love the thought partner idea. It's interesting, I was reading another article in the MarTech space a few weeks ago around all the efforts going on around AI and content creation, in particular that use case. And they used very similar language. They said they were leveraging it as really a creative ally. That idea of partnership and being an ally, very much, I think, is a way to look at it as we go into this AI world.</p>
<p><strong>Dave Wessinger:</strong> Yeah, I mean, the last thing I'll say, the experience for me was also, "What am I missing? What did I do wrong?" And they're like, "Oh, you're doing a great job, but you might want to think about..." like, oh my god, this is amazing. This reinforced positive behavior that somebody would be yelling at me and telling me I'm an idiot, but it's just like that. So, I would also say the last thing in healthcare that I'm really excited about is, as some of these things land in healthcare, like, they're using robots in Japan, they're using robots in high-risk situations. Believe it or not, laundry, right? Dirty laundry is a high-risk human job, at least in SNFs (SNFs (Skilled Nursing Facilities): Healthcare facilities that provide 24-hour nursing care for residents.), for sure. And so if you think about robots starting to take over in areas in dining rooms, things in laundry, it's going to be a point where they help ambulate and they do some basic things, and they minimize elopement issues, and all of this stuff where we're powering in that. What's interesting about that, and what I've heard from our customers is, as a companion, they're more inclined to engage more with a robot than a human because of the judgment aspect. There's a huge judging aspect here that kind of goes away that I think is really interesting as you engage with it. Maybe the interesting thing is to create an AI agent that judges you. That would be kind of a fun tool. No, kidding. I'm kidding. But, anyways, lots of fun. Big day ahead. We're a little bit over time, and I'll let you get on with the day, and I'm excited for all of you that have decided to make room for this today. Really important for us, really important for you, because I would tell you the last thing I would say here is our job descriptions for everybody in the company will change. Your job description today is already out of date, and we need to make sure that what you think your job is today, if you're not growing, you have to have that mindset of, what are you a beginner at? What are you learning? Absolutely critical, and we will be evaluating on your progress with AI capability. That's a necessary piece, and I think Mike talked with Toby from Shopify the other night, and that was a key indicator, is all of our performance reviews will have an element of AI to it. What have you done? Have you progressed? What are you learning? It's just too important for us. We can't miss this one. And so it's not okay to be, "Eh, I don't care about AI." That's just not cool. It's not cool to miss school. So, with that, I'll pause. Thank you all for being here.</p>
<p><strong>Alan Missen:</strong> Dave, thank you so much. That was awesome. I loved the back and forth there. And so with that, Marina, I think we're ready for our first use case.</p>
<p><strong>Marina Stojanovic:</strong> Absolutely. Yes, thank you both for jumping on and sharing your thoughts this morning. And again, we have lots of questions in the chat and in the Q&A that we'll be sharing with you directly to be answered, because we are a little bit over time, so I appreciate it. Thank you so much! Thanks, Dave. Thanks, Alan. All right, first up is our first use case. He's here to kick us off.</p>
<h2 id="section-2">II. AI Use Case Showcase: Part 1</h2>
<h3 id="section-2-1">Aha! Co-pilot Agent for Project Management</h3>
<p><strong>Marina Stojanovic:</strong> His name is Aakif Shaik, and he's going to get us started. Aakif, go ahead and start sharing your screen.</p>
<p><strong>Aakif Shaik:</strong> Alright, thank you, Marina. Are you able to see my screen? Hello everyone. My name is Aakif Shaik. I am a business transformation co-op in the SDO. Over the past few weeks, I've been working on building an AI-powered co-pilot agent that integrates with Copilot Studio and Power Automate. For those of you who aren't familiar with Aha!, it is a project management tool that teams use to be able to track and manage their work. Within the SDO, we essentially use Aha! to track and manage our key initiatives, like the go-to-markets and the product-to-cash program.</p>
<p>The problem that I was really focused on was, how can I make it easier for people, whether they're a program manager or someone within the team who's trying to access and get a quick update, to be able to use an AI-powered assistant to do that. So, if you've ever found yourself thinking, "Hey, I just want a quick status update without jumping between different tools," then this one's for you. Where we're at on our current journey is right at that pilot stage, where we're testing out use cases as well as adding additional use cases. Once we get to that full functionality, we want to move to full adoption.</p>
<p>Going to the demo stage. Here is a little bit of a walkthrough of what the UI interface looks like for Copilot Studio. As you can see here, I'm going to start off by giving it a simple prompt by asking it, "Hey, what are the activities that are currently due this week?" Once I go ahead and do that, you can see on the left side of the screen that it starts to execute a flow. What this co-pilot agent is currently doing is using Power Automate, which is integrated with Aha!, to pull in information on activities that are currently due this week. So here you go, it's particularly focused on GTM, which is the go-to-market program, and it shows us the names of the activities due this week, along with their due dates. This is great. Let's say we want to take it a step further and say, "Hey, how can we go ahead and get specific details for each of these activities?" So I'm gonna go ahead and give it another prompt now, asking it, "I want to know the status of a particular activity." Once again, you can see on the left side there, it's executing a different flow now, which is asking for which activity I would like to check. So, I want to give it the name of that particular activity. And once I do that, that's when it starts to execute a different flow. Now in this flow, the output is going to be different, because it is going to be focused on this particular activity and getting us the status updates. So here we go, it gives us the name, what the current status is, what the due date is, as well as who it is assigned to.</p>
<p>This is what the current functionality of the agent looks like. Going into a little bit of what's under the hood, if you want to add additional functionalities, you essentially add them as topics. You start off with a trigger, and then a question, and then the action. This is where you want to integrate your Power Automate flow with it. Lastly, you have your output message. The same thing goes for the other flow as well, which covers what is due this week. This trigger is really important because this is what the agent uses to differentiate what your ask is. So, once again, you have your flow, as well as your final message. For those of you that are curious to see what this Power Automate flow looks like, feel free to reach out, and I'll be happy to give you a walkthrough after this call as well.</p>
<p>Now, moving on to talking about impact. What this tool really allows teams to do is transform how they access project updates. Having this AI-powered assistant allows you to minimize the use of switching over different tools, as well as digging through different dashboards, and actually just be able to get detailed, focused answers through a simple question. The lessons learned for me in this journey were definitely to start small and build iteratively. Following up on what Dave had said earlier, it was starting off with a simple use case, testing out a sample set of data, and continuously building on that to make sure that it didn't get overwhelmed. And then getting to the stage where we're at, where we're working with all of the complex data.</p>
<p>How we can help others at PCC: teams can definitely use Copilot agents for various purposes. One thing I can think of would be for the product team to be able to build a co-pilot agent that integrates with their product roadmap, so that teams can get a status of where they're at in the entire product roadmap journey. This can also be useful for teams that use Jira, to be able to get quick status updates on what the Jira dashboard basically states. Lastly, the responsible use of AI. This project aligns with the responsible AI guidelines because it focuses on transparency and user control. The co-pilot agent that you saw earlier delivers clear information directly from Aha! without actually making any decisions on behalf of the user. And it does this with accurate information and ensures that there is no bias in the response as well, making sure that all of this data is secure. With that, I want to conclude my presentation, and thank you.</p>
<p><strong>Marina Stojanovic:</strong> Amazing. We really appreciate your presentation, and we'd love to hear from anyone that has any questions in the Q&A function. We are loving your presentation, Aakif. Way to go! Great job. Other than saying please and thank you to your AI robots, we don't really have any questions for you, Aakif, so thank you. Everyone's really excited for your use case, and if there are any future questions, we will be able to take them down and send them to him directly afterwards.</p>
<h3 id="section-2-2">Gainsight AI for Customer Success</h3>
<p><strong>Ketki Yennemadi:</strong> Next up, we welcome Pam. Our next use case is on Gainsight, being presented by Pam from Customer Success. Over to you, Pam.</p>
<p><strong>Pam Martin:</strong> Terrific! Thank you. I am a director in customer success. Today, I'm going to talk to you about Gainsight. Gainsight is a platform used by customer success to help manage the post-sales relationship, and today we're going to talk to you a little bit about how we're using that to uncover risk and trends in our customer base. For those of you who don't know what customer success is, it provides strategic guidance and expertise to accelerate customer outcomes and realize the vision and value of the PointClickCare platform. Those are fancy words for: We have deep relationships with our customers, we meet with them on a regular basis to help ensure that they are realizing value so they want to be customers, stay with us forever, and that we're discovering opportunities with them to help them achieve their goals, and for us to discover how we have other products that can help them achieve that.</p>
<p>How AI is helping us today: it's saving us time, it's providing a holistic account insight, and also trends across all customers. Gainsight itself is the core platform, and we have a lot of other platforms that feed information into it that help give us a holistic insight into our customers and what's happening with them. The first one I'm going to dig into here is the Gong integration. Gong itself creates a summary of action items and automated notes. This populates directly into Gainsight, saving CSMs (Customer Success Managers) time because they don't have to do that, allowing them to be more present in their meetings, and those action items can be converted right to tasks, making it easy for them to follow up. On the right-hand side here, you're going to see AI-generated sentiment. And that's really cool because it really goes through the automated notes and picks up the overall sentiment, removing any bias that people might have about how they felt that conversation went. So, good insight for the team.</p>
<p>The next one we're going to chat about briefly here is drafting emails with Copilot. Hopefully, everyone is doing this today already. But it really helps take that idea, make it concise, make it land better with customers, and really elevate it. While we're in Copilot with Outlook, we also have the ability to leverage Gainsight Assist to take those emails that we're drafting and put them right into timeline. And we're going to talk in a second here about why timeline is so important to us.</p>
<p>Timeline, what we're looking at here, is an account-level timeline, and it captures everything that happens in the account. There's no AI magic here. We're gonna get to that in just a second. But what it does is it captures all these activities that give us the full picture of what's happening in the account. So whether that's programmed messages that they're receiving, how they're managing risk in the account, managing NPS (Net Promoter Score: A metric used to measure customer loyalty and satisfaction.) detractors, those meetings that get posted there. So all of that goes into the timeline. Now, this is an account view, and you can see how really rich that can create information. And without an AI cheat sheet, you have to go through every single one of those to see what's going on. But, with an AI cheat sheet, it gives us a summary of the last six months of what's happening at that account level. And this is really powerful because it eliminates the recency effect, where people often only reflect on what happened last week or last month. A lot of times after that, it gets lost. So it pulls out some really key information in here that's valuable for the CSM, but even valuable in how we use this cross-functionally. So we have other teams that we can share this with. Think about if we have an escalation, if we have a customer who wants to discuss product, we can pull this summary of the account and share it with them. We do ask the CSMs to look at this and think about what they're seeing critically. Does it cover all the right information? Is there anything that's missing here? And so, they do have the option of adding notes to it if they feel like it's not accurately giving the full picture.</p>
<p>The cheat sheet, again, is at the account level, and this is where things get super exciting. Coming soon, they just launched something called Signal Mining using AI in Gainsight. Signal mining allows us to look across all of the timelines for all of the accounts. So now we'll be able to prompt it to ask questions about expansion opportunities, regional trends, competitor mentions, product mentions, advocacy quotes, and more. So imagine the power of saying, "Hey, we want to know what customers are talking about skin and wound," and entering in the prompt saying, "Provide me a list of every customer that's talking about skin and wound in the last 3 months and what they're saying about it," and providing that information cross-functionally. So we're about to unlock some really powerful information and insights to the organization. Very exciting.</p>
<p>To summarize, it's saving us time, it's providing holistic account insights, and we're shortly going to be able to see trends across all accounts. What we've learned is that AI is only as accurate as the information that's going in. So for Customer Success Managers, if it isn't in Gainsight, it didn't happen. It's really important that everything goes in there. We encourage you to look at the tools that you're using today, understand what AI capabilities it has, and ensure that you're leveraging it to its maximum capacity. And lastly, I'll just mention here that we still really need to ensure that we're looking at the outputs of it critically, for completeness and accuracy. With that, I'm going to open it up to any questions.</p>
<p><strong>Marina Stojanovic:</strong> Amazing. We actually had a question for you from Alan. Any sense of time savings being seen by the team since turning on these tools?</p>
<p><strong>Pam Martin:</strong> That's a great question. The cheat sheet we've had on for a while, but we haven't really done the math on what that's saving us. But something definitely for us to look into. What I'm really excited about, Alan, though, is the ability to look across all of the accounts and then understand how that's saving us time. When we think about that, it's something we're doing manually today, is saying, "Hey, customer success managers, who has customers that are talking about skin and wound?" Now we'll just be able to do that without having to ask them and then only bring them into conversations when we need to dig deeper on particular points or concepts.</p>
<p><strong>Marina Stojanovic:</strong> That's amazing. There's a lot of excitement about your use case in the chat. Lots and lots of positivity for you, Pam. So thank you again for your presentation.</p>
<h3 id="section-2-3">Azure OpenAI for Customer Interview Analysis</h3>
<p><strong>Auroosa Kazmi-Ishaq:</strong> Our next presentation is from Sonal for Marketing. She's presenting two use cases for us today, one on Azure AI Foundry and the other on Azure OpenAI GPT. Over to you, Sonal!</p>
<p><strong>Sonal Misra:</strong> Thank you. Hi everyone. I'm Sonal Misra, and today we're not gonna go back in time, but we're traveling deep into unstructured data. Using Azure's OpenAI, I engineered custom prompts that extract rich, meaningful insights from customer interviews. It's almost like having a time-traveling assistant who listens to every word and summarizes the gold. The tool that I used for this project was Azure's OpenAI. You must be wondering, what exactly is it? Think of Azure OpenAI as one's own digital Doc Brown—highly intelligent, fast-thinking, and just a little futuristic. It uses prompt engineering with GPT (Generative Pre-trained Transformer: An AI model that can understand and generate human-like text.) to break down long interview transcripts, pull up customer pain points, solution benefits, impact metrics, and even quote-worthy testimonials, all in a matter of seconds. To show you the action live, I have a little demo.</p>
<p>This is a demonstration of how we leverage Azure's OpenAI and generated custom-engineered prompts to transform interview transcripts into structured, actionable insights. This approach replaces manual analysis with automated extraction of key elements, such as customer challenges, value statements, and impact metrics. Over here in the chat playground, I have inputted the interview transcript collected from the interview. In order to highlight, for example, the customer challenges, I inputted the prompt asking it to highlight specific problems, inefficiencies, or frustrations that the customer faced before the adoption of the product. The model was able to identify quotes about manual burden, higher ed risk, and inefficient workflows, which are kinds of insights that the team can act upon immediately.</p>
<p>Next, in order to identify solution and product value, I asked it to extract descriptions on how the solution improved the workflow. The model was able to pull out value-driven quotes, such as how there was seamless information sharing, reduced medication errors, and an increase in efficiency for care staff—all wonderful things that are great for case studies and marketing material. Furthermore, in order to identify the metrics and proof points, I was able to input the prompt asking it to list numeric evidence or performance indicators that were provided in the interview. It was able to capture the number of years that the organization had been with PointClickCare, how it started off at one location and has expanded to over 50 locations, the reduction in call times, and such are the wonderful metrics from the interview transcription. Lastly, in order to identify value quotes and testimonials, I included the prompt asking it to extract them. It was able to capture each quote that the customer was able to mention, leading from current patient and resident care to reducing medication errors, which could be used again for marketing materials and customer testimonials. In conclusion, I was able to develop a full prompt library, categorized by theme based upon customer challenges, solution and value, and metrics. All of these templates that can be reused across transcripts are adapted for fine-tuning or can be embedded in search pipelines, reducing manual review time by over 50%.</p>
<p>The project is aimed to deliver high-impact results where we significantly reduce analysis time by eliminating the need to sift through lengthy interview transcripts. The extracted insights are now consistent, quickly accessible, and easily reusable across different teams, such as marketing, sales, and product teams. Furthermore, this ensures that the quality of the content has improved with more accurate quotes, clearer themes, and less reliance on manual interpretation. Now, you may wonder how others might be able to use this. The best part is, this approach is easily adaptable for any team working with qualitative feedback. Marketing, for example, can potentially extract compelling value quotes. Project teams can surface recurring pain points, and sales can possibly identify impactful success metrics, all using the same set of prompt templates. Whether analyzing surveys, interviews, or feedback forms, this method helps streamline and enhance insight generation across the board.</p>
<p>While creating this project, I also focused on the fact that I was using AI responsibly. These prompts were tested and results were manually validated. We prioritized explainability, used neutral language to avoid bias, and ensured humans remain entirely in control, so there were no rogue AIs rewriting our past, like Biff with a stolen sports almanac. Lastly, I would want to thank the marketing engagement team, who helped me shape the approach, showing me that the project is not just a shiny tool, but a time-saving, insight-driving platform when used responsibly. As Doc Brown would say, "Your future hasn't been written yet, so make it insightful." I would be more than happy to answer any and all questions that you have. Thank you.</p>
<h3 id="section-2-4">Automating Contact Collection with Azure OpenAI and Power Automate</h3>
<p><strong>Sonal Misra:</strong> Moving on, I'm excited to present my next project on automating the collection of critical contacts using Azure's OpenAI and Power Automate. This project was completed as a part of the Digital Customer Success Team, where our goal was to reduce the manual effort involved in tracking important contacts from auto-reply emails. This was done using Azure's OpenAI GPT via Power Automate, which is a low-code workflow platform. The GPT model is triggered within the automation to interpret the email content, extract structured information like names and email addresses, and then log it into an Excel sheet hosted on OneDrive and easily accessible to all. As you'll see in the demo next.</p>
<p>Every month, our team would send out digests or other communication pieces, which would result in auto-reply emails, and some of these would contain critical contacts or new points of communication. Manually tracking these is very time-consuming and prone to human error, so our automation scans each incoming email, extracts the relevant information such as the forwarding contact, and adds it to a centralized shared Excel sheet, making the whole process very quick and very consistent. And now I'll be presenting the demo for it.</p>
<p>Hi everyone. Today, I'll walk you through the process of automating email data extraction. First, the automation program is set up for extracting content from email bodies and storing it in an Excel sheet, such as forwarding contacts that we receive from auto-reply emails. This helps streamline data as well as improve efficiency. To organize our emails for automation, firstly, we'll have to create a subfolder. This can be done by clicking on the three dots on the left-hand side panel beside your email address and clicking on "Create a New Folder." Here, I've created the "digest" subfolder within my personal inbox for the purpose of this program. After that, we go into the shared inbox where we would be selecting the emails that we would be wanting to extract the data from. For the purpose of this demo, I've used the Customer Success Digest inbox, which has many auto-reply emails with forwarding contacts in them. So, we can select the right emails and then move them into the subfolder that we have created in our personal inbox. This could be done by just clicking Move, or directly dragging and dropping it into the folder. Once that has been done, I will have to go into the subfolder to double-check if the emails are being registered. After that, you can go back to the automation program to see the status of each email and the data being extracted. It is usually really common for it to take some time while the process is running. And now we can go into the Excel sheet and see all the emails and the forwarding contacts being recorded. The body column usually records the forwarding contact that has been mentioned in the email. If there are multiple contacts, those would be separated by a comma within the body column. For example, in this email, we can see the forwarding contact here has now been recorded. Those emails which do not have a forwarding contact and are still in the subfolder would not be registered in the Excel sheet. And that's about it. This is how we can use automated email data extraction in Outlook to save time and for accurate data collection. Thank you.</p>
<p>The impact of this automation program has been significant, where we have saved hours of manual work per month. The process now takes minutes instead of hours. It's improved data accuracy, reduced the risk of missing key contacts, and made our team even more productive. Everyone has access to the real-time list, which strengthens internal coordination and responsiveness. Now, you may wonder how others can use this. This can be used easily and replicated across other departments. For example, HR teams can possibly automate responses to applications. Support teams can potentially extract key details from ticket replies, and marketing can possibly use it to track event RSVPs. The beauty of this solution is its scalability and low barrier to entry, with no coding required.</p>
<p>While creating this project, another thing that I kept in mind was to responsibly use AI, where these prompts were tested and results were manually validated. We prioritized explainability, used neutral language to avoid bias, and ensured humans remained entirely in control. I would also like to thank the Digital Customer Success Team for their support. This project showed me how simple, responsible AI integration can drive efficiency in daily workflows. Furthermore, for the marketing engagement team, for the encouragement for me to showcase this project. I'm excited to continue exploring automation opportunities across the team. Thank you so much.</p>
<p><strong>Marina Stojanovic:</strong> Hi, Sonal, that was awesome. There's a lot of excitement in the chat, as usual, for your use case. Alan has asked to connect so that you can discuss your use case in more detail. He's sharing his excitement about how other work in the business has been happening along the same lines, so I think this is a great invitation to connect. They're trying to use tools from outside sources to help with this problem, so he'd like to learn more about it. Definitely take a look at the Q&A as well afterwards for some of the chat questions and feel free to answer them directly.</p>
<h3 id="section-2-5">Reggie: A Generative AI Chatbot for Regulatory Affairs</h3>
<p><strong>Auroosa Kazmi-Ishaq:</strong> Our next use case is from Mary and Hazelle from Regulatory Affairs on their generative AI chatbot named Reggie. Over to the two of you.</p>
<p><strong>Mary Henschel:</strong> I'm Mary Henschel, thank you so much for having us here. I'm with the Regulatory Affairs team, and I'm here with Hazelle, and she's from the Technical Support and Services team. Today we're super excited to introduce you to an AI solution that our regulatory team has developed for our department. We have finally named it Reggie, and it is a generative AI chatbot. There really are two parts that make Reggie so successful. First, Reggie has a repository that is automatically kept up to date with the latest regulations. And second, Reggie uses advanced natural language understanding, contextual awareness, and generative AI capabilities to address complex regulatory questions. On the maturity journey, Reggie is close to the pilot phase. We've loaded it up with senior living regulations first, and once we're comfortable with the results we're getting, we'll go ahead and add in our other business lines. With that, let's zoom in on the problem.</p>
<p>The Regulatory Affairs team is tasked with staying up to date with an ever-changing regulatory environment. If you were on the town hall yesterday, you heard Dave talk about just how much of our product is dependent on meeting regulations. It's a lot. Our team reads, influences, interprets, and translates regulations for internal teams like product, customer success, account execs, implementation, etc. We also provide information to our clients, not to mention we do a whole bunch of other stuff. Our industry has always been heavily regulated, but now we are seeing more regulations move down to the state level, which is compounding our problem. There are just so many more regulations for us to track. As an example, I'm on a senior living team, and the senior living industry has 65 different licenses across the 50 states, and they're all super different. There's not just one body of regulation; sometimes there are multiple regs that we have to read in order to understand the complete picture. The regulatory team is relatively small, so we needed a way to essentially multiply ourselves. This seemed like a perfect fit for AI to solve.</p>
<p>We currently have a regulatory repository where internal PointClickCare teammates can submit questions to us and we answer them, but we wanted to provide more of a self-service model, really using our team when they needed more context. We wanted it to be faster and self-service. We had worked with Hazelle and Rahim's team to develop that repository, so we really see Reggie as being V2.0 of the repository. We started researching for solutions last summer and we looked at several commercial AI products, but none of them solved our biggest challenge, which is to know when the regulation gets updated. All the other commercial tools put the onus on us to feed their repositories with the regulations. I really thought that we could do something better, and it turns out I'm right. I reached out to Dean and I described the problem, and he suggested that we have Rahim's team take a look at the challenge.</p>
<p>I'm going to talk about Part 1, which is the front end of the problem: figuring out when a regulation gets updated. I provided Amandeep Jaj, who's on Rahim's team and Hazelle's coworker, all the hyperlinks to all the senior living regulations and the state forms. There's a lot, I mean, there are hundreds. Amandeep built a tool that connects to all the state's regulations and downloads them automatically into a repository. Each night, the script runs automatically and checks to see if there have been any updates, and if so, his tool updates the repository. Then, he built this data pipeline that takes the regulation and feeds it into Reggie, where Hazelle's tool really does its magic. On top of that, the system sends an automated email notification to my team with a spreadsheet that indicates which regulatory links have been updated. Which is so brilliant, and it's working great. So now I'm going to have Hazelle talk about the work that she did with Reggie.</p>
<p><strong>Hazelle Florencio:</strong> Sure. So now that we have the data, Andrew Taniram and I developed a search and AI pipeline and user interface for Reggie. Reggie, as Mary mentioned, is a GenAI web chat application that users can use to get up-to-date answers to their regulatory questions more efficiently, instead of doing a manual search or reading through multiple pages of dense documentation. Reggie makes it easier, even for non-regulatory persons, to understand state regulations. Reggie is built on Azure services, full-stack code, and retrieval-augmented generation, which means that the answers you get are grounded by trusted and clean data. The system leverages retrieval of the most important or relevant information, then the AI model uses that to respond with accurate and contextually aware answers. Although it is possible to build something like this by building your own co-pilot agent in Teams or in Microsoft 365, we decided on this approach due to Reggie's requirements for scalability, flexibility, and reporting. This also enables us for more continuous learning capabilities and native support for an extensive catalog of AI services and models. Back to you, Mary.</p>
<p><strong>Mary Henschel:</strong> Alright, we're gonna do the demo. [Due to technical difficulties with audio, the demo was narrated live.] So this is Reggie, our landing page, your personal regulatory affairs assistant. I'm on the landing page and I'm gonna ask it a question. This is a particular question about who must review the Resident Assessment Tools. This was just updated recently, so this is actually a real use case. What it's doing is we ask it a very complicated regulatory question. In this example, this was a recent update that happened on April 28th in the state of Maryland. There was a question about who needed to review the resident assessment tool. So, I asked the question. You can see down on the bottom right here, it does give me a message saying that AI-generated content may be incorrect, and so that's part of our responsible use of AI. It also gives me the two references because I need to validate that this is actually correct. So I'm going to click on one of these, and then it's going to bring me to the source, and then I'm going to find this information in the source. Then it's going to go out further to look at the actual state website.</p>
<p>The way it works is it essentially is continually updating, making sure that we have the best and most up-to-date regulations. We can ask them questions, we can validate it, and then there's feedback loops in there. We can say, "Yes, that was good, that was correct," or if it was somehow incorrect or the citation was wrong, we then give it a thumbs down and we say why it wasn't correct. We can also say if there was some inappropriate language that was returned, which is also part of our responsible AI. So far, the results have been very exciting.</p>
<p>Our impact has been that we're essentially going to be able to effectively multiply our team. We can't just keep throwing more bodies at this, and there are just going to be more and more regs at the state level, which really is hard for us to keep up with. A lesson learned: while we were connecting to these state websites, the states all do things a little bit differently. Some return HTML, some return a PDF, a DOC; some have security around it. Sometimes we have to go through an API (API (Application Programming Interface): A set of rules that allows different software applications to communicate with each other.). So Amandeep really had to, in the beginning, do some of this manually, and now that we have our feet under us, he's going to use AI to accelerate his work so we can bring on the other business lines. We just hope that everybody who has a regulatory question can start here, ask it a question. We are always here to provide more context, to go deeper, but we think it can really save a lot of time in getting answers to our clients. And I can go ahead and turn it over to Hazelle to talk about RAI (Responsible AI).</p>
<p><strong>Hazelle Florencio:</strong> Yeah, so when it comes to responsible use of AI, we will make sure that we have well-documented guidance on how to use Reggie and what data Reggie has. We also included a disclaimer, as Mary tried to demonstrate, in the user interface to remind people that they always have to validate the AI answers. We will also continue to monitor and evaluate Reggie through reporting and the feedback that we've added. In the future, we'll also conduct LLM (Large Language Model: A type of AI model trained on vast amounts of text data to understand and generate human-like language.) reviews in case there are other or newer AI models that fit Reggie better. When it comes to security, as of now, we only have approved sources and content by the regulatory team. Also, Reggie is only accessible internally. There is a whitelist in place to accept VPN or office traffic only. Additionally, we could leverage Azure AI Content Safety, which allows us to enhance safety for Reggie, such as blocking harmful inputs or outputs, or creating custom AI filters if needed, as well as probably exploring the groundedness detection, which is a preview feature, to help detect and avoid the AI making stuff up, and more.</p>
<p><strong>Mary Henschel:</strong> All right, so what's next? What's next is we will soon be adding our other business lines: skilled nursing, pharmacy, etc. The other thing that Amandeep is gonna do is he's gonna actually highlight the actual language that changed in the regulation to make it easier to find at a glance. We'll be enhancing the feedback for more thorough answers, so sometimes we want to provide even more context around the regulation. We want the ability to manually upload some files. For some use cases, sometimes the state puts out provider letters or bulletins that have more context around the regulation; we'd like to upload those too. And then, thinking ahead, we really want to start generating actions, so creating a Jira ticket automatically, for example, or automatically creating a Salesforce case, or creating a regulatory briefing as well. And, you know, the other thing that, looking way out in the future, is potentially we could offer this to our clients at some point. There are, like I said, commercially available tools that people are actually paying to use right now, and it could be potentially even a revenue source for us. So with that, I'd like to thank our team members from the Regulatory Affairs team, who've been working on this with me: Tatiana Vasilieva, Robin Roberts, Janiece Hornberger, Jackie Nordhoff, myself, Eugene Gonzior, and of course, Donna Weimer.</p>
<p><strong>Hazelle Florencio:</strong> And from the Technology and Support Services team: Amandeep Chaj, Andrew DeNirum, Clyde Gonsalves, myself, and Rahim Ashwani.</p>
<p><strong>Mary Henschel:</strong> Okay. With that, any questions? If anybody wants to see it live, just let me know, and I can take you through the demo.</p>
<h2 id="section-3">III. Keynote: AI's Economic Impact and Corporate Strategy</h2>
<p><strong>Alan Missen:</strong> Thank you. I kind of feel like Dave was more of the keynote than I am. I've just got some insights I'm going to share with the team. Thanks for giving me a few minutes and a little bit of a break between what have been exceptional use cases and demos so far. I love the diversity of the types of ways that we're piloting and playing with AI. I know one of my goals today was for everybody to learn. I know I've already learned a ton in this first hour of show and tell. So hopefully you guys are getting as much out of it as I am.</p>
<p>I started the day a little bit with those quotes when we were bantering back and forth with Dave. I thought I would start off with a little bit of fun facts just around AI in general from a couple of different dimensions. First is what's going on globally around the economic impact and growth. A couple of these I touched on earlier, but if you kind of look at the global AI market, companies were valued at about half a trillion dollars at the end of last year. The forecast is a growth trajectory of about 37% a year. I've been in 11 industries, and I've never seen a CAGR of 37% over a 7-year window in a plan before. That is unbelievable. We're looking at a $1.8 trillion valuation for AI companies in a very, very short window. When we look at the projected contribution that's gonna make to the global economy by 2030, it's expected to be almost $16 trillion. For some data, that would surpass China and India's economies combined. This idea, I think Mike teed it up yesterday, around "is this a fad?" This is clearly not a fad.</p>
<p>In terms of productivity, the expectation is that AI should improve employee productivity by at least 40% in the coming years. The other one that's been really interesting, because a lot of organizations struggle with this, is the value around it, the ROI. It's been a bit tricky at times, particularly with some of the utility tools like Copilot. You give somebody 15, 20, 30 minutes of time back a day. How does that turn into true value for an organization? But organizations who are being very targeted around what they're using AI for are starting to see a turnaround in the ROI equation. 74% of organizations using some more advanced AI initiatives are meeting or exceeding their ROI expectations, and 20% of those ROIs are actually greater than 30%. I think that points to us really being thoughtful. I love the experimentation and the breadth of the types of things we're playing with, but part of our journey, I do think, is the prioritization of the ones that are going to be the most meaningful to the business. And then, you know, Dave talked a little bit about this as well. AI has very, very quickly become the top funded sector. Already one-third of VC funding is going directly towards AI-related companies in a very, very short time. For it to become the number one sector in literally the space of a year is fascinating.</p>
<p>If I look at the next dynamic around usage, and this is really more of a business usage lens, adoption for businesses by the end of '24 was about 72% of businesses were reporting using AI in at least one function, and that's a significant leap over 2023. GenAI, similarly, the adoption has soared, with about 50% of businesses using them by the end of 2024, and that's up 33% from 2023. So the acceleration of use, and we're seeing that, Rahim and I are seeing that with some of the tools that we've got in place around Copilot. We're seeing a very aggressive utilization number growing. Just for another data point, that 33% growth in GenAI year over year surpasses the initial adoption of smartphones. That's another one of those points where, is this a fad? I think not. This is definitely here to stay.</p>
<p>Speaking of devices, nearly 77% of devices now are using some sort of form of AI. The top 3 business use cases, I don't think are going to be any surprise to anybody. We've seen a number of them today. Time savings is at the top of the list in terms of efficiency. Content creation, the marketing teams have been using a lot of that. Generating ideas is another big use case, and of course, simplifying processes. Those are the usual suspects. The three areas in corporate worlds that have been impacted so far the most positively in terms of value have been customer support, software development across a number of different dimensions (code generation, testing, even use case development), and marketing. Those are the three areas that have seen the most value so far, even though as we see this agentic journey coming, it's really impacting every function in most organizations. The top tools, ChatGPT, no big surprise, Copy.ai and Jasper AI are the top three that are being used in the consumer and the business space.</p>
<p>If I look at the next dynamic around the workforce and how this is impacting the workforce, you heard Dave make a comment earlier that I thought was interesting about all of our JDs changing on the fly. I think that's a really interesting comment to make. If we think about job creation and displacement, there is going to be a lot of churn around jobs. Jobs that might be going away, but net new jobs that are starting because of AI, hence getting in front of it for all of us as individuals on our own personal learning journey. The thinking right now is that this net job number will actually grow because of AI in the area of 10-15%, but there is likely to be quite a bit of churn around some jobs going away and a lot of new jobs being created. The other thing that's interesting is the skill gap. One of the early use cases, particularly around learning, is actually allowing the bridge of the skill gap between low and high skill workers. The most obvious example that I've seen in the past is I used to run large call centers, and it would take us quite a while to get a new rep productive. AI is now really helping accelerate somebody getting productive in roles like that, so they get to be a knowledge worker much faster, instead of a 3-5 month window, they're getting to that window in 30 to 60 days. So it's really been interesting to see that.</p>
<p>On the societal side of things and how consumers are looking at AI, 84% of Americans actually use one or more AI-powered devices or services today. 55% of Americans regularly interact with AI several times a week, but only 34% of consumers realize they are actually directly experiencing AI, which I find fascinating. The virtual assistant is the big area where people are interacting the most, like Alexa and Siri. I mentioned this on the chat with Dave, there's a fair bit of optimism, 50% of consumers are optimistic about AI, but as we sit here today, three quarters of them are actually quite concerned about misinformation. So that trust factor that you heard Dave talk about a little bit earlier, the RAI angle of what it is that we do is so important to create that trust internally as well as with our customers.</p>
<p>When I look at healthcare, we talked a little bit about this. Dave gave some perspective as well, but in some of the research I was looking at, it's astonishing to see how already AI is starting to make a big difference in things like brain scans being twice as accurate, bone scans. So scanning technologies, AI-based, seem to be delivering much better results, getting to better outcomes for customers. Ambulatory evaluations. The other one that's fascinating, Dave mentioned the preventative side of it, disease prediction in patients who are not showing any symptoms. They're talking about AI being able to predict thousands of diseases that they will be able to get in front of before humans are starting to feel any symptoms at all by picking up other data signals. That's fascinating. Clinical chatbots around triage and helping doctors do triage faster. And then, of course, a place that's near and dear to our heart is a lot of the administrative burden relief. Clearly, that's a big part of our journey on the product side, but also players like Microsoft and Google are playing a key role in that as well, particularly in healthcare.</p>
<p>I'm gonna just put this slide up for a second. This is actually given to us by our partners at H&F. One of the things that I love about private equity firms is they tend to be quite directive. So this wasn't just an art of the possible kind of conversation. It was a little bit more like, "Here's who's winning, so here's where you should absolutely be spending your focus as an organization, but here's where experimentation is going." The big three that are listed here, we've already kind of mentioned. On the software development side: coding, testing, security, project planning. I would say we are starting to see value in a lot of those things already in PCC. It's still early days, but I think both in the corporate tech functions as well as with Bill's engineering team, we're already starting to see some value, some experimentation, but also some actual productivity around that space. We're even seeing value in early-stage project work. We're doing a lot of work within the OCIO around gathering requirements, building out use cases, and rolling that into a project by leveraging AI. So quite a bit of activity, quite a bit of valuable use cases in the software space.</p>
<p>Customer service is really at the top area where there have been multiple use cases that are directly customer-touching, and we are working pretty aggressively with Elaine and the customer support team around some ideation that we've got and a roadmap to help them there. Then marketing is another area that has absolutely exploded in terms of leveraging AI. I mentioned earlier this idea of a creative ally around content creation. There was an example of a small startup who was trying to get a lot of social posts done, and they implemented an AI assistant to help them with that. They started doing 50 social posts in a few hours, which was generally what it was taking their staffer about a week to do. So, a massive increase in productivity. That's on the drive side. On the experimental side, it's interesting. I think this data has actually changed even since the slide was created, because they're definitely pointing to a lot of experimentation around this agentic push and platform push, which you've seen a couple of examples of already this morning. We've had partners and vendors who are delivering capability that we can take advantage of. I think the Gainsight example that Pam gave was fantastic. So you're now seeing this starting to impact every other corporate function as well. On the drive side, sort of the winners to date have been targeted at a more modest list, but you can see in this experimental column, it's really starting to impact everybody, and the platform push from all the vendors and the agentic push that's happening is really driving a lot of that.</p>
<p>What's the journey looked like for us so far here at PCC? I would say that our AI corporate strategy, Dean and team were clearly working on this on the product side earlier. Our journey probably started about 15 or 16 months ago. Early on, I would say it was very assistant-focused because that's where the technology was at that time. It was very much a question and answer journey around GenAI capabilities, like Microsoft Copilot. It was around individual productivity-focused. In FY24, we probably had about 100,000 Copilot requests the first year we launched the platform with Microsoft, and that probably, according to what I like to call Microsoft math, they estimated that to be probably in the area of 10 to 15 minutes a week of time savings per employee across the entire organization. In FY25, that number has changed quite dramatically. We are probably gonna end up at north of a quarter million Copilot actions requested, and another 150,000 LLM actions, GPT actions. The impact of that would appear to be somewhere in the range of about 50,000 to 60,000 hours of what Microsoft likes to call assisted hours, or time savings. So that's taken us from a 10 to 15 minute a week of time back to what looks to be closer to about 30 minutes. That's actually quite a good bump year over year in terms of usage and adoption that we are seeing with Copilot. 92% of you are using it on a consistent basis. Even in recent months, we're continuing to see an even stronger acceleration. We've seen about a 125% increase just since January in Copilot actions and doubling down on the assisted hours.</p>
<p>The areas that typically people are seeing the most value today in terms of prompts and value is definitely meeting-related. It's absolutely at the top of the list. It's probably 50 to 60% of the value. So, those meeting summaries, those sorts of things are absolutely at the top of the list. Corporate search is another interesting one. It's a significant portion of the usage today, and I find that interesting because there's a tagline being floated out there around AI that's saying, "Is AI the new UI?" Much like Google kind of changed the search dynamic with a very simple UI, a search bar, and drastically changed how that experience is. Will AI and agents sort of change that as well? You heard Dave talk about, we're getting past the days of humans entering something. A lot of activity around consuming voice data and going off and doing a task or bringing back information. The idea of old-fashioned intranets for employees, does that go away? We're actually starting to see that a little bit with Copilot and people starting an HR journey or a question within Copilot as their UI versus going to a more sophisticated website. Email's kind of the third area where we're seeing quite a bit of usage.</p>
<p>The other area I've listed here is Spark. So Spark is very similar to what you just saw with the Reggie tool, but we started out with the customer service group last year. It was really kind of an experiment for Rahim's team. It's a knowledge-based tool, natural language responses, but we sort of added it to the team as, again, an ally. So it wasn't replacing reps; it was really a tool for the reps to get better and faster when answering questions to customers, and I think it supported north of 150,000 questions last year in dealing with the customer service team. We saw improvements in mean time to resolution, CSAT, and customer effort through that. So, again, a little experiment that actually did deliver some decent value. The other thing we're starting to see more and more of is the other piece that we talked about, which is the application world. Application partners are starting to come to the forefront in a number of areas: analytics, process automation, and then the software development and security side for sure. What you're looking at here was a number of the vendors who came to us with solutions in 2024. I would call it a bit of a wave, but 2025 seems to be more like a tsunami. I think I shared this data point earlier, but literally within the next 6 to 12 months, 80% of software platforms are expected to have AI features. Hence, you heard Dave talking about both the opportunity we have, but frankly, the threat that we have. If they're not spending money with us, they could be spending money with competitors. From the product side, I know there's a lot of passion around getting to market with more tools around what we can do to help our customers. I do think what's happened is not only are our customers', I think all customers' expectations are drastically changing around this, and there's an expectation of having AI capabilities when a software vendor knocks on your door. I think one of the conversations we're having internally is, do we actually make that a standard in an RFP at this point? If you don't have AI capabilities and are working on it with an active roadmap, you're not going to be included in an evaluation, potentially. So that's a way for us to think a little bit differently around pushing our partners as well.</p>
<p>So if I look at PCC today, at the beginning of that, on the right-hand side, what we're seeing is more the tsunami. I think we probably had about a dozen vendors who were talking to us in '24 around AI capabilities. I would say I don't know if we're at 80%, but it feels like it's 80% of the vendors now are knocking on our door. Gainsight's a great example where some of those capabilities Pam was showing, we've just turned on. So we have story after story of our partners, and I do think from a perspective of this group, that's also part of what we should be learning. How can we become experts on the AI capabilities within the tools that we already have? Agentic building and building agents is a great one as well, but I think actually becoming an expert on how the Gainsight AI works actually adds value. Those are really important to us as well because we've already made significant investments in these platforms.</p>
<p>If I think about where we are today, I think, again, I mentioned this a little earlier when Dave and I were chatting, we actually have a fair bit of activity going on. We have about 16 that we're aware of, it's probably higher than this. We have about 16 functional teams today that are doing anywhere from 1 to 10 different use cases that they are playing with, piloting. Some are live, some are still in the ideation state. So we have north of about 70 unique use cases, a number of which you guys are seeing today. They are in various states of progression: ideation, POCs, pilots, and a number of them are live. The capabilities that we are looking at are actually quite diverse across those, and I think you'll get a good flavor of all of that as you guys see the rest of the day as well. So some of them are related to insights. The voice and conversational intelligence capabilities in a lot of these platforms are jumping through the roof. I think at the SLT, I said 30 days before the SLT, I think we had one platform that had conversational intelligence capability. Today, I think we have five. That's in the space of about 60 to 90 days. So some of this stuff is just exploding. We have co-pilots that people are looking at. We have agent development that people are looking at. We have agentic foundational frameworks that Cedric is working on that is fascinating. And then we have even agents starting to talk to agents, and I think that's a game changer. You heard Dave talk about that earlier. So now agents in different ecosystems actually being able to interact with each other is something that's sort of on this new verge. We just heard of a major announcement from Salesforce this week around that exact thing. If we want to have Microsoft agents talking to Salesforce agents, that's now possible, and 3 months ago, it wasn't. So, really exciting there. We've got CodeGen going on, customer experience AI activity going on, and a lot of other stuff.</p>
<p>I would say we have a mixture of some buying activity with tools, but we've also got build activities going on, so a pretty good mixture of both. It's a lot, but I would say that one of the things we're trying to do, and I think today is the beginning of that, is really kind of accelerate these ideas through the ideation state into actual action, execution, and value. We seem to have a lot of the ideas that are still kind of early stage, being played with or talked about. We've got to be able to get through these cycles of "should we or shouldn't we" with this much, much more effectively than we have. We've been, I would say, fairly modestly slow, and I keep coming back to Dave's passion around the speed of the organization, and that's definitely an area we need to focus on, even though we do have quite a bit of actual activity. And, you know, I think the other area we've got activity, and Cindy and I chatted about this briefly this morning, is there is a pretty robust AI curriculum that the HR team and the learning team have brought forward. Hundreds of courses are available for you guys. So, if we think about the genesis of this dialogue and learning at the core of the discussion, I think one of my action items, and I think it really needs to be all of ours, is to really take advantage of that content and really start focusing on the actual learning and accelerating our learning, and using the tools that we have and actually helping inform taking that enablement capability to the next level.</p>
<p>So as I kind of wrap, I wanted to start with a couple of thoughts that maybe start with each of us as an individual, and then maybe roll into a little bit of the corporate AI-first culture. I think we each have a personal journey, and there's a corporate journey around this. I do think we should be asking, each of us should be leaving this session today really asking ourselves, what can we each do to maximize our impact? My little catchphrase there is, "How can we use AI to AYI—accelerate your impact in the organization?" To me, that's a commitment to learning, to collaborating, to experimenting. The fact that we've got a CEO who yesterday shared with us that he's been building agents, I think that's some pretty cool leadership shadow for us to be looking at how we should be tackling this. And again, I think today is all about learning.</p>
<p>If I think about it maybe a little bit more from a culture and a corporate perspective, one of the hot phrases right now is an "AI-first culture." My definition of an AI-first culture would be making AI a part of every major decision, innovation, and process in the organization, and it is at the heart of how the organization operates. You heard Dave ask me a question earlier today about how we are thinking about AI as it applies to P2C. We've been talking about P2C as a transformational program for a couple of years now, and we are in the heart of delivering it right now. But an AI-first organization would be starting to apply it, "Hey, let's not wait till we're done and then think about AI. Let's see what we can do to apply it right now." So I think that's a very valid way to sort of start your thinking around an AI-first culture. I think an AI-first culture also requires deep knowledge on AI: what are its strengths, what are its weaknesses, what are its potential impacts? And we need to be thoughtful about that. Again, this comes back to the learning journey. It also, Dave talked about this, is about rethinking and redesigning the work processes. There's an automation aspect to it, but it really is around rethinking and redesigning work. I kind of equate this back to, it's really a combination of having a Lean Six Sigma mindset along with applying AI tools to it. So I think that's another big part as we evolve this AI-first culture that we need to be thoughtful about.</p>
<p>I do think it also means adapting and embracing AI as part of your daily work. The Copilot growth is a great example. We're starting to see people really use that tool more and more, but I think each of us should be thoughtful about, how do I create an AI habit for myself? There are lots of books out there on how to create a habit, so I won't go through the details of that, but I think we should all be thoughtful about how we are creating that daily habit in our life around AI. I also think a part of the culture is what we are doing today, encouraging teams to work with AI. Today's session is the poster child of that personal commitment to continuous learning, evolving with AI, I think, is a really important aspect of how we think about it, and I think that's a natural extension of a growth mindset. You heard Dave mention growth mindset again this morning.</p>
<p>If I think about this from a bit more of a strategy perspective, at the top of the list around any strategy is leadership commitment. And again, if Dave and Mike's commitment to AI is not clear, I'm not sure what meetings you've been attending, because it's about as clear as it can be that right from the top of the organization, this is a top, top priority. The other thing that we are focused on on the corporate side right now is a little bit around the vision, the corporate vision, and building out a bit more of a robust strategy to help people wrap their heads around what the vision is, as well as some guideposts. As I look at our corporate vision, I've got two or three things that are bubbling up. Our goal is to transform our workplace by augmenting human potential with AI to increase our pace, multiply capacity, and improve effectiveness. That's kind of at the core of it. It also means, from a strategy perspective or a corporate perspective, it's about investing, and I think we're investing time today. One of the things I appreciate about this organization is when an investment makes sense, there is no shyness from a leadership perspective to make an investment. So, investing in training and tools is at the forefront of that, and again, one of the things I think PCC is quite exceptional at compared to other organizations I've been in is they're not afraid to make those investments.</p>
<p>I think it does mean more robustness around planning around AI, working more and more on a robust AI roadmap, and we've got some thinking on how we can help the functions actually accelerate some of the work that they're doing, kind of having function-by-function dialogues in the coming weeks. Enablement we talked about with tools, with training, enablement with data, enablement around ethics. I think that's another key part of the strategy. And then the other thing that could happen is this could lead to, Dave mentioned earlier the idea that JDs could be changing. Could this maybe lead to some modest level of org design? I don't know. Do you create things like centers of excellence? Do you have more cross-functional constructs to actually help accelerate? So, those are some of the things we're thinking about and trying to get a little bit more granularity around on the strategy side.</p>
<p>I'll probably wrap with one more quote. I love my quotes. "Artificial intelligence is not about replacing humans, it's about amplifying human potential." I really think this ties back to what you've been hearing from Dave and Mike. Mike yesterday made comments about this journey being focused on improving our speed, quality, and effectiveness of the team we have. And I think that's a really important aspect of the journey here at PCC. Speed, you heard Dave mention speed two or three times in our dialogue earlier this morning, so it's really about amping up our potential more than anything else.</p>
<p>Final kind of thought here. Today is about ideas and the art of the possible, and again, my hope for everyone today is you learn something, get exposed to ideas that you haven't been thinking about yourself, that you think you can apply. But I also want everybody to leave asking some questions. Kim actually came up with these questions at the SLT, so I'm not gonna take credit for it, but I think they're really, really good things for all of us to leave this session with today thinking about. So how are you envisioning the role of AI evolving your role and your function? Think about it at an individual level as well as the function that you do. How can AI drive innovation in the team? How can AI be integrated into existing processes that you have? What specific challenges can AI help us solve? We're trying to get back into these functional conversations. We believe that part of that is sort of a pain point analysis, so we think that those sessions will help with that. What competitive advantages can AI provide us in the marketplace? I know Dave is putting 99% of his thinking around that right now, which I feel really confident about. And then what partnerships can we leverage to advance our AI capabilities? Earlier on, I spoke about just how many vendors are knocking on the door right now with an AI capability. So we should tap into that for sure and understand what partnerships can help us, or whether it's a solution integrator who's got learning and some good stories around what they've been able to deliver for customers around AI capabilities. So just think about partners that we can tap into as well to help us with that. So with that said, thanks for letting me share some of my thoughts today, and let's keep going on the symposium.</p>
<h2 id="section-4">IV. AI Use Case Showcase: Part 2</h2>
<h3 id="section-4-1">ReliaQuest GrayMatter Agentic AI for Security Operations</h3>
<p><strong>Ketki Yennemadi:</strong> Starting with Caleb and Christy from the Security and Trust team. They will be talking to us about ReliaQuest GrayMatter Agentic AI.</p>
<p><strong>Kristy Liu:</strong> My name is Christy, I'm here with Caleb. We're both from the security operations team. We focus on phishing emails and different types of investigation that involve users and endpoints, things like suspicious login account issues, or anything unusual happening on devices. Today, we're going to talk about how we've been using Agentic AI to speed up and simplify threat detections. Looking at this slide, you can see just how many different tools we use on a daily basis. We use platforms like Defender, CrowdStrike, Sentinel, Wiz, and Mimecast. They're all important to our work, but each one has its own interface, and each tool shows data in a different way. This means investigation can take longer because we need to pivot back and forth. Sometimes we need to run multiple queries in different platforms and try to piece everything together manually. We realized the challenge and we can do something to improve it. Therefore, we purchased ReliaQuest and we feed all the log sources into ReliaQuest. Now ReliaQuest becomes the central platform. It pulls the data from all these tools, and it uses AI to normalize the data, and we can just work from one place. Because of that, investigation time has dropped from 45 minutes down to about 20 minutes in many cases. We now have reusable playbooks and a clear process in place that makes it easier for anyone on the team, regardless of whether they are new or experienced.</p>
<p>This slide shows how ReliaQuest uses Agentic AI to investigate alerts. When an alert comes in, the process starts with the planner component. It's like the brain of the system. It looks at the context around the alert. It knows the environment, if there are any similar past alerts, and so on. Then it will decide how to investigate it. After the planner stage, it hands off to the part of the system that actually takes actions. This part runs the searches, uses the tools, and does the heavy lifting to carry out the investigation. Now, depending on what happens during the process, we get one of three possible outcomes. If the result is unclear, or something doesn't look right, the system goes back to the planner to rethink the approach. If everything looks good, it builds a reusable playbook. If it's not a real threat, it marks it as a false positive. This is how the Agentic AI process works at a high level, from planning to action to outcome. I'll hand it over to Caleb. He will be showing a few examples in the demo.</p>
<p><strong>Caleb Waldemar:</strong> Thanks, Christy. I'll go over two different examples of alerts that we've used Agentic AI with to greatly reduce the mean time to investigate and resolve. The first example here is the modification of a sensitive file. Without Agentic AI, this would take us a long time to investigate, could be an hour, could be three hours, because we have to pivot into multiple different tools, as Christy was showing you earlier, look at different logs, and try to correlate which user performed this activity and what device it happened on. However, with Agentic AI, the alert triggers, and then the Agentic AI can look at it and take proactive action. The big difference between AI and Agentic AI is that Agentic AI is able to take more proactive measures without as much human intervention and guidance. So, Agentic AI with ReliaQuest will proactively generate an investigation plan. It'll pivot into all of the tools that we've integrated with it proactively and then look for related logs and activity. It'll analyze the different command lines that an attacker might perform to be able to give us plain text descriptions of what's actually occurring. It'll look to automatically go out to the internet and enrich suspicious websites, URLs, or files to tell us if it thinks that it's suspicious or not. And then it'll also give us a final decision on whether it thinks that this activity is malicious or not.</p>
<p>This is just a second example of a similar alert, but this was a true positive. I think the big benefit that I've seen Agentic AI provide is it helps us to keep all of the users at PCC operating more smoothly. So if a user or device is impacted in an attack, or they click on a phishing email, Agentic AI helps us to get the user back up and running a lot faster. Whereas previously, we would have to manually disable the account, perform an investigation that could be one hour or three hours, perform remediation, and eventually bring everything back online. But with Agentic AI, before the alert even comes to us security analysts to investigate, the AI has already gone in and investigated. "Okay, this is a compromised user. They did click on a phishing email," or as you can see here, "they did execute this suspicious file and run it." And then it can proactively, for us, isolate or suspend the user's device. It can reset passwords proactively. And so, when the alert actually reaches us, the user has already had their account reset, and the malicious emails quarantined.</p>
<p>So as Christy was mentioning previously, the biggest impact for us is reducing the investigation time to under 20 minutes for most of the alerts that we receive. The alerts that we receive are a lot more valuable than they were previously. So, with previous vendors, a previous MSSP that we used, they would basically say, "Okay, this user did this activity, deal with it." But with Agentic AI, it's able to say, "Hey, this user performed this activity. They also were seen performing this other related activity that looks suspicious." The AI is able to make a decision for us and say, "Hey, looking at everything, I believe this user's activity indicates a compromise or not."</p>
<p>I think the biggest lesson learned for us is that AI isn't a fix-all. You can't just let it run and do its thing forever and not provide it active feedback. With ReliaQuest's Agentic AI, we provide it proactive feedback for every escalation that it sends us. We'll provide feedback on whether the AI's analysis was accurate, did it provide us the right data, were there data points that it was missing that we wish we would have seen? And as we provide that data to the AI, it's able to proactively learn and adapt itself to the use cases that we really want it to operate in. I think that's one of the big benefits, being able to proactively train or teach the AI to benefit you as much as possible. When it comes to helping others at PCC, I recommend that you just step back from the daily tasks that you're doing and look to see what kind of manual or menial tasks that you do on a very repetitive, frequent basis that may be automated or you could potentially use AI to perform for you. With us and the responsible use of AI, with ReliaQuest's Agentic AI, every single action that the AI takes, we have strict guidelines around. So we only have specific pre-approved playbooks and actions that the AI is able to take. All actions are logged and recorded, and then we're able to investigate why this AI made this decision on this particular alert. If there are any issues, we're able to proactively work with ReliaQuest to make improvements to the AI. Open to any questions y'all have.</p>
<p><strong>Marina Stojanovic:</strong> Awesome, Caleb and Christy. We do have one question in the Q&A for you. Besides the time saved, how accurate is this tool? Do you find more true positives with it, and have false positives caused any issues?</p>
<p><strong>Caleb Waldemar:</strong> That's a very good question. I'd say that it is very accurate. The false positives are fairly minimal because the Agentic AI, as it analyzes alerts, will proactively close them out as false positives if it determines that they are benign. We will do audits of those closed alerts and validate that they are closed correctly, and I personally haven't seen an alert that the Agentic AI closed that I think shouldn't have been closed. It could have been a notable event, but it wasn't anything that was malicious.</p>
<h3 id="section-4-2">Reimagining Account Planning with Gong and Copilot</h3>
<p><strong>Marina Stojanovic:</strong> We have Daisy next, and over to you, Daisy.</p>
<p><strong>Daisy Dool:</strong> Perfect. Thank you. I am Daisy, and I'm an Enablement Program Manager. I design and manage programs that empower customer-facing teams, like sales and customer success, so they can do their best work. My focus is on driving efficiency, boosting productivity, and creating learning experiences that truly support our revenue goals, whether that's increasing pipeline, improving customer retention, or enabling teams to confidently navigate complex processes. I work cross-functionally with sales, customer success, professional services, product, and marketing to build scalable training paths, launch new tools and workflows, and ensure teams have what they need at the right time to succeed with their customers. Today, I'm sharing how we reimagined a core workflow using AI, specifically how we helped account executives reclaim hours of planning time by using tools they already have. No new platforms, no steep learning curves, just a smarter, more intentional approach.</p>
<p>This year, we rolled out a new customer engagement model for our enterprise customer-facing teams, like sales, CS, and PS. The goal was to create greater consistency and alignment in how we support our customers, especially in more complex strategic accounts. With that came the need for a more structured and visible way to collaborate across teams, and that's where account planning came in. As a part of this new model, we introduced account planning as a key motion. For context, an account plan is a shared document that helps teams align on customer goals, identify risks and blockers, map out key stakeholders, and document how we plan to engage and grow the account strategically. But very quickly, we realized that creating these account plans, while important, was also really time-consuming. Account executives told us it was taking 3-5 hours, and most of that time was spent summarizing what they already knew, not building strategy. So we had a critical motion that was meant to support deeper engagement and strategy, but it wasn't scaling. That was the challenge we needed to solve. We didn't want to throw out the process; we just needed to modernize how we supported it. That's what led us to rethink the workflow using AI.</p>
<p>We didn't bring in any new tools; we just leaned into what we already had access to. For those who may not be familiar, Gong is our conversational intelligence platform. It captures and transcribes customer calls, and then uses AI to surface trends, like what topics are being discussed, how much a customer is speaking, and even indicators of risk or momentum. Quip is our collaborative workspace. It's where account executives and other members of customer-facing teams document the account plans. It's live, editable, and in context. It also integrates directly with Salesforce, so it becomes a part of the workflow, not an extra step. What we did was introduce a workflow that connects the two. Gong gives us the insights, and Copilot helps structure those into a draft account plan that's ready for Quip. The goal here wasn't to automate thinking; it was to save reps time on summarizing and formatting so they could focus on strategy. Importantly, every plan still goes through a human filter. Reps tweak, adjust, and make it their own. It's still their voice, just with a head start.</p>
<p>Before I show you how the workflow works, I want to quickly highlight what we were able to unlock by rethinking our approach. First, we took what used to be a 3-5 hour task of building an account plan and turned it into something reps could kick off in about 15 minutes. That shift gave them back time to focus on strategy, not documentation. They could spend more time thinking about what moves the account forward, not just capturing what already happened. We also introduced a repeatable playbook that meant teams weren't starting from scratch, and leaders could more easily coach to a consistent process. Along the way, we improved our data hygiene. As we rolled this out, we uncovered issues with contact records and CRM (Customer Relationship Management: A system for managing a company's interactions and relationships with customers and potential customers.) alignment that we wouldn't have noticed otherwise. It helped us clean up the foundation we were building insights on. And lastly, this approach is scalable. What we built for account planning can be adapted to assist customer success managers with success plans and just gathering other important customer insights. So, now that you have a little context, let's jump into the demo.</p>
<p>Hello, Demo Daisy here. I'm gonna be walking through the workflow at a high level. I already have everything preloaded, so just keep in mind that this might be a bit of a quicker experience than what our AEs are going to be doing, but it's still time-savings for them as well. I already have a customer account here up and ready in Gong. Just as a reminder, Gong is essentially our source of truth for all of our customer interactions. It hosts our call recordings but also email interactions. We are using a Gong briefer, which is essentially a group of prompts that our AEs can leverage with one click. It is pulling insights across those customer calls as well as the customer emails. I already have the account plan brief here pulled up. Something to be aware of, we have created this brief so that it aligns with the same headings that are in the account plan template. But essentially, what will happen is the AE will prompt Gong to pull this brief, and it will, again, just pull insights across all of our calls and emails. Once that's ready, they will copy all and head over to Copilot. We built an account plan agent and embedded three prompts that we think are going to be the most impactful when we're thinking about the different tasks involved in account plan builds. We have the first prompt, which is "build my first draft," and this will essentially take the information that we have pulled from Gong and put it into more of an account plan-friendly format. You'll notice things like a summary at the top of each of the sections, and basically it will be removing any redundancies or duplications that are coming up across the bulleted points from Gong. So here we have that summary. Everything is still built into those sections, so it really is an easy copy and paste for our AEs. I think one thing I do want to call out here is there's always going to be the opportunity for the AE to review as they're building out their account plan draft. Going back to Gong, it's more than just reviewing the points. They can dive in deeper and figure out where Gong is pulling this information specifically.</p>
<p>Now that we have our first draft, maybe the AE wants to prioritize which sections they really should be focusing in on. We have created a prompt, which is, "strengthen my account plan," and this will have the account plan agent review what was built, what's working well, and any recommendations, section by section. You'll have noticed in that prompt library there is a third prompt, which is basically a prompt that allows the AE to combine the information from their Gong insights with an older account plan. This really saves them time so that they're not having to virtually start from scratch, and there's a continuation from any previous account plans. Once they are comfortable with what they have here from Copilot, they can begin copying and pasting into the Quip Account Plan template. Like I mentioned, we made it super easy by matching headings to headings here. One thing I do want to call out, we purposely omitted the executive summary because this is really where we want the AE to be spending their time. This is where they're going to be building their summary and point of view based off of all the information they have compiled, whether it's through Gong, Salesforce, or various different areas. And they're gonna build that summary here in the executive summary. So, this is really important because we are being purposeful with how we're using our AI workflows here. It's always meant to be a supporting tool, not an end-all be-all, and that's built into the workflow by omitting the executive summary. That's my workflow, looking forward to continuing on with the presentation.</p>
<p>Just to recap, but also zoom out, we've taken what used to be a multi-hour task and turned it into a 15-minute jumpstart. But this wasn't just about speed. The real unlock was giving reps time to think strategically and removing the friction that made planning feel like a chore. We built this using tools people already knew—Gong, Copilot—so the rollout was really smooth, and because the workflow is repeatable, we are now scaling it across enterprise sales. But we also learned a few things the hard way, like the importance of clean CRM data. Gong was surfacing insights tied to the wrong contacts, which helped us uncover and address deeper hygiene issues. Now, we're adapting this workflow for other teams: success plans, regional sales, value-based care progress—wherever people are stuck spending time on structure instead of strategy. That was the key for us. AI gives reps a head start, but the team is always in control of what gets shared and how it's shaped. AI supports, but never, ever replaces their judgment. Before we head over to questions, I just want to say a few thank yous. First, a big shout out to Corey Fosco and Mark Bouchard. You were the ones asking how we could save the team time and help them focus on what really matters. This workflow exists because you are looking out for your reps. Samantha Leckie, my manager, thank you for encouraging me to pause and explore how we can improve things through better workflows. Your support made the space for this work to happen. And finally, a huge thank you to every AE who tested, gave feedback, and helped shape this. We wouldn't be here without you. This was a true team effort, and I'm really proud of what we built together. Alrighty, with that, I am excited to open this up for questions.</p>
<p><strong>Marina Stojanovic:</strong> We don't have any questions for you in the chat, only compliments. There is one question: Is this agent autonomous, or can it learn and adjust and relearn?</p>
<p><strong>Daisy Dool:</strong> Right now, we built it so it's not autonomous; it's not learning off of anything. We've really built it based off of prompting because the goal of the agent was to take the insights and make it format-friendly for our account planning in Quip.</p>
<h3 id="section-4-3">AI-Powered Utilization Data Analysis</h3>
<p><strong>Ketki Yennemadi:</strong> Next up, we have Jenna.</p>
<p><strong>Jenna Paglia:</strong> Hi, everyone! My name is Jenna Paglia. I am the Sales Enablement Manager on the Revenue Enablement Team, and I am so excited to be talking about our AI use case today. My project was in conjunction with solution architect Jeff Wright. Our use of AI will empower the go-to-market teams to easily understand customer utilization data and have more meaningful conversations with customers about business outcomes. A lot of prep went into this. For example, I went as far as to watch "Back to the Future" for the first time last weekend, so I've never felt more ready to talk about advancing technology.</p>
<p>I wanted to start by talking a little bit about the problem we were facing. 360 Insights is an incredibly powerful tool which provides us with an abundance of data, including customer product utilization and performance metrics. However, with this increase in data availability, the senior care sales and customer success teams were faced with a double-edged sword: a great amount of information, but also a great amount of information to interpret. Reps can spend up to an hour interpreting utilization and performance data for a single customer call. Now, in revenue enablement, our job is to support the go-to-market teams, and their problems are our problems. We wanted to come up with a way to enable our teams to really easily understand the data in 360 Insights, cut down on the amount of time spent interpreting that data, and ultimately, give them that time back to focus on what really matters: how can we help our customers deliver exceptional care? Enter AI, our solution.</p>
<p>We created an army of AI agents that can do all of the heavy lifting for our reps when it comes to interpreting data for specific PointClickCare products. These AI agents translate raw utilization data from 360 Insights into trends that can then be related back to customer business outcomes. I'm gonna hand things over to my partner on this project, Jeff Wright, who recorded a quick demonstration of our infection prevention and control AI agent in action.</p>
<p>We've been working on a tool to help show the correlation between great outcomes and adoption and utilization of our products. The example we have here is our infection prevention and control analyzer. Really simply, how we built it is to test to see if the application would work. Obviously, if we're going to roll this out at a larger scale, we'd want to connect directly to the data itself. So there's a couple of steps I'm going to show you here that eventually we would want to automate as well. But the first thing I wanted to show you is we're going to take a customer's utilization data. I'm using a customer's data, but I've cleaned it up and am making sure that we just use a fake name here: CareCorp. So I'm going to upload CareCorp's infection prevention and control utilization data, and what I've asked it to do is group the homes together in green, yellow, and red. Green meaning great utilization, yellow means moderate utilization, and red is indicating that utilization needs some work. And so what we've asked it to do is group those homes together so then we can see if there is a correlation between those utilization groups and the outcomes that should be impacted by the use of this tool. So you can see here, down below, we have 18 homes that are in that green zone, 14 in yellow, and 13 in red. The next step, we created a prompt that would then allow us to upload outcome data for the agent to go in and see if there's a correlation between the two. So I'm going to upload CareCorp's outcome data, and in a few seconds, it'll add to that table and show us the green group, the yellow group, and the red group's outcome data related to infections. So, as you can see here, very quickly, our green group has the best outcomes with regards to the percentage of long-stay residents with urinary tract infections and the average percent of infections where patients go back to the hospital. And you can see that in this case here, this example, we have shown a correlation between adoption and utilization of our solution and the performance outcomes of those buildings. We're hoping to apply this to obviously more products than just infection control and be able to tell this great story to our customers.</p>
<p>Thanks, Jeff. Great demo. So, to kind of go into a little bit more context as to what we're seeing, to summarize, the AI agent that we created was able to establish the facilities belonging to CareCorp into three categories: red for not-so-great utilization of our IPC product, yellow for moderate utilization, and green for optimal utilization. It was then able to identify trends, and what it saw was that facilities in the green zone, those with optimal utilization of our IPC products, are showing the best results. They have fewer long-stay residents with urinary tract infections and lower percentages of patients returning to the hospital due to infections. So this demonstrates a correlation between the adoption and effective utilization of our solution and the improved performance of these facilities.</p>
<p>It's important to note that we're using AI for correlation, not causation. While we have this information, it's great, but we can't directly tell our customers, "If you use IPC, you'll see a reduction in rehospitalizations." But what we can do is show them the trends within their own facilities that support these better business outcomes and allow them to connect those dots back to the utilization of our PointClickCare products. It's also important to mention that these AI agents aren't meant to replace the work our reps do, but rather empower them to have more meaningful conversations about product utilization and the impact on business outcomes with our customers. Now, if you're in sales or customer success, I know what your question's gonna be: when the heck do I get to try this? And to that, I say stay tuned. We will be sharing more details over the next few weeks. That's all I have for you today. I am so very appreciative of your time. I will open it up for questions.</p>
<h3 id="section-4-4">Copado AI for Software Development Lifecycle</h3>
<p><strong>Ketki Yennemadi:</strong> Next up, we have a very interesting and insightful use case by Lipsa from OCIO on an AI agent called Copado. I'm very curious. Go ahead, Lipsa.</p>
<p><strong>Lipsa Mishra:</strong> This is Lipsa. I'm the senior manager from OCIO. The AI tool is Copado AI, and I'm trying to showcase how using Copado AI, we can streamline our software development lifecycle from requirement intake through our development. We have different processes when we are doing the software development lifecycle. We have planning, building, testing, then we have release, and we have operations. We are trying to showcase how we can use the Copado AI to build different kinds of agents and automate all of them. The Copado AI platform uses five agents: plan, build, test, release, and operate. How can it help accelerate development? And then score quality, reduce technical debt, and then we can have increased team productivity.</p>
<p>I'm going to showcase a little bit about how our automation works right now. So, we have business analysts who take care of our requirement phase. Then they create the stories in Jira. Then we have engineers who write the code, refactor, do the unit testing, and then we deploy them into production. All of this can be done and automated using the Copado pipelines. Let me showcase to you a demo. Special thanks to my teammates Damien and Rob, who have done this demo.</p>
<p>Using Copado AI to extract requirements from multiple meeting transcripts. First of all, in a new chat, I will upload transcript files. Once they're all loaded, we'll include this prompt: "Assume you are a top-performing senior Salesforce Business Analyst. Please analyze the meeting transcripts and extract identified and perceived business requirements for lead management, and use the MoSCoW methodology to provide a clear sentence. Then, produce a matrix showing traceability between business requirements, pain points, use cases, use case scenarios, personas or roles, and then format user stories in well-defined acceptance criteria in the given, when, then format." As you can see, it first provides requirements using the MoSCoW prioritization, and then the traceability matrix: business requirement, the pain point, the use case, the use case scenario, persona or role, the user story, and acceptance criteria for each. As you can see, the business requirement in the traceability matrix is a summarized version of the actual requirement, so lead scoring model implementation must implement a lead scoring model that accurately reflects lead quality and potential value.</p>
<p>Alright, I'll be demoing the Copado AI platform from a Salesforce implementation perspective. I have the chat already generated because it takes quite a bit of time to go through this, but I'll just walk through the features that are highlighted here. So, basically, I gave our agent a prompt to create a user story for us and gave it some of the acceptance criteria here. It's regarding a case that's added and reopening the case status to "in progress" when a comment is added. And if the case has been closed for more than 10 days, then the user cannot add a comment. It wrote out the user story in the format that I asked it, giving some acceptance criteria and provided some technical considerations. Then I switched over to the build agent, which is the agent that can actually code, and I told it to create a trigger on the CaseComment object that satisfies the requirements of the story. I gave it some hints on things that I don't want to see, like debug statements, and there should be some error handling. It thought quite a bit and then it came up with this trigger handler class, which implements our trigger framework, which I asked it to use. It is connected to our Salesforce sandbox instance to pull metadata and read it, and then it will spit out things that are essentially connected to it. It implemented the appropriate methods based on a comment being inserted or updated, and then it had some logic here that will update the status to "reopened" when the comment is added. Then it added the exception handling here, put some debug statements, but obviously it tells us that we can change this to whatever framework we want. Then it implemented the trigger over here, so that's the trigger that says, "before insert, after insert, whatever, run the handler class or run the logic that it previously wrote." And then I asked it to write a test class, which is essentially a unit test for the code that it generated. I told it that it should run as a portal user, so essentially run as a customer to make sure that all the security stuff works, and it should assert that things happen the way that they should. So that's what it did. It created this test class, it has this setup method where it inserts test data, creates the portal user, and then it has the unit test for each different scenario. It has the asserts as well to make sure that the data is as it should after the test has run. Then I switched to the test agent to ask it to create some testing scenarios for manual testing. I told it to include detailed test steps, including the object and field references in Salesforce, including any buttons or the pages that the user needs to go to, so that it's very specific to Salesforce. It generated the positive and negative test cases based on this user story, talking about logging into Salesforce, going to the case tab, and things like that. I have another chat here to just demonstrate the release agent, which is the one that can essentially write release notes for us. It's connected to our Copado instance, which stores all of our stories that are deployed, so I asked it for this release name, "what was released?" and then it checked those user stories and looked at the descriptions and came up with these release notes. Thank you.</p>
<p>I'm going to summarize what my teammates just presented. We saw how we used a plan agent to create our requirements and then create the user stories out of it. We used our build agent to design and create our code with test cases, so there is quality from day one, very faster delivery, really good quality documentation. Then we saw how we can use a test agent to test what we have coded, ensuring our scenarios all included positive scenarios, negative scenarios, and any kind of edge case scenarios, making sure our quality is really good. Then we used our deploy agents to make sure it goes to live. We have release agents which create our release notes. So what I want to say is, AI agents are like our superpower sidekicks. We don't have to go day one and be the AI SDLC (Software Development Life Cycle); no processes. We can go with baby steps. What are the biggest pain points that we have right now? Is it writing the code documentation? Is it the creation of user stories? Is it the creation of your release notes? Maybe start with that. We are just trying to see how we can use all of these different agents to make our life more efficient and make sure that we can focus on solving more difficult problems. Any questions?</p>
<h3 id="section-4-5">AI-Powered Metadata Generator for Data Governance</h3>
<p><strong>Marina Stojanovic:</strong> All right, so we'll put it over to Julia and to Raka. We're looking forward to your use case, and you take it away.</p>
<p><strong>Raka Dhar:</strong> Hi, everyone! Good afternoon. I am Raka, and along with Julia from engineering, Ben, and Tom Zorc, we're excited to walk you through a tool which we have built and named ourselves: an AI-powered metadata generator. Now, it sounds scary, but let me simplify it a bit. Metadata is how your AI knows it's reading patient records and not pizza orders. Think of metadata as the LinkedIn profile for your data: where it's from, what it does, and who to call. Today, we will show you how our tool automates metadata generation, helping streamline governance, boost transparency, and fast-track our organization's AI readiness. This work right now is in the pilot phase. For easier understanding, especially for our non-technical audience, we have shared some key terms and definitions in the chat to follow more comfortably.</p>
<p>Now, fueling trusted AI with governed, metadata-rich data. Metadata is one of the building blocks for data governance. In an AI-driven world, your first step is not modeling or building GenAI; it's cleaning up your data closet. To build any intelligent system, especially an AI-enabled, responsible application, we need a strong foundation that starts with data governance, ensuring data is secure, well-managed, and trustworthy across the organization. You cannot have intelligent, responsible AI without intelligent data governance. Governance is your AI's personal trainer. At the heart of governance is metadata. It provides the context: what your data means, where it came from, who owns it, and how it should be used. To simplify it, think of metadata as the GPS for your data. Without it, your AI is just driving blind. It's like subtitles for your data; it helps everyone understand the story, no matter their role. And remember, if AI is the engine, data governance is the oil. Skip it, and you are heading for a disaster. That's exactly where our tool, the metadata generator, comes in, because even the smartest AI cannot go far without a good GPS.</p>
<p>So far, I have talked about the importance of data governance and metadata. Now, let's look into this slide to see what our tool does. We have built this using Azure-hosted GPT-4 with enterprise authentication, which makes it flexible enough to work not just with SQL-based systems but also with non-SQL data sources. One of the key features of our tool is data lineage. It shows how data flows, transforms, and connects across systems. Think of it as Google Maps for your data pipeline, giving you visibility from source to destination and every stop in between. Now, let's focus on our features. We use AI to automatically generate plain language descriptions for tables, views, and stored procedures. This helps bridge the gap between technical metadata and business understanding. Second, we have visualized data lineage so that users can see how data flows and transforms across systems. We added business context, such as suggested data quality improvements, business term mapping, and PHI (Protected Health Information: Any health-related information that can be linked to a specific individual.) tagging, to make the metadata actually useful. Finally, we offer export options in both JSON (JavaScript Object Notation: A lightweight format for storing and transporting data.) and Markdown, making it easier to integrate with any tools, documentation, or data catalog. And all of these features combined create a highly usable, flexible, and intelligent metadata solution ready for AI governance at scale. Now, my colleague, Julia, will walk you through how our team previously analyzed metadata to establish data lineage, followed by a live demonstration of the tool.</p>
<p><strong>Julia Groza:</strong> Thanks, Raka. So, our team works on a product called Performance Insights, which generates analytics for skilled nursing facilities using complex, data-intensive processes. Now, developers working on this product often need to understand the precise flow of data by tracing the inputs and outputs for each data table or stored procedure. We have high-level documentation of our data flow process, but before having this tool, it used to be unrealistic to have detailed step-by-step documentation for every single object. Mapping this data flow can take a developer up to half a day, costing the company as much as $1,000 each time. So this manual process highlights the need for better tools for metadata and data flow analysis. Now we're going to demo our tool and show how we made that process much easier.</p>
<p>Welcome to the Metadata Generator tool. The first thing that needs to be done when you're working with this tool is you have to be connected to a database. So, I'm connected to one of the databases that we use within our team on Insights. I'm gonna go to the Database Objects tab, and this is where all the action happens. So, I have all of the object types that are available in my database, and there's an option to filter by object type. I'm gonna generate metadata and talk about the descriptions and the data lineage, and how that's being generated within the tool. As that's working, the first thing that's happening is we're getting a plain language description of this object that will give us information on the purpose of the table, business context, any relevant tags that could be used later on in machine learning applications, and other things. The way we're getting this is we're getting all the information about columns, column types, primary keys, foreign keys, indexes, and a little bit of sample data from the testing environment. We're providing that all in a prompt towards the Azure AI service, and we're getting back that metadata description. The second thing that's happening is we're generating a data flow diagram indicating how data is flowing into and out of this object. You'll see that this information was already generated. The way this is working in our tool is we want to find all of the stored procedures, which are kind of these scripts that modify data within tables, and we want to find all those scripts that change, add, or use information in this table. These scripts might also get data from other tables, so we follow all of those connections step-by-step until we build this network of database objects that you see here. This is called data lineage. We also look at it the other way around. Not only do we want to know which data flows into the object that we selected, which is this table here, but we also want to know how the data from this table is being used in other objects. The way the tool is doing this is it reads all of the stored procedures and it finds those source tables and those destination tables and creates those connections.</p>
<p>Let's look through the metadata that was generated. We can see the plain language description, giving a brief overview of the table, some business context on why this is important, those relevant tags I was talking about, some data quality checks, some insights on the lineage, and some data privacy considerations. In this lineage graph, it's a little bit small right now, but I can go back to this metadata browser, which shows us the metadata in a larger context. So this is the same metadata that we just generated. Our selected object is in purple, our source tables are in green, and our destination tables are in red, and our stored procedures or those scripts are in orange. You can see how data is flowing from this table into this table, and how this table is being used in all of these destination tables. You can start to see how this could take a developer a really long time to do, but is super quick with our tool. Now, you might be thinking, how did the tool do this so quickly? How did it read all these stored procedures and all these database objects and get that information? When I first started this application and ran it, there was a background process that was occurring that was reading all of these stored procedure objects and extracting the source and destination tables using AI. We store all of that information in our database. So something really important about this tool is that everything that's AI-generated is then saved in our database. We do this because excessive calls to the AI service can become time-consuming and costly. An AI response is only generated once per object and then it's reused every time thereafter because we can have many people generating metadata descriptions for the same objects, and we don't want to make repeated calls. You can see that that's indicated by this flag here, that this metadata is up-to-date, no regeneration needed. If the database object was updated, this would be warning you that you should probably regenerate the metadata.</p>
<p>Another thing that I want to share is our AI model specifically looks at column names to see if there's any potential PHI in these tables. So, you can see that I selected another table. The metadata description immediately came up because this is also saved in the database; we don't need to generate it again. You can see that we might have potential PHI in the physician first name, middle name, etc., and the user should be aware of this. The second thing I want to show you with this tool is our schema comparison feature. The purpose of this feature is if you're working with multiple database objects and you want to understand the difference between them, whether it be structure-wise or business context-wise, it's helpful to be able to compare them. So, I'm gonna pick two schemas, and when I'm picking two schemas, the tool is finding all of the common objects between them that can be compared, and it's doing this based on naming conventions. As you can see here, these two object names are similar to each other except for that schema name difference. So when I go ahead and compare schemas—this is already saved to the database as well, like I mentioned, we save all the responses in the database—we get a summary of differences on the parameters, the objects used within this particular object, any differences in logic, output columns, as well as some risks and recommendations for working with these two objects. So, overall, this tool is very helpful for developers to get better business context on database objects. It's preparing the data, giving it relevant tags that could be used later on in those machine learning applications. And the most important thing is it's developing that data lineage and showing that data flow, which is imperative when you're building on top of or modifying your data flow transformation.</p>
<p>Based on the database that was demoed in that video, which is specific to our product, Performance Insights, that database has roughly 1,000 database objects. So, this tool has the potential to save 250 to 4,000 hours in developer time and $60,000 to a million dollars in cost savings. And again, this is just for one database for Insights alone. Our goal with this tool is to make this tool available to all engineering teams for their respective databases so everyone can benefit from the same time and cost savings. For our non-engineering teams, we hope we provided another example that you can take away from this symposium on how to break down complex, repetitive workflows and use AI for well-defined steps along the way.</p>
<p>Now, we have several planned enhancements to make this tool even more valuable. The first one is that we want to increase the granularity of that data lineage graph. Right now, it's tracking the data flow across tables, but we want to make it track the data flow across columns. This is going to give developers better visibility into how changes to individual columns can impact the entire system. Next, we want to improve our metadata itself and divide it into business, technical, and operational metadata, so it's more actionable for different types of users. And finally, we want to expand even the reach of this tool beyond databases. We'd love for this tool to be able to document the data flow for any kind of repository that has some kind of data flow, which is a lot of repositories.</p>
<p>When it comes to responsible AI, the most important part of our project is that we're saving every AI-generated result with timestamps, enabling full review and auditability. When we do prompt the Azure AI service, we're creating highly specific, context-rich prompts with standardized inputs and standardized outputs, allowing us to control the generated response as much as we can. But most of the logic in this tool is handled by deterministic code that we as developers can review. So, after completing this project, we have two key takeaways. One is that AI is most effective when you have a strong understanding of what it's generating. It's easy to rely on AI suggestions without grasping the underlying libraries in your code, for example. But we found that reviewing documentation and then guiding the AI ultimately saved us more time than prompting it without sufficient context. And lastly, I keep talking about this point, but we found that AI works best for small, well-defined tasks, because it allows us to maintain control and validate results as we go. So, thank you so much for attending this demo, and thank you to the AI Symposium team for giving us the opportunity to share this with all of you. We can take any other questions that you have.</p>
<p><strong>Marina Stojanovic:</strong> Amazing, Raka and Julia. I do have two Q&A questions that have come in. One of them is how much effort did it take to build this?</p>
<p><strong>Raka Dhar:</strong> Not that much. When we started, I started it on some Saturdays and Sundays, and almost all of the structures were built because we leveraged AI. But the complexity starts when we started including the graph modules and all. Julia, would you like to share those inputs and findings of how we have to learn the modules about the graph and how we improved on that?</p>
<p><strong>Julia Groza:</strong> Yeah, so I kind of mentioned how there are some technologies, like the visualization tool, that use a specific library, and it's valuable to be able to understand that documentation first. There's a little bit of time spent towards that, but once you do understand that, you're able to prompt much more effectively. I would say AI was super helpful and minimized development time significantly.</p>
<p><strong>Marina Stojanovic:</strong> Awesome, appreciate that. Last question is, when will the database metadata generator be available?</p>
<p><strong>Raka Dhar:</strong> We will talk to our director, and then...</p>
<h3 id="section-4-6">Figma and Copilot for UX Design</h3>
<p><strong>Ketki Yennemadi:</strong> Next up, we have Jennifer, Krisika, Maya, and Charlie, the UX team! Excited to hear more about Figma and Copilot.</p>
<p><strong>Jennifer Magana - Product:</strong> Hi, Charlie, Maya, Krisika, and I from User Research and Design are excited to share how we're partnering with AI to help us move faster, spot insights sooner, and make our work more inclusive. Today we're focusing on that early phase of product development, when we're still figuring out what to build. It's what we call product discovery. This phase is often overwhelming. Ideas are slow to form, research findings are shared too late, and collaboration happens, but in silos. That's why we're rethinking how we explore and align. We're learning how to partner with our AI tools we call "Design Pals" to change how we collaborate and build with more confidence. We each give it a role to play.</p>
<p><strong>Maja Madirazza:</strong> Figma AI is our new AI-powered ideation coach. It helps us remix ideas quickly and explore multiple design directions to solve user problems. I recently used it to explore how users could indicate the location of documentation within an assessment. Instead of sketching, I use prompts to generate a design that closely matched what I had in mind. Being the design helped me uncover a new challenge: how might we help users not just select a progress note, but select the right one? So for the next round, I adjusted the prompt to include more context, like who wrote the note, their role, and the date. Then I realized, wouldn't it be better if users could actually preview the entire note before selecting it? I then added a preview feature. Now, when users click preview, the note expands, allowing them to read it fully before linking it. As you can see, Figma AI helped me ideate quickly, think visually, and iterate on the fly, turning one idea into three different variations I could share with the product team. With that, I'll pass it over to Krisika.</p>
<p><strong>Krisika Suthan:</strong> Okay, so now I'll talk about our next design pal, AI as an interaction/prototyping partner. Here is a mock-up. It's helpful for aligning with product, engineers, and even users, but one screen doesn't show the full experience. It's hard to grasp functionality and flow from a static image. Normally, this is where we designers prototype, but often we don't always have the time or clinical context to build something that is realistic. Here is where we use Figma AI. Using Figma AI, I turned this mock-up into a working prototype in just over half an hour. It does not match our Evergreen design system or Core, and that is okay. What it does do is bring the mock-up to life, helping us visualize interaction, workflow, and realistic content scenarios. In our recent exploration, we used this to quickly align with product managers on key ideas. But looking ahead, there is potential to use these prototypes for user testing and end-to-end evaluation of feasibility. Passing it down to Jennifer.</p>
<p><strong>Jennifer Magana - Product:</strong> Thanks, Krisika. Discoverly is an insight translator. It's an AI agent I've customized in Copilot to help me share research findings in real time. Before Discoverly, we talked to customers, highlighted transcripts, summarized key points, created themes and insights, and then presented the findings. Now, we're still talking to customers and highlighting transcripts; that part's not going to change. Think of it like data labeling. Basically, it's helping the AI interpret that data accurately. But now, I can partner with AI to generate those summaries, themes, and insights in a fraction of the time, and instantly share them cross-functionally for real-time collaboration. Now we can make better decisions together. Now on to Charlie.</p>
<p><strong>Charley Yang:</strong> Thanks, Jen. Now, talking about impact, with tools like Figma AI and our custom research Copilot agent Discoverly, we're accelerating discovery and iteration through rapid prototyping, quicker synthesis of research insights, and streamlining collaboration to free up time for more strategic, high-impact design and research. Moving on to our next slide, responsible use of AI. AI tools support our ideas by informing our decisions and helping us do more at a faster and smarter rate. But this is not a substitute for expertise, and it shouldn't replace human insight in decision making. When it comes down to our lessons learned, experimentation is how we learn what works and what doesn't, especially with AI tools. Constant iteration allows us to determine how to move forward and what to scrap, especially as we are vetting these tools within our workflows. Segueing into our next bullet, as AI evolves, so do we. We maintain a constant state of learning and adapting our skills as the tools advance. Finally, how can it help others? There's no one-size-fits-all. Every individual and team can shape their own version of a design pal to fit their needs. If it doesn't work, continue to iterate; otherwise, there's always another tool out there. That concludes our presentation. Thank you all for attending. We'll go ahead and open up the floor to any questions.</p>
<h3 id="section-4-7">Profit: AI-Powered Cloud Cost Forecasting</h3>
<p><strong>Auroosa Kazmi-Ishaq:</strong> All right, I think we can throw it over to Dave from Cloud Financial Operations to talk about Profit.</p>
<p><strong>Dave Chodos:</strong> Great, thanks very much. I'm here to talk about something that we worked on with a tool called Profit, and I'm calling from the Cloud Financial Operations team. Before I get too far into Profit and the cool things that it can do, I thought I would tell you a little bit about what Cloud Financial Operations is. We are part of the SaaS Ops department, so cloud infrastructure, and we support the cloud engineering, finance teams, and a few others, like sales and product. Some of our key concerns have to do with cloud cost visibility, reporting, forecasting—I'll put a pin in that one for later—and alerting. We build various custom tools and systems where needed to make these things happen. Doing all these things, we work on achieving savings at a company-wide level. We look at things like negotiations on contracts and commitment discounts. Essentially what we're trying to help the company understand is, are we spending efficiently in the cloud? Is all this money that we're pouring into the cloud driving value for the business? This little image here has dollars raining out of the cloud. Really, I want to imagine those dollars kind of getting sucked up into the cloud; it's kind of the direction that things tend to go. But what our team does at the end of the day is save PointClickCare millions of dollars in cloud costs, and we ensure that the money that we do spend is effectively supporting our products and our customers. That gives a bit of context for who we are as a team, what we're doing.</p>
<p>Now I want to dive into a particular problem that we've solved, and that has to do with predicting our cloud costs. A lot of what I talked about just now had to do with watching those costs as they've happened and understanding what they were. But we also want to understand what the cost will be going forward. There are two key stakeholders for this. One is engineering, where they have annual budgets that they need to set. It's $40 million in total, so it's certainly not small change, and it's divided into over 100 different items, so there are lots of different moving pieces in this budget-setting effort. Engineering teams and those managers of particular products are definitely interested in ongoing cost tracking as well and understanding not just what we've spent recently, but what we are going to spend, and does that align with expectations and plans? Speaking of financial plans and expectations, we also work closely with finance, particularly the financial planning and analysis team. They are responsible for quarterly forecasts for the business, and one key part of those forecasts is our cloud costs. We help them predict those and inform the rest of the business about what that piece of the puzzle is. Now, all this is well and good, but it's a little harder in the world of the cloud because cloud costs can be variable and hard to understand. They're charged on a daily basis and can change quite a bit based on various factors, like product usage or new technology changes. Sometimes cost models themselves can change. Those costs, as we receive them from the cloud provider, from AWS or from Azure, are not immediately related to things that we care about at PointClickCare. They don't tell us, "Here's how much this product spent," or "Here's how much this budget owner owes to the cloud." It's a large volume of somewhat inscrutable information. So, we needed to come up with a solution to this.</p>
<p>The look on Doc's face indicates that we did. We've got some key components that we were able to bring together to address this challenge. Those three key pieces are invoice data, PointClickCare context, and an AI tool. Bringing these together, we can deliver useful forecasts to stakeholders. The invoice data, there are millions upon millions of entries that we gather each year, telling us how much we spent in the cloud, and each of those entries has several dozen dimensions to it, so it's pretty dense data that we're talking about. As I mentioned, that doesn't immediately tell us what we want to know. So, we bring PointClickCare context into the mix to align all those data entries with meaningful categories, things that matter to us at PointClickCare: our products, our budget owners, cost centers for financial analysis. Finally, there's an AI tool, the reason we're all here today. In this case, we are using a tool called Profit. I'll tell you a little bit more about that in a moment, but essentially, Profit allows us to take historical input and generate forecasts from that. In this case, the input we're feeding into Profit is our past year of invoice data plus that context that I was talking about to help us make sense of the data. The output is a year-long forecast into the future for each of those 100-plus products.</p>
<p>What does this all look like in action? I wanted to tell you a little bit more, first, about this Profit tool that I mentioned. It was developed by the Meta company, Facebook is their main product, and it's an open-source tool, so you're not paying any money for it. It's just freely available. Its main purpose is providing forecasting for time series data, which is essentially data that is organized around time, like days and months. Its key features are that it's quite fast, accurate, and provides automated results, so you don't need to do a lot of complex configuration.</p>
<p>Bringing our data into Profit and coming up with forecasts, we found that those forecasts are highly accurate. We've tracked what the forecasts were against what we actually spent and found that over a 6-month period, the forecasts were within 1% of our actual spend, so they are very much bang on. What we've done then is taken these forecasts, you can kind of see an example on the top right here, brought it into a custom cost tracking system that we've developed, and we can empower better decision making through this combination of detailed cost tracking reports and tools and these Profit-based forecasts.</p>
<p>I want to give you one example of Profit and these forecasts in action. Here's one product that we're tracking the costs for. We can see the blue bars on the left are the costs so far, and then the darker blue line represents the forecast. If you were to just look at the costs so far, you might have the impression that it's pretty steady, we don't need to worry too much about cost growth, we're in good shape. But then if you look at the forecast, you can see that it's actually charted to rise by 25% over the rest of the fiscal year, from around $3,000 a month up to $4,000. In total dollar terms, it's not so much, but from the perspective of this particular product and how it's doing, we want to be able to rein in those costs. If we know that this is where it's headed, we can do that early, rather than finding out midway through September that we wound up spending more than we planned to.</p>
<p>I'll share another example that may seem less dramatic in terms of the direction of the forecast, but it is also quite important. This is our core EHR product, the main thing that we sell. On the left, again, you can see the costs seem somewhat stable. That darker blue forecast line indicates that they are going to rise somewhat over the rest of the year. But I want to draw your attention now to, over on the left, the y-axis is spending. How much money are we talking about? This is one and a half to two million dollars every month. So, when we look at that dark blue trend line and see it sort of creeping up a little over the course of the rest of the fiscal year, that creep represents tens or even hundreds of thousands of dollars every month. If we have some advanced warning of that and are able to get ahead of it, then we can save that money and invest it in other places and not have it just kind of unexpectedly trickle out over the course of each month.</p>
<p>I do want to take a moment now and talk a little bit about the responsible use of AI, because that is a key consideration in anything that we're doing. In this case, I've been talking about how we are using Profit. We got these forecasts, they're accurate, they're helpful, they're wonderful. But I do want to emphasize that they are not set in stone. We don't just take these forecasts and charge ahead blindly with them, saying, "This is what this thing will cost. AI told us. We're done." We present those forecasts to the budget owners using a custom tool, and they can be reviewed by those budget owners and adjusted as necessary. For example, if a particular owner knows that their product is in early availability right now with very little usage, but it's gonna move to limited availability in Q4 and see a jump in mid-September, then they can indicate in the forecast that there will be a corresponding jump in the cost at that point that Profit wouldn't be able to predict because it wouldn't be indicated from the past historical results. Any of those manual changes that are made are kept from one month to the next, so the AI results don't just wipe it out the next time we generate them. What this means is that our forecasts are really a blend of AI and expert human input. The AI results give us a helpful starting point, and then those adjustments from the budget owners, from those product experts, are encouraged where they're needed to make sure that the forecasts are as accurate as possible.</p>
<p>So what has the impact of all this been? How has it helped? I want to look at it on a few different timeframes. From month to month, we have this cost tracking tool that is then improved with the forecast information layered on top. These forecasts are provided on a per-product basis, so for each of those 100 products, we get this tailored forecast. They're updated every month, and budget owners can then compare their actual costs to those forecasts on a month-to-month basis and respond as needed. As I talked about, they can take some of those proactive actions if they see that the forecast is climbing, and they can take action early to rein in those costs.</p>
<p>On a quarterly basis, we provide the financial planning and analysis team with forecasts, and those are then provided to the business as a whole so that they are aware of our cloud costs and what those look like from one quarter to the next. PointClickCare leadership can take that information and adjust investments across the business to reflect shifting costs and priorities. For example, if there was some large project that we thought was going to cost $500,000 in Q3, and we got to the end of the second quarter and realized that things have changed and it's actually only going to cost $200,000, then the business can be aware that we have $300,000 extra that we didn't think was going to be present, and we can invest that in other places that will better serve the business. That's from one quarter to the next. And then on an annual basis, we've greatly simplified the budgeting process for all of our engineering teams. This saves about 60 engineering teams weeks of effort at annual budget time, where they don't have to start from scratch. They can start with this AI-powered budget beginning and then layer in their own knowledge of what's happening with their product at key deployment points and essentially provide that AI and human expert blend of their budget with the most accurate information that we have. Finally, we can look even longer term than one year to the next. We can look two, three, five years down the road and help identify some long-term trends that, if we're aware of them, we know what might be coming up down the road, and we can execute early intervention to avoid rising costs or large problems.</p>
<p>I want to end with this idea of, well, what's in it for me? If you're in an engineering or a finance role, hopefully, this answer is obvious. All of the above, all the things we've talked about—the budgeting, the cost tracking, the forecasting—all of these capabilities and tools are baked into this custom dashboard and cost framework that I talked about. It is all there for you to use. Ask me if you have any questions. If you're not in one of those teams, and this is all kind of new and unfamiliar, I want to encourage you to really think about how this could apply to the data and the challenges that you have in your role. The tool is really quite widely applicable. I've been talking about it in a cloud cost context because that's the world that I'm in, but really, it's applicable to any situation where you have historical data and you want to understand what trends it's indicating. With this tool, historical data goes in, forecasts come out, and we can work with your context, with your problem area, with your particular concerns, and bring the capabilities of Profit to bear on the challenges that you might have. A few examples I want to talk about. In the cloud and cloud finance world, we have long-term contracts with our cloud providers, with Azure, for example, where we have a long-term contract to get significant savings in certain areas in exchange for a spending commitment in that cloud area. To go into that contract, we needed to have a firm idea of what our long-term spending was going to be, and this Profit tool was able to help us develop that understanding and track it as we've gone through this contract from one year to the next.</p>
<h3 id="section-4-8">GitHub Copilot for Platform Modernization</h3>
<p><strong>Auroosa Kazmi-Ishaq:</strong> For our next use case, we have Pawandeep and Victor from Engineering on GitHub Copilot. Over to the two of you!</p>
<p><strong>Pawandeep Kaur:</strong> Good afternoon, everyone. Thanks for joining us. My name is Pawandeep, and I'm here with Victor from the Engineering Department under Tom Andraca. Today, we'd like to share what our team has been working on and some of the lessons we learned along the way. In March 2023, PointClickCare acquired Patient Pattern as a strategic investment to advance value-based care and better drive patient outcomes. Following the early access launch in April 2024, stewardship of the product transitioned to our engineering team, who brought strong expertise in Java and related technologies. It became clear that while the product offered substantial potential, it also presented several unforeseen challenges that required careful attention moving forward.</p>
<p>From the outset, we recognized there were significant challenges hidden beneath the surface. The system had become complex over time with quick fixes, workarounds, and evolution from PCC standards, making improvements slow and unpredictable. The front end, inspired by the Patient Pattern theme, lacked PCC co-design styles, resulting in an inconsistent user experience. While learning a new language like Python and Django wasn't a challenge, adapting to the way frameworks were implemented created extra hurdles for us. Routine changes started to require significant efforts and often impacted our performance, reliability, and scalability, making it clear that we needed a more scalable, unified foundation to deliver improvements faster and more confidently. That's when we decided to try something different and bring AI into our transformation journey.</p>
<p>With just two engineers, we rebuilt the platform in three focus phases, all powered by AI. First, we used GitHub Copilot and SonarCloud to untangle the maze, mapping workflows, doing class-by-class comparisons, and building test-driven blueprints. This let everyone, engineers and business folks, get streamlined. Next, we put up those blueprints and put AI to work, migrating key modules from Python to Java, modernizing the front end with React (React: A JavaScript library for building user interfaces, particularly for single-page applications.), and connecting it all with Mermaid diagrams so we could catch issues early. In just one week, we had a working prototype. Finally, we polished the product, iterating on performance gains and catching security vulnerabilities. Beyond the speed, what stood out most was the clarity and assurance AI brought to our design and how it was making our decisions very impactful.</p>
<p>So what did this transformation mean for our team and our users? First, this transformation could reduce development effort from what was once estimated at 400 engineering hours to just 20, allowing us to deliver value to customers weeks sooner. With improvement testing and streamlined workflows, we can lower support needs and could strengthen user trust. Our system could handle twice the workload on the same hardware without degrading the expected latency. We were able to automate 30% of repetitive tasks, which was one of our greatest wins. These benefits are based on measurable gains we saw in our pilot version, demonstrating what's possible as we scale these improvements.</p>
<p>Looking back, a few lessons really stand out. First, mapping out our workflows made a huge difference. It turned uncertainty into clarity. Second, AI is a powerful tool for speed and scale, but it's the expertise of our people that ensures quality. And finally, quick wins matter. Every small success builds momentum and helps teams stay engaged. This approach isn't unique to our journey. Any PCC team can take these steps: make work visible, combine AI with human judgment, and keep moving forward. With this, I'll hand it over to my colleague, who will walk us through a live demo of what this transformation looks like in action.</p>
<p><strong>Victor Tarnovski:</strong> Hello, everyone. Today I'll be going over a live demo of our new React.js application and a Spring Boot application. But first, I'll be going over our old application quickly. Our old application has served our clients' needs for a long time. However, as Pawandeep mentioned, our clients' needs are outsizing our framework and our application as it is. That's why we decided to create a new application in React.js and Spring Boot. Even just navigating through the pages, for example, switching tabs, it takes a while to load since Django only supports server-side rendering. So, we can do better than this. That's why we decided to create our React.js application. As you can see, it's using our Evergreen styling, which will fit much better with the PCC ecosystem as a whole, and it'll just be a much more consistent user experience. As well, as I mentioned with the rendering, React.js allows us to use some client-side rendering, which will allow us to, like, look how quickly we can change tabs. Instant tab changes, from completed to upcoming. We can instantly open the resident's information up. We can create new certifications right away. Searching is also just much quicker, and I think our users will be delighted with this. I think that this will save them a very big chunk of time, and they'll be happy with it. Hopefully as happy as I am with it.</p>
<p>Onto the responsible use of AI. For our project, and a lot of projects that have been demoed today, we've kind of shown that we can develop so much faster with these AI tools. But we need to be careful. We need to definitely spend the time we gained from generating our code on architecture, on making quality, fast designs, making secure designs. We really need to hammer down on this to ensure we're not making bloated AI code with thousands of security vulnerabilities and performance issues. We don't want that; we want quality code. That was definitely one of our biggest time spends, was the designing of the actual application. And then finally, we need to be careful about the AI tools we use. Even if this means that we can't use tools as soon as they're released, we do need to do our due diligence to make sure that we're not leaking any proprietary code or any information. With this, I'd like to pass it off to any questions.</p>
<p><strong>Marina Stojanovic:</strong> Thank you, Pawandeep and Victor. I just saw one question come through. What coding assistant do you use? Is it GitHub Copilot?</p>
<p><strong>Victor Tarnovski:</strong> Yes, so we're using Copilot. To my knowledge, this is the most powerful one we have that is approved by security.</p>
<h3 id="section-4-9">Security Program Assistant with Azure GPT</h3>
<p><strong>Auroosa Kazmi-Ishaq:</strong> We're gonna segue directly to Eric. This is Eric and Arush, who'll be on video from Product Marketing and Product on Azure GPT. Over to you guys.</p>
<p><strong>Erik Stabile:</strong> Great. My name is Erik Stabile, I'm a Product Marketing Manager, and today I'll be presenting on the Security Program Assistant on behalf of myself and Arush Sharma, Senior Product Manager. Together, in part with Rafat Rajudin, we used Copilot Studios to tackle a challenge that we faced during the rollout of our new security enhancements for PointClickCare customers.</p>
<p>When we launched our latest round of security enhancements, we were flooded with questions from internal support teams, customer success managers, and customers. But the answers were often complex and specific. They were scattered across multiple resources, making it difficult for teams to find consistent, timely information, slowing down response times and increasing support overhead. To solve this problem, we introduced an AI-powered agent embedded directly in Microsoft Teams and trained on all of our relevant customer-facing content. Now, instead of digging through lengthy FAQs, guides, and slide decks, team members could simply ask the AI and receive context-aware responses. This reduced response times, improved consistency, and freed staff to focus on higher-value work.</p>
<p>Since launch, the agent has powered 150-plus sessions with a 75% engagement rate and a 4 out of 5 satisfaction score among internal users. During live office hours, which we host weekly to answer customer questions around MFA (Multi-Factor Authentication: A security process that requires users to provide two or more verification factors to gain access.), it's empowered a panelist to answer roughly one question per minute in real time, boosting productivity and reducing friction for customers. And of course, to be responsible, we added a disclaimer reminding users to verify AI-generated content for accuracy, keeping our standards high while moving fast. With that, I'm going to pass this off to Arush for our demo.</p>
<p>Let's take a behind-the-scenes look at how you can create an agent for your use case. At the top of the screen, you'll find the section where you can enter a description and define the purpose or objective of your agent. Next, define the instructions for the security program assistant. Remember, the more specific your instructions are, the more accurate the agent's responses will be. You can turn on generative orchestration. This enables the agent to use generative AI to decide how it responds, making conversations more natural and fluid for the user. Within Copilot Studio, knowledge sources work alongside generative answers. When you add a knowledge source, your agent can tap into enterprise data, whether it's from internal systems, public websites, or external platforms. You can simply drag and drop a file or choose from the data sources listed below. In this setup, we've added SharePoint, along with customer-facing documentation and help files. And just recently, they released a new feature that lets you integrate SFTP servers too. Tools in a co-pilot agent allow your agent to take action beyond just answering questions. They can trigger workflows, call APIs, query databases, or even perform tasks like resetting passwords or updating records, all based on user input. Think of tools as the hands of your agent, while the generative AI is the brain. Together, they make the agent not just conversational, but truly functional. Agents can work together by connecting with other agents. This means your primary agent can delegate specific parts of a workflow to another agent that's dedicated to handling those steps. It's a powerful way to break down complex processes, keep things modular, and ensure each agent focuses on what it does best while still delivering a seamless experience to the user. Once your agent is ready, you can publish it directly to Microsoft Teams. This makes the agent easily accessible to users within your organization, right where they already collaborate and communicate. It appears just like a regular Teams app. It's a fast way to bring automation and support directly into daily work conversations.</p>
<p>This agent isn't just about saving time; it's about reclaiming our attention for the work that matters most—the problems that don't have obvious answers. If you've ever thought, "Someone should automate this searching," or "There's got to be a smarter way," then take this as your sign. You're the someone. Build the agent you wish you had. All right, thank you. Any questions? I'm happy to take those offline as well.</p>
<p><strong>Marina Stojanovic:</strong> I do see one question in the Q&A. Is this live, or is it in POC?</p>
<p><strong>Erik Stabile:</strong> This is live. We've been using this for almost a month now, and we actively use it on a weekly basis, especially during our weekly customer Q&A sessions.</p>
<h3 id="section-4-10">Pharmacy GPT: A Data-Focused Co-pilot Agent</h3>
<p><strong>Auroosa Kazmi-Ishaq:</strong> Our next use case is from Syed, Jordan, and Rubin from Technical Services and Customer Support on a data-focused co-pilot agent that they built. Over to you three.</p>
<p><strong>Syed Hasan:</strong> Good afternoon, everybody. I'm joined today by Jordan and Rubin. Along with myself, we also wanted to give a quick shout-out to Rhea and Ashley from Technical Services, who helped us put this agent together. What we've built here is called Pharmacy GPT. It's a co-pilot agent. The reason we decided to work on this is PointClickCare's product portfolio is ever-increasing. New products are coming in, more and more complex. As that happens, we need to ensure that everybody across the board that is customer-facing has expert-level knowledge available to them. We picked up Pharmacy Connect, a product a lot of us have heard about, and that's what we targeted here. So this is an AI agent that's baked into Microsoft Teams. As an agent, anyone who has access can start an instant chat with it. It is trained on the Pharmacy Connect feature set, and it really acts as a knowledge expert, making knowledge available to everybody at their fingertips. It can be used for just learning about the product to understand how it works, as well as a troubleshooting resource. Before we get into much more detail, I'll hand it over to Ruben to go over some high-level architecture.</p>
<p><strong>Ruben Vieira:</strong> Thanks, Syed. I've been working on several AI agents and initiatives within customer support, and I recently had the chance to collaborate with Syed and the team to build Pharmacy GPT. Let's walk through, at a really high level, how Pharmacy GPT works under the hood. It really starts with part one, with the co-pilot agent owners. These are the people who build and update the knowledge that powers the agent. While I built most of the infrastructure of the agent, the major work here is from Syed and the team to make sure that we're feeding it quality content. That was a monumental task for this agent. Once that knowledge is curated and put together, that then gets placed into SharePoint. From SharePoint, it goes into Cognitive Search, which is the index. That's what allows the agent to very quickly find relevant articles that are going to help generate the answer that the user's looking for. That's really part one. Part two is simply the end user, who we've shared Pharmacy GPT with, asking questions and interacting with it to get what they need. That's where they go into Pharmacy GPT, ask the question. That question gets sent to OpenAI to then interpret what the user's asking and what the intent is. That then gets matched to relevant content in the index where we've indexed all the knowledge articles to then find the most relevant articles that it can build its answer from. That then gets sent right back to the user very quickly, pretty much in real time. So that's it at a very high level. I hope this gives you all a clear idea of how maybe you can implement something similar. Back to you, Syed.</p>
<p><strong>Syed Hasan:</strong> As Ruben mentioned, agents are really only as good as what you train them with. So we had to really figure out a quick way of generating documentation that everybody loves. Documentation is the bane of everyone's existence here. So we did unlock a path here to quick, detailed, and accurate documentation. Essentially, what we are doing is, for every release, we identify our deliverables, and we pick each feature, do a quick 15 to 30-minute transcript on that feature. Generally, you would find yourself being able to talk through something in 15 minutes that would take you five hours to type. We go for our transcript, then we feed the transcript back into Copilot and build detailed documentation out of it. Going from feature intent to feature logic to marketing and sales talk tracks, to internal and external training checklists, course outlines, whatever the case may be, we can actually get that in a matter of minutes using Copilot. When I talk about detailed documentation, I mean detailed documentation. These are 10 to 15 to 20-page documents on a single feature. It's very detailed and complete documentation. We then go and update our data dictionary. We had to build data dictionaries because while you may have heard a lot today that your responses are only as good as the prompt, we kind of wanted to make that process a little bit easier for people so that people can talk to it in a human way. We have built data dictionaries where we have documented abbreviations or similar terms that people may use to refer to certain things. A quick example would be a facility. Depending on which side of the market you're dealing with, they may be called skilled nursing facilities, or assisted living facilities, or they may simply be called homes. We built these data dictionaries, so we update them if they are needed, and then we go ahead and train Pharmacy GPT with that same documentation and test it. Really, all we're doing here is we're using AI to generate content to feed back to the AI. That's really the process here. This is just one of the many documents that we've created. You can see this is an 11-page document, a monster of a document with tons of details captured in here, extremely knowledge-rich. 95% of what you see on my screen is all Copilot-generated. We've got a bunch of these documents that we've been creating, so if anybody needs any help with how we're doing this, feel free to reach out, and we'll be more than happy to help.</p>
<p>As we are data-focused, the big thing for us was, how do we become responsible with our use of AI? Well, number one, again, AI can hallucinate, so one of the things we've done is all of our responses will always cite the source materials that it's using, so that if it may have hallucinated, you always have access to the actual source data and you can just pull it up and read through the document. This kind of unlocks a weird use case as well. If anyone's gone into Confluence, it's a disaster trying to find what you're looking for. You can kind of just use the agent and say, "Hey, can you just point me to any documentation about this topic?" and it'll just spit out the most relevant, most recent information that the agent has been fed on. Second thing is, when you look at very detailed documentation about how the logic works, you really have to make sure that your AI understands it. We also unlocked a really neat use case over here to validate our documentation to ensure that our AI is reading it properly. So I'll give you an example here. Once we build this document, we actually just ask Copilot, "Hey, build me a flowchart of what this entire logic looks like," and it kind of builds it out for you, and we kind of use this to validate our own documentation. In this specific example, we saw that it connected the wrong dot right here. So we knew that, okay, let's just go back to the documentation and make that change. "Hey, did these two functionalities you connected a dot on? They're mutually exclusive, they're not related, they don't interact." So we went in, so we can quickly validate documentation within a few seconds, go and update that, and then we ask it to do the exact same thing, and now you see a very different type of flowchart. This allows us to very quickly validate our knowledge sources to make sure that it is, in fact, understanding it correctly, and that it will give the right types of responses to users. I will now pass it over to Jordan to do a quick demo on this.</p>
<p><strong>Jordan Bowman:</strong> As mentioned, you first have to be granted access to Pharmacy GPT. Once you have it, it'll be similar to being invited to a Teams chat. Once you have access there, you just have to go within Teams to the Copilot section and then go on to the right to the list of agents and Pharmacy GPT. You can then chat away with it, and there are also the previous conversations you have in the bottom right window. This is very useful for maybe getting back to something that you had from the previous day or sharing information that you've learned from it with someone else. Now, let's talk about the different kinds of conversations that you can have with Pharmacy GPT. Maybe you're new to Pharmacy Connect and you're just learning it, maybe you just need to brush up on a specific topic, or you're just having a memory lapse or something. Since it's trained on all of the feature sets and functionality of Pharmacy Connect, you can just ask it to describe that to you, as we can see in the example on the left there, asking about a specific feature. Of course, since this is a conversation, you can then drill down, get more granular with it, and ask it follow-up questions or to elaborate on certain things.</p>
<p>Now, perhaps you are familiar with functionality, and you're in a more customer-facing role, and the client is having issues with the problem, or you're helping somebody else that's dealing with an issue with Pharmacy Connect. It can be used to get ideas on how to proceed with basic troubleshooting steps. On the example on the right, we presented a basic problem and we asked for suggestions on how to proceed, and it's able to provide next steps to give us a launching point, at least point you in the right direction. Now, we can even take things one step further, and while it's a bit experimental, it can actually be leveraged to perform a highly technical analysis that historically only a few subject matter experts could identify and resolve. In this next example, we actually fed it a segment from a pharmacy HL7 (HL7 (Health Level Seven): A set of international standards for transfer of clinical and administrative data between software applications.) message that was populating an order in a way that was incorrect. We weren't expecting it to. It was actually able to analyze that and identify the issue and explain the problem in a very digestible format. It sort of allows anyone to talk with your clients or others like you're an expert. It makes troubleshooting issues with Pharmacy Connect far more accessible to everyone else, and it helps alleviate that bottleneck we were seeing where only a few subject matter experts could help with. You can also see at the very bottom there, as I had mentioned, it lists the source documentation that it pulled from. If it was pulling from multiple sources, there'd be multiple documents there, and you could just follow that back to actually learn from the source material or verify the information that it's giving to you. These are just a couple of ways that you can use Pharmacy GPT, and we're really excited to figure out all the other ways that people are going to be using it. It's already being used by several teams now, and we've been receiving some great feedback so far. We hope that this will continue to help everyone learn, troubleshoot, and develop their own skills with Pharmacy Connect. Thank you very much, everyone, for listening. We'd like to open the floor to questions.</p>
<p><strong>Marina Stojanovic:</strong> Great job, everyone. I do have two questions for you. Do you need to retrain as we develop new workflows in Pharmacy Connect?</p>
<p><strong>Syed Hasan:</strong> Yes. That involves going back through and doing that documentation update. We're hoping that we can establish good communication from the various teams where our product will go through, they'll give us documentation, and then we can use that method that Syed talked about earlier, update existing documentation, or just plug in those new documents into the SharePoint to update everything.</p>
<h3 id="section-4-11">Pulse Implementation Clinical Metrics Analysis</h3>
<p><strong>Ketki Yennemadi:</strong> I believe I'm the next presenter. This is Kate.</p>
<p><strong>Kate Kaplya:</strong> Good afternoon, everyone. My name is Kate Kaplya, and I'm an implementation consultant with the pharmacy and integrated medication management team. My presentation today will be focused on leveraging the Microsoft 365 Copilot app to analyze Pulse implementation clinical metrics for facilities implementing PointClickCare solutions. This use case is currently in the pilot stage, and previously it's been reviewed with the consultant team, as well as I've used it on my own projects.</p>
<p>As part of the project lifecycle, consultants are preparing a post-implementation metrics Excel dashboard using the data pulled from the production self-service portal. Typically, this is done over a 4-week period, where we meet with customers to review and discuss the current health status of their database and to identify improvements. Consultants spend time not only generating reports but also validating the data in advance to create action plans. This idea came to me back in February during a cross-functional project manager and consultant onsite where we discussed how AI can be incorporated into the implementation lifecycle. I found that I frequently spend a lot of time reviewing the metrics report, developing personalized recommendations, and preparing for monitoring calls. Today, I would like to show you how Copilot can be leveraged to extract performance indicators and generate tailored action plans from the metrics report.</p>
<p>For the demonstration, I'm using a pre-built test clinical dashboard containing data for two facilities. The dashboard contains five different clinical workflows, which in turn contain multiple metrics listed on the left, displaying data over 4 weeks. One thing to note about the dashboard is that it contains macro elements, which Copilot is unable to analyze, so it must be converted to a regular Excel workbook before running the analysis. The demo will review how to transform a prepared metrics report into meaningful, facility-specific improvement strategies, enhancing care quality, compliance, and operational efficiency.</p>
<p>For the purpose of this demonstration, I've already entered my prompt and I've already attached the workbook. You can save your prompt or you can type out your prompt. Under "View Prompts" within your chat, you can look at the prompt gallery, and I've saved my prompt under "Your Prompts." In this prompt, I've outlined some details about the request. I've asked Copilot to develop an action plan for each clinical workflow, separated by facility with specific focus areas, next steps, and recommended support, how-to, quick reference guides, and other resources. I asked Copilot to look into PointClickCare OneDrive, SharePoint sites, and other workspaces. This report and this analysis is based on the Pulse Implementation Monitoring Metrics document that I'm attaching. I've also asked it to highlight promising trends for each workflow, including multiple metrics, and also separating by facility. I've already sent my prompt and included my document in here. I can go ahead and just remove the prompt because I've already sent it, and then I'll be able to review the analysis generated by Copilot.</p>
<p>Down here, Copilot analyzed the report that was uploaded and provided me with the following information. It included the details per facility, and it also split it up into different workflows. It's outlining promising trends as requested, any focus areas—so any areas that I've noticed maybe the numbers are higher in, or maybe there are uncleared items as outlined in here. Any next steps, as well as recommended resources. As we can see, it's separating by those workflows, so we have interdisciplinary admission, medication management dashboards, orders portal, any focus areas, and then medication management pharmacy orders portal, and that was for my first facility. And then I have the same information for that second facility: promising trends, focus areas, next steps, and recommended resources. We can scroll down and review all of that information that was outlined per facility. It asked me if I want to generate a formatted document or if I want to create a slide deck. As you can see, this analysis allows consultants to prepare for the metrics review call and to discuss what the facility can improve on, or maybe to highlight any areas where a facility has been doing well or where a facility has been improving. All of the information was already generated by Copilot, and it also included some recommended resources, any required next steps, so any actions that the facility should be taking. That information can also be shared with the facility on the call and can be included in a follow-up email or further conversation with the facility.</p>
<p>You can also request Copilot to summarize key points for a high-level overview or to request a more detailed breakdown for a specific workflow. On this slide, I included a quick visual of the input versus analysis. On the left, we have the clinical dashboard metrics data, and then on the right, we have the tailored action plan generated by Copilot. So why is this use case important? In terms of impact, we're looking at increased consultant efficiency when preparing post-go-live recommendations. Consultants can reclaim time, saving up to 20% of an 8-hour workday when preparing metrics for four facilities daily. We also have standardized improvement planning across facilities, allowing for continuous workflow optimization. And last but not least, this empowers the implementation team with actionable insights and direct access to support materials, leading to increased productivity and the capacity to process three times more facilities in the same amount of time.</p>
<p>In terms of lessons learned, you do want to make sure to use very specific and detailed prompts outlining what information to analyze, including, but not limited to, facility and workflow names or specific metrics. Linking metrics to resources was also identified as an area of improvement, as Copilot was unable to extract resources directly stored within the customer support portal. For example, it is possible to pull in SmartZone eCourses, however, that information was only pulled from the documents that were found in shared workspaces. It also may pull personal cloud files and email attachments from my experience. Resources and recommendations need detailed review to confirm that they apply to the facility-specific workflows. For example, you want to take into account differences between a skilled nursing facility versus an assisted living facility.</p>
<p>How it can help others at PointClickCare: by linking metrics to specific how-to guides and resources, AI acts as a dynamic navigator, bridging data and resources, which in turn reduces training gaps and improves adoption. Different prompts can be utilized to access training resources and recommendations for learning and development in customer support teams. It also accelerates post-go-live monitoring, so Copilot can automate that first layer of post-go-live review, flagging trends and surfacing support materials. This model can be replicated across other workflows, such as billing for implementation, customer success, and account management teams. For responsible use of AI, you do want to make sure to validate the recommendations against facility-specific nuances. So you want to approve, edit, or annotate the plan before actually sharing it with the facility. You also want to review the reference sources to check for PHI or project data, specifically focusing on items that are used by Copilot to generate recommendations and supporting materials. And finally, you want to refine your AI prompts or adjust your metric thresholds based on the generated responses, as risk thresholds may vary from project to project. In conclusion, this use case allows us to reduce the amount of time spent on analyzing metrics to prepare for monitoring sessions, freeing up time for strategic outreach. It also shows how AI can transform raw post-implementation data into actionable insights, enabling teams to make faster evidence-based decisions without manual analysis, which ensures more efficient reviews, improved care outcomes, and a future-ready approach to continuous improvement. I will now open the floor for any questions.</p>
<h2 id="section-5">V. Panel Discussion: The Future of AI in Healthcare</h2>
<p><strong>Auroosa Kazmi-Ishaq:</strong> I have a series of questions for the panelists. My first question, and this question is for Rahim and Jared: What new AI tools or technologies are you most excited about, and why?</p>
<p><strong>Rahim Hashwani:</strong> Happy to start. First, thanks for having us. I've seen some great, inspiring demos, and I'm eager to see how today's gonna help accelerate our AI story. Getting back to your question, there are two technologies that I'm personally excited about. The first is AI video generation and content generation. I dabbled in digital animation ages ago, so that's always been an area of interest for me. But the stuff that can be generated now with just a two-dimensional picture, an audio clip, and maybe a prompt is just incredible. Besides the nefarious deepfake stuff, some of the actual creative digital content is just going to rival, if it isn't already, some of the studios. So I'm really looking forward to seeing what happens with that. The other area that has a ton of practical application for us is autonomous AI agents. Agents that can consume inputs and data, and then plan, reason, and act autonomously across our digital environments. They're becoming more and more capable, and that's a tremendous opportunity for us to harvest and automate the mundane, or even eliminate it. An autonomous customer or employee-facing agent that can research an issue and not only recommend a solution but actually handle workflows or write code to implement the solution with human guidance and guardrails—you have to have the human in the loop—but we could do so much more with the same resources. We're actually investigating and experimenting with that in TSS using Copilot Studio and ServiceNow.</p>
<p><strong>Jared Pilcher:</strong> What I'm most excited about is actually AI for coding, agentic development. I think there's a lot of opportunity there for us as humans to grow with, and for us as a company to accelerate with. There's so much, I think, that we forget as engineers—problems we can be solving. Focusing more on a strategic, higher level can really help us. Producing code faster is going to be an exciting opportunity to solve more problems, more challenges. I see a time when we'll be able to drastically speed up our development so much that the number one question is how do we align better with it? I think that's gonna be a key focus, and something that we're all going to have to put our heads together and figure out together. But I am so stoked and excited for agentic development. I think it presents a lot of opportunity not only to help our company, but industry-wide, we're gonna see a lot of great new products and challenges being fixed and addressed.</p>
<p><strong>Cedric Anne:</strong> Before you get to the next question, so that it doesn't seem like this is very Copilot-generated, I think that's the cool thing around doing an AI symposium—you can actually challenge the AI, because that's what we do as humans. To just put a quote between all the things that Rahim and Jared were mentioning, I think the one thing we need to all think about and live in is there's going to be a shift in human potential, as exactly as other things have done in the history of humankind. There has been a shift, and we expect it to continue to be the case. The sooner we accept it, the sooner we work with it, the sooner we put it as part of our strategy, our relationship, how we care, the better the outcome.</p>
<p><strong>Auroosa Kazmi-Ishaq:</strong> My next question is actually for you and Jared. How do you envision AI transforming internal operations and productivity in the next 5 years?</p>
<p><strong>Cedric Anne:</strong> When we look back, in the next 5 years, we'll go back and see how this decade, essentially, the work will be redefined. How we define work is in the process of getting redefined. AI becoming a native part of how work happens, and not just enabling or helping us with certain things, but embedded into what we do. Similar to how Excel is de facto when we need to do spreadsheets, AI becomes embedded with all the things we do. A cool example I use to illustrate that is you actually don't go to a dashboard to see what is going on; the dashboard comes to you. When we realize that, that's going to be the transformation that, over time, we'll see embedded in all the things we do. It's not going to replace what we do; I think it's more so going to release us from the grind. Grinding in terms of sending meeting notes, which is something now that can absolutely be done that much more efficiently, duplication of work, putting entries in two systems—like NetSuite and Salesforce. That's the kind of thing that we should expect in the next 5 years to be things from the past. We're always going to do migration of work, but the migrations become that much more intuitive and not just feel like grinding. Muscle memory, I think, is something that's gonna be one of the challenges. The things we do as muscle memory, when you add AI on top of it, in the next 5 years, things will look a lot more seamless, a lot more contextual, but at the same time, you'll feel certain things become invisible. Let's just be ready, accepting, and welcoming this kind of change.</p>
<p><strong>Jared Pilcher:</strong> For me, this is an interesting question. At the beginning of this year, I thought that we wouldn't be giving agentic software development any serious thought until maybe next year. Then, when I saw Claude 4 come out, and Gemini 2.5, and how well they developed, I was really quite shocked. I think that we are entering this much faster than we expected, and as software developers, we just need to hang on, because we're about to see some sharp changes really fast. But don't be afraid of it. Ride the wave, and let's figure it out together. The underlying goal is to speed up our productivity. I see that time and again with the conversations I've had with our VPs. It's a focus on trying to improve our productivity. The one thing that I really want AI to do, that I think is not talked about enough, is it prompting us and improving our communication among each other. That's something that really most organizations suffer with—communication issues. It also needs to challenge us so that we understand what we know and what we don't know, and all potential avenues we could take. That's what I expect AI, in an abstract way, to do for us. I just don't know yet how it'll be applied.</p>
<p><strong>Auroosa Kazmi-Ishaq:</strong> This question is for Lisa, Jared, and Cedric. How can teams foster a culture of innovation and openness to AI technologies?</p>
<p><strong>Lisa Jarrett:</strong> I'll start. What has worked in multiple organizations in which I've done AI is when you're looking at a problem to solve or something to do with coding that needs to be done, ask first, "What can AI do?" Go to that first as your starting point. Or if it can't do all of it, can it do part of it? And then ask, "Should AI do it?" Because not everything has to be AI. Are other approaches better suited, like rules-based? And then just try, try, try with rapid experimentation. Some of that's a mindset, some of that's a behavior change. Another part of a practice that I've done and I see a lot of other people doing, which is very beneficial, is just set aside part of a day, like 15 minutes, or an hour a week, and just read, read, read. Set yourself a challenge, and then go after it personally, and then see how you can accelerate that across the team, looking at it from multiple different dimensions.</p>
<p><strong>Cedric Anne:</strong> I'll go next. When I think about it, I'll probably share the leadership view. I think it starts with permission for teams to experiment, to be curious. The big things that have happened through life just happen in small ways, and then they just grow bigger. When I think about one of my teams and how this thought of putting a culture of innovation came about, we brought a team into tech services a couple of months ago, and the one thing we asked this team to think about is, "What would you automate or do differently with automation in all the things you do?" And then we got a slew of ideas and tried many of them. The ones that were defined as being that much better and had a breakthrough, they are, today, automated or are becoming an agent or something along those lines. The results are incredible if we give the permission to experiment. For us leaders, normalizing that approach is very important, and making sure that we're also rewarding when there are great new things coming out, and favoring that over perfection, I think, is the important piece. As an organization, we should feel empowered to say, "Yeah, go and build it." That's a change in the approach that I have taken, and I hope others are following the path because I think that's going to be super impactful for our teams.</p>
<p><strong>Jared Pilcher:</strong> I love that we already have a great culture of sharing what we do and being vulnerable and being open to learning. We have started an AI community of practice a couple of years ago that's still continuing. We'll send the link to the channel. Please join us, and let's continue the conversation. We're trying to bring those conversations and general AI conversations throughout engineering, especially, into this set of channels, so please join us. I think one thing, too, is focusing on learning not only how we can apply these large language models but also how they work under the hood. That is a very important thing for us all to learn, at least at some level. We need to understand that in order to understand what its limitations are and what we're missing in terms of what it can predict for us, what it can do to help us. With some tweaks, what else can we achieve? What have we not thought of? So, continue learning and joining these communities that we find. Let's talk and keep the conversation going.</p>
<p><strong>Auroosa Kazmi-Ishaq:</strong> This question is for Lisa, Dean, and Rahim. In what ways do you think AI will disrupt or enhance the healthcare industry as a whole?</p>
<p><strong>Dean Slawson:</strong> I can start. I mean, I would focus on how we at PointClickCare will disrupt the healthcare industry with AI and our products. One area that we're working on is addressing what I call the "caregiver deficit." One of our most precious resources is our caregivers' time and attention. There's never enough to go around, whether that's due to the shortage of caregivers or just too many distractions, too much information. The quality of care suffers, and the experience of caregivers suffers; they burn out, which makes things worse. It's kind of a vicious cycle. We're disrupting that by using AI in our products to really make a transformational improvement in productivity and efficiency. For example, right now we're using AI to summarize and surface the most critical information from unstructured data for a variety of use cases, like our work on the AI assistant. For acute and payer, we have the "reasons for transfer" model. Those are both moving forward, but that's just really scratching the surface of what we can do. Alerts could be so much smarter with AI, reducing alert fatigue. A lot of tasks can be automated. We're working on AI to make the MDS nurse role, like, 10 times more efficient. Imagine taking a role that has a fully loaded cost of, like, $100,000 a year and making it 10 times more efficient. You've saved the customer $90,000. I would think we could recapture some of that as software revenue. But with AI, we're just gonna disrupt healthcare by allowing practitioners to focus on what they do best, working more productively, more efficiently, using their time better, and then letting the AI do what it does best: summarizing, prioritizing, automating tasks.</p>
<p><strong>Lisa Jarrett:</strong> Dean did a great job of summarizing the PCC specifics, so I'll go a little bit broader across the health ecosystem and the array of different processes that we work with. One of the things I'm most excited about for AI and advances with data interoperability is the opportunity to right-size administration. In the United States—I'm sorry, I don't have the statistic for Canada—30 cents of every dollar that's spent roughly on healthcare goes to administration, not care. You add that up over the trillions of dollars that we spend, and it's really quite outrageous. I think that with models, with agents, with appropriately refined agentic AI, we have the opportunity to change that ratio. It's the best opportunity we've ever had in history to be able to right-size that. That's one space that I think is amazing. The other place is really across the healthcare ecosystem, those transitions of care. Better awareness, better use of relevant data, getting it to the right person ahead of a transition, and then enabling better care through those transitions overall. I think the opportunities, particularly with agentic AI on that, are incredibly exciting. I'll just put a note in on agentic. Everybody who knows me knows I say this a lot, but there are good places for agentic AI, and there are places in healthcare where you have to really look closely to see if that's exactly the right place, particularly with autonomous or semi-autonomous workflows.</p>
<p><strong>Rahim Hashwani:</strong> For enhancement, I think speed, velocity, and again, automation. Automating the mundane, getting rid of the administrative burden on our caregivers so they can actually provide care. In terms of velocity, think of enhanced imaging, for example. There are actually areas where AI is outperforming radiologists on certain things, like detecting strokes or early stages of cancer. AI tools can analyze the images with greater speed, perhaps greater accuracy, and reduce that time to get that information across to the caregiver. Personal experience, you know, if you're going to a doctor, it takes a few days to get the image and then get that analysis back. If you're in emerge, maybe it's a few hours rather than a few days, but you can get that instantly. So that time, that administrative burden gets removed so that you can spend more time on that care, and you get that information sooner. That's an area where it can be enhanced and disruptive, for sure.</p>
<p><strong>Auroosa Kazmi-Ishaq:</strong> This question is for Cedric and Dean. What strategic steps should our organization take to remain at the forefront of AI innovation in healthcare?</p>
<p><strong>Cedric Anne:</strong> Let me get started. I think as an organization, it's high time to shift from exploring to making it part of the operation. The time to explore is behind us. I think it's time to put it into the operation, to try, to fail, to do this again. What we've done as an organization, and it's very clear from leadership, is that AI is a core business strategy. It's more than an initiative; it's not an innovation in a lab. We heard it from Dave many times, so it's very clear where it's coming from and that it's part of and should be included in our DNA going forward. When we think about where we need to embed it as an organization—whether it's onboarding, implementation efficiency, product, obviously, as you heard from Lisa and Dean, or customer support timelines—it's about making it part of the core business strategy. The second point I'd like to make is around access. I think the more we democratize access to it, the better it is as a utility, as a business form going forward. Prompt libraries are a good example. It might be daunting for some people to just ask the AI in a certain way, but then when you hear from somebody else how they've done it, it becomes that much clearer in capabilities and the things we can do with it. The third point is, as we get so many ideas, as we look at all the things we can do with it, I think as an organization, we have the duty to make sure that we're doing the things that are going to get us to win, and not just cool stuff or doing it just because we can. It's critical that it needs to be for the right reason: reducing costs, improving care, obviously, accelerating outcomes, implementing faster, better, with more data quality. All things in such a way that allows us to win and gives us a chance and an opportunity to win in the markets that we're in. Those would probably be the strategic steps that I'd like to share.</p>
<p><strong>Dean Slawson:</strong> Yeah, those are great ideas, and I think the thing I would focus on is we need to invest in our approach to iterating more rapidly with these AI capabilities and the associated user experiences. There is some tooling and customer engagement refinements that we can do, but learning faster with our customers is the thing that's going to help us pull ahead. There's such a wide range of technologies that fall under the AI umbrella. It's not all large language models; there are small language models, parameter fine-tuned models—I could go on, there are dozens of them, and more coming every day. These all have tremendous potential, but only if we apply the right technologies the right way to the right problems, and that's a collaboration across disciplines. Not every application of AI that we expect to work is gonna work in practice with real users in production at scale the way we think it will. We need to set ourselves up to make intelligent, well-reasoned choices about which tech might work in which products to solve which user experience, and then we've got to find ways to go faster. We make those educated guesses, and we try them out, iterate quickly. If we can converge on the high-value solution faster than our competitors, we win, and we win big. If we can't, we lose, no matter how good the ideas are. If we cannot stay ahead of competitors and just stay ahead of the market in learning and trying and iterating and refining and get them to be good enough—not perfect, just good enough that we're delivering differentiated value—we can do that, but it's going to take a little bit of focus and investment.</p>
<p><strong>Auroosa Kazmi-Ishaq:</strong> This question is for Lisa, Dean, and Rahim. What ethical considerations should we be mindful of when deploying AI in healthcare settings?</p>
<p><strong>Lisa Jarrett:</strong> There's a lot to consider in putting this in healthcare settings. Responsible AI has so many different dimensions to it. A quick guide for those that are listening: PointClickCare is an ONC-certified (ONC (Office of the National Coordinator for Health Information Technology): A U.S. government body promoting a nationwide health information technology infrastructure.) EHR (Electronic Health Record). Last year, we had to go through a process of doing that certification for a new AI-focused area, and ONC came up with a shorthand, which is FADES. The F is for fairness, the A is for appropriate, which is a big one, V is for valid, E is for effective, and S is for safe. Our customers are looking to us to do the responsible thing for them. They don't necessarily have the resources to look deeply across all of these different dimensions. As we move forward with AI parts of our product, they're looking to us to do the testing and do the work, make it transparent, make it understandable, and do the risk management that's associated with it. Be transparent about what data sources are being used. There are a lot of different dimensions, and the last point I'll make is that it's not a one-and-done. When you put an AI capability inside of a product, you don't do RAI at once. You do it throughout the entire lifecycle, and you keep doing it after you've deployed it, because things change. You may enhance it and add things to it that might introduce other risks. You have to document what you're doing about those risks. You need to be able to educate your users about what you're doing and keep them informed. Keeping that user-focused lens on making sure you're being clear and answering their questions and concerns and addressing them proactively is really where the opportunity space is for PCC as a thought leader and a market leader.</p>
<p><strong>Dean Slawson:</strong> Yeah, I could add to that. That was a great summary. I mean, you were asking about ethical considerations, and to me, those are the moral principles behind its use: things like fairness, respecting privacy, and thinking about societal impact. The way we put those ethical considerations into practice is by having exactly what Lisa was talking about, this set of responsible AI principles. Those focus on accountability, security, transparency, safety, and of course, regulatory compliance and human oversight. And then it's just about our integrity. When we deploy an AI capability, does it do what we say it will do? Is it both safe and effective? Ultimately, to be ethical and responsible in our use of AI, we need to have a clear value prop in mind, and then we have to validate that our solutions deliver on that promise with no harmful side effects. We also need to align our messaging. We don't want to over-promise. That requires educating our customers about what our solutions can do, what they can't do, how to use them, and how not to use them. We've all seen the headlines of bad examples of AI used to unfairly deny claims or over-promise on clinical models. But by taking the high road on the ethical and responsible use of AI, we can really differentiate our offerings and ultimately our brand versus all the AI hypesters that are out there. This is a great opportunity for us.</p>
<p><strong>Rahim Hashwani:</strong> All great points. I'd maybe just highlight the transparency piece. A lot of times, AI models or tools function in a black box, happening behind the scenes. It's not necessarily clear or easy to understand how an AI-generated decision or recommendation has been made. Patients should understand how AI is being used in their care. Clinicians should be able to explain why an AI tool made a recommendation for a specific treatment and what factors led to that recommendation. The tools need to provide not just the sources but the reasoning behind that conclusion. If not, you're undermining informed consent. That transparency is key. I'm not seeing a lot of that out there, but I think that's important for us to consider.</p>
<p><strong>Auroosa Kazmi-Ishaq:</strong> There's actually a question that came up in the Q&A that sort of dovetails really nicely to this conversation. The question was, how do we balance going fast in AI and protecting our clients' PHI? How can we be certain that LLMs and models are not sharing this data with the platform they are being hosted and pre-trained on?</p>
<p><strong>Dean Slawson:</strong> Yeah, I can talk about that a little bit. This is a huge focus of attention in the Advanced Tech Group and research with product. We partner very closely with legal, privacy, and InfoSec to make sure that we have the right kinds of processes and controls in place. It starts with making sure we have the rights to use the data, making sure we're only using the data in environments with proper controls, and only using it for purposes for which we have the rights to use it. Rigorous testing—we've done red teaming, we do other kinds of tests. This is top of mind for us every day. Obviously, our clients' PHI and the patients', residents', or members' PHI is not just legally our responsibility to protect, but morally. We wouldn't want any of our information leaking out or being used inappropriately. I'll just say that's a big focus of what we do.</p>
<p><strong>Lisa Jarrett:</strong> I would agree with Dean. This is part of the same messaging about beginning, middle, after, etc. It's not just one time. You're doing it through the development, but then you also have the obligation to continue throughout the capability's lifecycle of making sure that it continues to stay safe and secure. As far as speed, it's a factor, but we're not going to release something that we don't believe is secure or puts PHI at risk.</p>
<p><strong>Cedric Anne:</strong> The one question we should always ask ourselves is, if we wouldn't want this AI tool, agent, or function making decisions for our own loved ones, then just don't deploy it yet.</p>
<p><strong>Auroosa Kazmi-Ishaq:</strong> How much of a concern is bias in the data source, and ensuring AI outputs provide equitable care? And how do we combat this if the historical data is indeed biased?</p>
<p><strong>Lisa Jarrett:</strong> I'll start, and then I'm going to turn it over to Dean, because we come at it from different perspectives. That's part of us analyzing the problem we're going to solve. What kind of data do we have to do that? How do we make sure it's not biased? And how do we go forward? But it all goes back also to those data use rights. We have to understand if we can use the data, what data we have, and how do we make sure it's not biased before we go forward. I'm going to turn it over to Dean because he's deeper in on it.</p>
<p><strong>Dean Slawson:</strong> There is a technical aspect to it as well, because as mentioned in the question, there is bias in healthcare data. That's not something we can completely eliminate because it's data today largely generated with human involvement, and humans have bias. This is something we proactively look at during the AI model development process. We do binary classification, we see if different groups are differentially giving different outputs to a model. It's something that we measure, it's something that we evaluate, and something we continue to measure even after we deploy because there could be shifts in population or data or biases that get introduced later. It's also something that we work to mitigate. Sometimes you can change the threshold of a model and address most of the bias issues, or a lot of it is communicating properly so that users understand what they need to be aware of, because you can't 100% eliminate bias. We obviously don't want to ship something that's going to be harmful to any group, but we also want to create the greater good. It's always a focus of attention and a balance to make sure that what we ship is responsible and that users understand any limitations of it.</p>
<p><strong>Auroosa Kazmi-Ishaq:</strong> Another question here. Azure Studio is pretty locked down to us as users, only uses Chatbot. Who do we work with to gain access to some of the other great features it offers?</p>
<p><strong>Rahim Hashwani:</strong> Honestly, reach out to us. Reach out to me directly, and we can work with you to help. Obviously, we're going to be responsible about this and fair. There are models that are out there that we may not want to actually enable because of where they've originated from, but we can certainly help to unlock some of the capabilities.</p>
<p><strong>Auroosa Kazmi-Ishaq:</strong> Do you think AI is going to make the human lifespan even longer, improve the quality of life for our current lifespan, or both?</p>
<p><strong>Dean Slawson:</strong> It's a speculative question, but I'm very hopeful and optimistic that not AI, but our appropriate use of AI, has huge potential. I hope it's making our lifespan longer and that it's making the quality of our life longer to go along with that. I think there are innovations that address both in using AI and other technologies in health tech that have a lot of potential for that.</p>
<p><strong>Lisa Jarrett:</strong> I'd add that everything Dean said, but we're still people. So, until the AI or the LLMs are actually materially changing our behavior and encouraging us to improve our health, I think there's opportunity for both to have an impact on population health more broadly.</p>
<p><strong>Cedric Anne:</strong> I see two things. One, living longer may be more so living better. There's something to be said around how we're adding more years where you can move, think, connect, and your independence is preserved. In our use case, just looking at it from a PointClickCare perspective and thinking about it for our mission, when you give back time to your clinicians through AI, all of a sudden you have fewer frictions. You have a proactive care model when you think about what the patient can expect. And at the end of the day, just sharing what I've seen when visiting customers, there's this whole thing about dignity when you think about all the vulnerable population that our software helps to take care of. This is one where, when we enhance and provide all of these tools, it's not just life longer, it makes life better.</p>
<p><strong>Jared Pilcher:</strong> I think AI presents a lot of opportunity to not only help us answer what we kind of know, do summarization, helping us with notifications, etc., but I think one of its biggest impacts in the future will be helping us understand what we don't know. If we can really capture that, then we may be able to answer questions we haven't even asked yet. That's what I want to see, and then that could translate into a longer life.</p>
<p><strong>Auroosa Kazmi-Ishaq:</strong> What's one piece of advice you'd give your past self about embracing AI?</p>
<p><strong>Rahim Hashwani:</strong> If I could hop into that DeLorean and go back, other than betting on OKC to win the NBA championships, I would say dive in. Like, use AI every day and share. Push people to use it as well. I would have been like, "Hey, I just tried this out. What are you doing? Well, put it on your phone. Just do it! Do it now!" And just get people to really embrace it even sooner than we would have. Build that muscle memory, build that habit, adopt it.</p>
<p><strong>Cedric Anne:</strong> I'll take the same approach. I'll take my DeLorean, go back, and invest in OpenAI. And in all seriousness, I think I would model curiosity against certainty. When I started looking at it, I had so many biases and so many thoughts of, "Is that really going to be a thing?" and didn't start when I should have. Going back, I would be a lot more curious and try things until we get the one success.</p>
<p><strong>Dean Slawson:</strong> I guess first of all, if I could talk to my past self right now, I'd say, "Great news, you're gonna make it till at least the first half of 2025." But more importantly, I would let myself know that, "Hey, you're gonna be alive during the greatest era of software innovation the world has ever seen." The technologies that are going to be available at your disposal are going to have unheard-of potential to create meaningful value, to change the world. I would just tell myself to make more time to learn as much as I can, try things, experiment. Some things you can only learn by trying and making mistakes. I could have made more mistakes and learned more, maybe. It's okay to be wrong, but it's not okay not to try. I'd probably have said earlier in my career, maybe go deeper. I remember I had the privilege of taking a class when I was a grad student at UCLA with one of the pioneers in the early field of AI, Judea Pearl. He was the inventor of something called Bayesian networks, and he was a Turing Award winner later on. It was a fun class, and then I kind of moved on to other things. I've continued to stay involved in AI, but if I had foreseen what's happening today, I might have gone deeper with some particular area of technology. Instead, I'm more of a generalist futurist, but it's good advice for all of us to keep scanning the horizon. New things are coming along all the time. Place your bets wisely.</p>
<p><strong>Jared Pilcher:</strong> I think this is starting to catch on, but AI is not a fad. I thought it might be two years ago, so I hesitated for a while. I did jump in, but not with both feet; kind of put my toe in a little bit. So, I would say to my past self, jump in with both feet, learn everything you can about LLMs, about agents, and then try to push the envelope sooner. That's what I would tell myself.</p>
<h2 id="section-6">VI. Closing Remarks</h2>
<p><strong>Marina Stojanovic:</strong> We're coming to an end of a remarkable event. This is the first of its kind at PointClickCare, and I want to take a moment and reflect on the journey we've all taken together today and what lies ahead in our very bright and exciting future. I'm gonna channel the iconic duo from "Back to the Future," which is our theme today: Doc Brown and Marty McFly. One of the things that stands out is, "Your future is whatever you make it, so make it a good one." This is really true and sage advice even today. We're standing, as you can see, on the brink of some incredible technological advancements. Who would have thought 10 years ago that we'd be sitting here talking about all the things our little robot assistants can help us with? When we go back to thinking from 1985 what they imagined for the year 2025, they imagined flying cars, hoverboards, and self-tying shoes, and all sorts of other limitless possibilities. Even though we don't have flying cars, the innovation that we're seeing is really something extraordinary, and we can only see it accelerate over the next few years. I would like to think that Doc Brown would be really thrilled to see how AI is transforming our world, from revolutionizing healthcare and really shaking things up the way that they've been done, to enhancing our daily lives with smart assistants and autonomous vehicles, all sorts of things that we enjoy, sometimes without even noticing. Marty McFly, I think, would be excited about the endless opportunities for creativity, innovation, and all those wonderful things that AI brings. Since we're seeing such an incredible amount of creativity today, we're safe in saying that Marty McFly would be proud of us today. But they would have their concerns, and again, we've touched on a lot of these topics today. Doc Brown might be worried about the ethical implications of AI, such as ensuring that all of these technologies are being used responsibly and do not infringe on individuals' privacy. As Alan mentioned earlier, really taking care of our personal information and our customers' information. Marty McFly may be worried about the potential for AI to widen the gap between those who have access to these technologies and those who do not. They would both urge us all to be vigilant and proactive in addressing these challenges. And let's not forget, Doc Brown would probably remind us to avoid any flux capacitor mishaps. We don't want to accidentally send our AI back to the Stone Age, or worse, to a time when dial-up internet was the norm. Marty McFly would joke about making sure that AI doesn't develop a taste for Pepsi-Free, because who wants to pay for a soda that doesn't exist anymore?</p>
<p>Now, we're gonna turn it over to our own Doc Brown, with much better hair. We're going to turn it over to Dr. Cindy Plunkett. She's going to add some closing remarks from her end.</p>
<p><strong>Dr. Cindy Plunkett:</strong> Thank you so much, Marina. I want to take a moment and thank and congratulate everyone who contributed to today's event: our planning committee, our review committee, our presenters today—so brave, and thank you for submitting your case studies and sharing them with the rest of the company. Thanking our panelists, the many advisors we depended on to make today's event as successful as it has been. So thank you to everyone that helped make sure that we were able to bring the AI Symposium to PointClickCare.</p>
<p>As a reminder, any new AI tools have to be reviewed by our security team before they're made widely available, and only approved AI tools are to be used. For some tools, they need a purchased license, so that'll require a budget, and you'll need to use the BuySmart process. Certain AI tools need additional considerations around data quality, integrity, and scalability. Any tools that use PPI or PHI require special consideration for regulatory compliance and privacy. We saw this in all of the case studies today, and our panelists talked about this. Responsible and ethical use of AI is always required. It's crucial to always double-check AI-generated responses and ensure that they're accurate and reliable. This helps to maintain the integrity of the information and it prevents the spread of misinformation, which is vital for reliable content.</p>
<p>As we look to the future, I think today has helped us open our arms. Let's embrace that spirit of curiosity, exploration, and innovation that Doc and Marty embodied. Let's continue to push the boundaries of what's possible and always strive to make our world a better place and help every provider deliver exceptional care. Thank you again to everyone who submitted use cases, to our dedicated panel who reviewed them, to our organizers, and to you, all of our attendees who made this event a success. Together, we're all shaping the future of AI at PointClickCare, and I can't wait to see what we achieve next. Remember, the future's in our hands. Let's make it a good one. Thank you so much, everyone.</p>
`;

    const zhContent = `
<h2 id="section-1-zh">一、人工智能趋势与战略要务</h2>
<p><strong>戴夫·韦辛格：</strong> 我的两大投资者是Dragonair和Hillman Friedman。他们花了很多时间，试图让我与每一位在人工智能领域表现出色、更优或与众不同的人建立联系，以便我能从中学习。这是一段巨大的学习旅程，每天都可以花在了解另一家公司的发展历程上。他们倾向于把我介绍给那些取得了相当成功的公司。因此，我先谈一个与医疗健康相关的案例，这个案例偏向金融，但他们确实有一些医疗客户，然后再谈一家医疗公司。</p>
<p>我看到的一个案例是一个非常有趣的概念，我认为当我谈论其他组织时，我主要是在谈论他们向市场提供的解决方案。但当我们思考我们自己可能向市场提供什么时，我们内部也在消费他人的解决方案。所以，这其实是同一件事，只是颠倒过来了。这个组织做得很好的一点是——他们曾努力向市场推出人工智能产品。我认为我认识到他们至少迭代解决了的挑战是，他们现在在终端市场的人工智能领域发展得非常好。他们的收入同比增长了一倍。他们收购了一家人工智能公司，加速了部分工作，并在过去六个月里一直在构建智能体（Agent: 一种旨在执行特定自主任务的人工智能程序，如创建报价或分析数据。），为业务带来了大量机会。他们将其作为一种编排层（Orchestration Layer: 一种自动化和协调跨多个应用程序或服务的复杂任务和工作流的系统。）销售给客户。他们将其产品化，而不是让终端客户自己构建智能体。他们做得非常出色，我认为在一年内实现收入翻倍，实际上是一个相当了不起的成就。所以这非常积极。</p>
<p>我从中得到的一个启示是，他曾挑战自己的团队——一群非常聪明、能干的人——去开发智能体并自己构建。他给了他们一定的时间，但最终他们没能达到他预期的水平，所以他不得不进行收购。我的感悟是，如果我们不花时间磨砺自己、学习和成长，我们就会一直被日常问题和那些会拖我们后腿的优先事项所困。我认为，专注于我们需要前进的方向，需要领导层和我们所有人的巨大勇气。而且我认为，关键不在于你对什么说“是”，而在于你对什么说“不”。我们在这个组织里经常听到的一件事是，有很多优先事项，而这些优先事项最终取决于领导层。如果我们不清楚我们需要去哪里、需要选择什么，无论我们今天学习多少，我们都无法取得进展。我们需要创造空间，这会很困难，有时甚至难以接受，因为这会偏离我们现有的计划。但这是一个例子。</p>
<p>另一个例子是，这是一个稍微外部的视角，我与一些利用人工智能来推动其在医疗健康领域增长的公司进行了交谈。一个例子是一家公司，它在我们的应用程序之上构建了一个编排层，可以做两件事。第一，它让终端用户能够自动化他们所有的手动流程。他们称之为“智能体操作程序”。他们正在我们的应用程序之上构建大量的这种程序。有趣的是，这不再是“以人为本的设计”，而是“以机器为本的设计”。这很有趣，正在偏离传统。然后，他们抓住了一些机会，创建了基于我们应用程序的Chrome扩展程序，打造了一个并行的工作流，客户可以在这个Chrome扩展程序中创建大量智能功能。他们取得了非常不错的进展，在某种程度上还处于营收前阶段，但已经开始起飞，因为它显然解决了一个大问题。在每个董事会里，要求都是更多的人工智能、更多的人工智能、更多的人工智能。所以如果有人在解决这个问题，而那个人不是我们，那可能会有问题，这确实会驱使你产生一种紧迫感和节奏感，开始满足这种需求。所以，这是两个不同的公司利用人工智能的例子。一个不是原生人工智能公司，另一个是。接下来的问题是，你如何与他们竞争，你如何看待这个问题？</p>
<p>然后，在内部，思考一下这个问题。我们正试图为我们的客户提供由人工智能驱动的解决方案，这是我们希望达到的目标。艾伦，你所接触的我们内部的供应商，也在试图向我们提供人工智能，他们往往专注于自己的领域，无论是财务、销售、产品、服务还是其他。但我们必须以某种方式将这些零散的部分整合起来，为我们自己的员工提供无缝的体验和流程。所以，很难考虑单一来源的人工智能供应商。这就是为什么像Copilot或编排层这样的东西会兴起，因为它们可以跨越许多不同的应用程序，并为业务带来巨大的效率提升。所以，这只是几个例子，确实能带来一种紧迫感。这些事情不仅仅是我们理论上谈论的；它们是真实存在的。它们正在开始影响企业，而且是实质性的。所以我认为这既是内部的机会，也是外部的机会。两者是相辅相成的。</p>
<p><strong>艾伦·米森：</strong> 是的，这些都是很好的例子，戴夫。我认为你关于投入时间学习和那种严格的优先级排序的观点，这两者的结合，坦率地说，是我们今天之后需要认真对待的一个非常有力的评论。我认为这是一个很好的观点，说得很到位。</p>
<p><strong>戴夫·韦辛格：</strong> 艾伦，在我们来回交流的时候，我问你一个问题。正如这里的每个人都知道或应该知道的，我们在P2C（P2C（从产品到现金）：涵盖从产品创建、销售到收入收回的整个生命周期的业务流程。）方面付出了有意义的努力。当你思考我们在设计方面所做的工作时，业务流程工程或业务流程建模很大程度上是关于人类如何使用解决方案，我们考虑到Salesforce或其他可能包含在其中的组件，以及NetSuite。当涉及到为我们传统上关注的事情进行不同设计时，你如何看待人工智能？人类如何做X，我们如何做得更好？在重新设计流程时，你如何以不同的方式思考使用智能体或人工智能？</p>
<p><strong>艾伦·米森：</strong> 是的，坦白说，我们正处于这段旅程的起点，但我确实认为这是我们正努力快速发展的领域，戴夫。如果我们看传统的交付大型转型项目的方式，你是对的，你基本上是确定范围，构建它，测试它，然后上线。我们大概走了三分之二的路程，突然之间，出现了一个我们在项目开始时没有的能力。现在，我们正在积极研究，在P2C中是否有三到四个领域可以立即开始利用这项技术。所以，这不仅仅是未来的新想法，而是我们手头正在进行的事情。我们如何开始考虑立即应用它？所以一个很好的例子是，我想我们在SLT（高级领导团队）会议上展示过，我知道这也是你非常热衷的一个，就是我们能否让一个智能体（Agent：一种旨在执行特定自主任务的人工智能程序，如创建报价或分析数据。）为客户构建一份报价，并在11月上线？我们真的能准备好吗？所以我们正在这方面大力推进。我认为在财务方面，后端也有三到四个类似智能体的想法，我们已经开始尝试，看看我们是否也能在11月1日前实现它们。所以这有点吓人，因为我们试图在“建造飞机”的同时改变范围。但这些是我们围绕这个想法在PSC内部考虑的一些事情。</p>
<p><strong>戴夫·韦辛格：</strong> 很好。是的，这很令人兴奋。你的观点非常有趣，因为在六个月内的进步，更不用说24小时了，简直令人不安。变化的速度，我认为迈克谈到了一个五年的时间范围。云的颠覆真正花了十多年时间。而这里的颠覆几乎不能用年来衡量。我的意思是，两三年后，我们今天视为正常的东西会感觉像是50年前的历史。这太不可思议了。</p>
<p><strong>艾伦·米森：</strong> 是的。我认为你提出的另一个评论也很有趣，就是你在一些大型平台上看到的一些东西，创新的攻击点实际上是在边缘地带，对吧？不一定总是大公司在攻击你，而是一些小型的、创新的公司在我们的业务边缘进行突破，这对我们来说是一个非常有趣的动态，需要我们去理解。你还提到了我们这个领域的供应商，我们的平台合作伙伴，他们是如何参与的？有一个数据显示，到明年，80%的应用软件都将嵌入人工智能功能。所以，要理清哪些是好的，哪些可以集成，哪些我们应该使用，这确实是一个挑战。你说得对，现在每个供应商都在敲我们的门，说：“你需要看看我们的东西。”</p>
<p><strong>戴夫·韦辛格：</strong> 让我与你分享这背后的原因。这真的始于企业价值，它是许多人的一个关键驱动力。你坐在董事会里，和他们交谈。这一点之前有所提及，但在我们讨论“如果我们做得好会怎样，如果我们做得不好又会怎样？”之后，这个话题变得更加突出。让我们设想几种情景。如果我们做得不好，六个月后，我们的价值可能只有今天的一半。我们价值的一半。如果我们做得好，区别是什么？我们有由人工智能驱动的解决方案出现在市场上，展示出与之相关的真实收入，我们的表现将远远好于我们股东价值可能的样子。所以，如果你只考虑经济因素，以及为什么你会看到供应商出现并说，“买我们的人工智能产品，买更多”，因为他们的整个企业价值都建立在他们证明自己有能力做到这一点的基础上。这就是为什么对于客户、我们以及其他企业来说，进入这个新世界如此重要。这对他们业务的价值构成了生存威胁。所以，是的，人们都很有动力，有些人比其他人更有动力。对我来说，这就是机会所在，但这只是让你了解它的来源，以及为什么你会看到围绕它有如此高的强度，特别是当你接到那些关于“买这个，买那个，以这种方式配置，以那种方式配置”的电话时，对吗？</p>
<p><strong>艾伦·米森：</strong> 我前几天看到了一个关于你所说的估值的有趣数据点。在2024年底，人工智能组织的总估值大约是4500亿美元。预计在未来六年内，这个数字将达到18万亿美元。这相当于每年37%或40%的复合年增长率（CAGR (复合年增长率): 投资在超过一年的指定时期内的平均年增长率。）。所以，这完全印证了你的观点，这种预期简直是疯狂的。</p>
<p><strong>戴夫·韦辛格：</strong> 嗯，我给你一个非常具体的数据点。最近有两家公司被收购，一家只有两个人，估值超过1亿美元。两个人。另一家公司，一家以色列公司，以数亿美元的价格被收购，大概有三四十人。这两家公司都没有任何收入。没有收入。这就是市场对基于人工智能的公司的渴求。这太不可思议了。显然，没有历史包袱，从头开始更容易，但这绝对是令人难以置信的。这让我想起了2002年，我希望那时的SaaS（SaaS（软件即服务）：一种软件许可模式，软件按订阅方式授权，并由中心托管。）公司也能做到这一点。它们在1999年，在泡沫破裂之前就在这么做了。但是的，这很清晰也很有趣，我看着镜子里的自己，心想：“天哪，我老了。我要赶上第二波浪潮了。”第一波是云，我还能经历另一波，我可以分享故事。我有点兴奋，想为《福布斯》写下一篇关于一生中经历两次重大颠覆的文章。所以，总之，我跑题了。</p>
<p><strong>艾伦·米森：</strong> 当然。那么下一个简单的问题，关于医疗健康领域，你之前也稍微提到过，你认为未来几年哪些领域会有最显著的颠覆？</p>
<p><strong>戴夫·韦辛格：</strong> 嗯，我认为增强人类能力和取代一些单调乏味的任务的能力，毫无疑问是绝对的。另一件我想说的是，让人们更聪明地安排工作优先级的能力，这样我们在医疗健康领域用有限的资源就能做更多的事情。但我也想说，我认为非常有趣的一点是，我相信整个行业最终都会对信息做出反应并采取行动。所以，如果你考虑到传感器，以及摄取信息的能力，无论是生物传感器、历史信息，还是其他所有信息。那种“你需要输入一些东西才能有观察结果来做出反应”的模式。现在设计任何需要人类输入东西的系统，就好像在说：“你在说什么？那已经不是个事儿了。”所以，当你想到那个障碍已经消失，我们现在有了完整的信息，我们可以把它变成我们做出反应的依据。我认为这是一个思考未来的非常有趣的方式。</p>
<p>但就影响而言，我想告诉你们，任何在峰会上或听过我与鲁博士交谈的人都知道，他们在眼科领域所做的工作，那种能够读取眼球扫描并了解你的整个诊断，或其中很大一部分的能力。想象一下，那一张图像很可能最终会出现在手机上。现在它是一个相当复杂的设备，但它会变得商品化。那一刻，你就能理解原本需要数小时评估才能了解的东西，如果他们意识不清或无法沟通，你可能无法获得所有信息。通过一张图像，在一瞬间就能了解人体状况并知道该怎么做，你可以有效地驱动整个服务计划、护理计划、需要什么、诊断是什么，让他们得到适当的个性化治疗。那将是一个非常有趣的日子，而且这很难出错，因为你不依赖于人类的反应。你不依赖于他们无法提供的反应，或可能不准确的文档。它清晰明了。所以，在了解个人和知道该做什么方面的进步，我认为将在推动这些人应得的护理质量方面发挥关键作用。</p>
<p><strong>艾伦·米森：</strong> 是的，这感觉与我最近在医疗健康和人工智能方面所做的一些研究非常相似，特别是你提到的以人工智能为中心的扫描技术。它们提供高质量数据的准确性和速度——你知道，脑部扫描的准确性是过去的两倍，骨骼扫描能发现X光未发现的骨折。与分诊相关的活动，能够识别出哪些人需要去医院，哪些人不需要，以及与急救服务相关的判断。是的，这方面确实有很多进展。</p>
<p><strong>戴夫·韦辛格：</strong> 预防性早期检测，显然是节约成本和提高生活质量的重要方面。但我们仍然是人类，我们仍然会选择那些吃鸡翅的夜晚和那些让我们惊呼“哦，天哪”的东西，所以这与它如何延长我们的生命没有完全确定的关系，但我们知道该怎么做。问题是，我们会去做吗？</p>
<p><strong>艾伦·米森：</strong> 太棒了。下一个问题。关于医疗领域的人工智能，有没有什么值得讨论的误解？</p>
<p><strong>戴夫·韦辛格：</strong> 误解。哦。这是个好问题。我不确定有什么真正的误解。他们害怕它吗？我认为没有恐惧因素，但我认为也有点自负。如果你想一下那些从业者，或者那些通过积累知识建立起职业的人，要从这一点上分离出来是件很了不起的事情。我不知道这是否是一种误称或误解，但我确实认为，医疗保健的某些领域会比其他领域更快地接受这一点。有一个巨大的信任因素是真实存在的。所以，如果误解是，“嘿，只要它证明了结果，每个人都会追捧它”，我认为我们会看到，考虑到它的负责任性、伦理、幻觉——如果你不是99.99999%正确，你可能会害死人，那就不好了。顺便说一下，我们今天在PointClickCare就有这种情况，而且甚至不是人工智能。但我们根据药物信息提出建议，让临床医生说，“哦，是的，这有道理，”然后将其转化为医嘱或其他形式。但是从自然语言到结构化格式的转换可能会出错。如果他们必须验证，因为它总是对的，他们会说，“是的，是的，是的。”但偶尔一次错了。你猜怎么着？那真的可能害死人，是真的。所以现在你该怎么办？你不启用它吗？你倒退吗？所以，是的，我们都在谈论它。我认为期望它能顺利落地并正常工作，而他们只需要克服自己的自负，这是一回事。但另一部分是，它真的必须有效。它真的必须有效，否则你实际上在造成伤害，我们谁也不想造成伤害。我们相信，今天，人类正处在确保我们有验证和核实的中间环节。如果这变成一个简单的步骤，我们就会失去这一点，我确实担心它会成为人类的天性和行为，最终无意中造成一些裂痕。所以我认为我们必须关注这一点，我认为在医疗保健领域，这比我们想象的要困难一些。在其他领域，你可以有那种错误率；在这里，我认为在某些领域会非常困难。行政任务，没那么严重。临床任务，绝对是。</p>
<p><strong>艾伦·米森：</strong> 是的，我完全同意。我最近读到的另一个数据点也与人工智能和信任的动态有关。今天，75%的公众消费者不信任人工智能的结果。所以，当你把这一点应用到像医疗这样重要的事情上时，要克服信任这座大山，对我们来说绝对是一个巨大的挑战。</p>
<p><strong>戴夫·韦辛格：</strong> 我认为这很巨大。是的，我认为这很巨大。你知道，我们快要结束了，我想这就是我们看到玛丽娜的原因，所以你好。但对我来说，当我们思考我们的业务并回到今天的主题时，艾伦，我认为你开场得非常好，我想问你，艾伦，今天成功的标准是什么？</p>
<p><strong>艾伦·米森：</strong> 对我来说，这又回到了你之前提到的评论。对我来说，如果我们真的能创建一个更强大的、包含真正有力的用例列表，我们能够实际采取行动并推进，这对我来说是今天的一个巨大成果。我想你稍后会看到，我知道我们今天晚些时候会再聊，我们在几乎每个职能部门都取得了一些虽然不大但还算不错的进展。我想我们今天正在研究的用例超过了70个。我希望这个数字能达到两三百个，然后开始真正努力建立能够快速实施这些用例的技能。我们前几天就构建一个智能体的投资进行了一次非常有趣的对话，这已经不是10、15年前的软件了。也许你可以构建一些东西，它可能只在3个月内有效，然后你就把它扔掉，但达到那个目标的投资是如此之快，以至于这是可以接受的。我认为，在实际行动和实际产品上取得更多进展，以我们以前未曾见过的速度，为这些用例带来价值，这对我来说是最大的成果，是最大的胜利。</p>
<p><strong>戴夫·韦辛格：</strong> 我喜欢这个。其中有几点让我印象深刻。我想你在智能体方面提到了手动任务，比如如果我们把日历安排自动化一些，我们就能创造出空间。我的天，我们浪费了多少时间在忙碌的人们之间协调日程安排上。但我想请大家思考的是，要认识到人工智能是一个了不起的思考伙伴和合作者。所以，如果你想写一份关于你想做的事情的备忘录，这有点像亚马逊的风格。他们真的是靠备忘录而不是PowerPoint来运作。如果你想真正地合作思考并提升你在某个问题上的思考能力，你的智商会显著提高，你会对你正在思考或试图改进或解决的任何方面都准备得更充分、更明智。另一件事是，你不会被评判。ChatGPT或任何产品都不会评判你。所以你只是一遍又一遍地迭代，你的想法会变得更强大、更周到、更恰当。所以，无论是电子邮件、备忘录，还是分享你想去的地方，或者你想做的演讲，所有这些，对我来说，都会让你表现得更好，行动得更快。我们显然会互相合作，但我会请你利用这种能力来提升你对这里的事物以及你确实想解决的问题的思考方式。所以，我就说到这里，但这对我来说会是一个很好的结果，人们认识到这对他们来说是一个很好的机会。</p>
<p><strong>艾伦·米森：</strong> 太棒了。我喜欢“思想伙伴”这个想法。很有趣，几周前我在市场技术领域读到另一篇文章，内容是关于人工智能和内容创作方面正在进行的所有努力，特别是那个用例。他们使用了非常相似的语言。他们说他们将其用作真正的“创意盟友”。这种伙伴关系和作为盟友的想法，我认为，在我们进入这个人工智能世界时，是一种很好的看待方式。</p>
<p><strong>戴夫·韦辛格：</strong> 是的，我想说的最后一件事，对我来说，经验还在于，“我错过了什么？我做错了什么？”而他们会说，“哦，你做得很好，但你可能想考虑一下……”天哪，这太棒了。这强化了积极的行为，而别人可能会对我大喊大叫，说我是个白痴，但这却如此不同。所以，我想说的最后一件事，在医疗领域，我真正感到兴奋的是，当这些东西进入医疗领域时，比如，他们在日本使用机器人，他们在高风险情况下使用机器人。信不信由你，洗衣，对吧？脏衣服是一项高风险的人类工作，至少在专业护理机构（SNF）是这样。所以如果你想到机器人开始在餐厅、洗衣房等领域接管工作，它们会帮助行动不便的人，做一些基本的事情，减少走失问题，以及所有这些我们正在推动的事情。有趣的是，我从我们的客户那里听到，作为伴侣，他们更倾向于与机器人互动，而不是人类，因为少了评判。这里有一个巨大的评判因素消失了，我认为这在你与它互动时非常有趣。也许有趣的是创建一个能评判你的AI智能体。那会是个有趣的工具。不，开玩笑，我开玩笑的。但总之，乐趣无穷。前方是重要的一天。我们有点超时了，我让你们继续今天的日程，我为所有今天决定为此腾出时间的人感到兴奋。这对我们非常重要，对你们也非常重要，因为我想告诉你们，我在这里要说的最后一件事是，公司里每个人的工作描述都会改变。你今天的工作描述已经过时了，我们需要确保，如果你不成长，你必须有那种心态，就是“你在什么方面是初学者？你在学习什么？”这绝对至关重要，我们将会评估你在AI能力方面的进展。这是一个必要的部分，我想迈克前几天晚上和Shopify的托比谈过，那是一个关键指标，我们所有的绩效评估都会有人工智能的元素。你做了什么？你进步了吗？你在学习什么？这对我们太重要了。我们不能错过这个机会。所以，说“呃，我不在乎AI”是不行的。那太不酷了。逃学是不酷的。所以，我就此打住。谢谢大家到场。</p>
<p><strong>艾伦·米森：</strong> 戴夫，非常感谢你。那太棒了。我喜欢那里的来回交流。那么，玛丽娜，我想我们已经准备好迎接我们的第一个用例了。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 当然。是的，谢谢你们今天早上加入并分享你们的想法。另外，我们在聊天和问答区有很多问题，我们会直接分享给你们回答，因为我们有点超时了，所以我很感激。非常感谢！谢谢戴夫。谢谢艾伦。好的，第一个是我们的第一个用例。他来为我们拉开序幕。</p>
<h2 id="section-2-zh">二、人工智能用例展示：第一部分</h2>
<h3 id="section-2-1-zh">Aha! Co-pilot 智能体用于项目管理</h3>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 他的名字是Aakif Shaik，他将为我们开启今天的活动。Aakif，请开始分享你的屏幕。</p>
<p><strong>阿基夫·谢赫：</strong> 好的，谢谢你，玛丽娜。你能看到我的屏幕吗？大家好。我的名字是阿基夫·谢赫。我是SDO（战略交付办公室）的一名业务转型实习生。在过去几周里，我一直在构建一个与Copilot Studio和Power Automate集成的人工智能驱动的副驾驶智能体。对于那些不熟悉Aha!的人来说，它是一个项目管理工具，团队用它来跟踪和管理他们的工作。在SDO内部，我们主要使用Aha!来跟踪和管理我们的关键项目，比如市场推广和产品到现金的计划。</p>
<p>我真正关注的问题是，如何让人们，无论是项目经理还是团队中试图获取快速更新的成员，更容易地使用人工智能助手来完成这项工作。所以，如果你曾经想过，“嘿，我只想快速了解状态更新，而不想在不同工具之间切换”，那么这个就适合你。我们目前正处于试点阶段，正在测试用例并添加额外的用例。一旦我们达到完整的功能，我们希望转向全面采用。</p>
<p>进入演示阶段。这里是Copilot Studio用户界面的一些演示。如您所见，我将从一个简单的提示开始，询问：“嘿，本周有哪些活动到期？”一旦我这样做，您可以在屏幕左侧看到它开始执行一个流程。这个副驾驶智能体目前正在使用与Aha!集成的Power Automate，来提取本周到期的活动信息。所以，这里显示了，它特别关注GTM，也就是市场推广计划，并显示了本周到期的活动名称及其截止日期。这很棒。假设我们想更进一步，说：“嘿，我们如何获取每个活动的具体细节？”所以我现在要给它另一个提示，询问：“我想知道某个特定活动的状态。”再次，您可以在左侧看到，它正在执行一个不同的流程，询问我想要检查哪个活动。所以，我需要给它那个特定活动的名称。一旦我这样做，它就会开始执行一个不同的流程。现在在这个流程中，输出将会不同，因为它将专注于这个特定的活动并为我们提供状态更新。所以，这里显示了，它给出了名称、当前状态、截止日期以及分配给谁。</p>
<p>这就是智能体目前的运作方式。稍微深入了解一下其内部机制，如果你想增加额外的功能，你基本上是将它们作为主题添加。你从一个触发器开始，然后是一个问题，接着是动作。这就是你想要将Power Automate流程与之集成的地方。最后，你有你的输出消息。同样的过程也适用于另一个流程，即涵盖本周到期事项的流程。这个触发器非常重要，因为这是智能体用来区分你的请求的依据。所以，你再次拥有你的流程以及你的最终消息。对于那些好奇想看看这个Power Automate流程是什么样子的朋友，请随时联系我，我很乐意在这次通话后给你做个演示。</p>
<p>现在，我们来谈谈影响。这个工具真正让团队能够改变他们获取项目更新的方式。拥有这个由人工智能驱动的助手，你可以最大限度地减少在不同工具之间切换以及在不同仪表板中搜寻的需要，而是能够通过一个简单的问题获得详细、集中的答案。我在此次旅程中学到的经验是，一定要从小处着手，迭代构建。正如戴夫早些时候所说，从一个简单的用例开始，测试一组样本数据，并在此基础上不断构建，以确保它不会变得不堪重负。然后才进入我们现在的阶段，处理所有复杂的数据。</p>
<p>我们如何帮助PCC的其他人：团队绝对可以将Copilot智能体用于各种目的。我能想到的一个例子是，产品团队可以构建一个与他们的产品路线图集成的副驾驶智能体，这样团队就可以了解他们在整个产品路线图旅程中所处的位置。这对于使用Jira的团队也很有用，可以快速获取Jira仪表板上的状态更新。最后是负责任地使用人工智能。这个项目符合负责任人工智能的指导方针，因为它注重透明度和用户控制。你之前看到的那个副驾驶智能体，它直接从Aha!提供清晰的信息，而不会代表用户做任何决定。它提供准确的信息，并确保回应中没有偏见，同时保证所有这些数据的安全。就此，我想结束我的演讲，谢谢大家。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 太棒了。我们非常感谢你的演讲，我们希望在问答环节听到任何人的提问。我们非常喜欢你的演讲，阿基夫。干得好！太棒了。除了对你的人工智能机器人说“请”和“谢谢”之外，我们对你没有其他问题了，阿基夫，所以谢谢你。大家对你的用例都非常兴奋，如果之后有任何问题，我们会把它们记下来，然后直接发给你。</p>
<h3 id="section-2-2-zh">Gainsight AI 用于客户成功</h3>
<p><strong>凯特基·耶内马迪：</strong> 接下来，我们欢迎帕姆。我们的下一个用例是关于Gainsight，由客户成功团队的帕姆呈现。帕姆，交给你了。</p>
<p><strong>帕姆·马丁：</strong> 太棒了！谢谢。我是客户成功部门的总监。今天，我要和大家谈谈Gainsight。Gainsight是客户成功团队用来管理售后关系的一个平台，今天我们将稍微谈谈如何利用它来发现客户群中的风险和趋势。对于那些不了解客户成功是什么的人来说，它提供战略指导和专业知识，以加速客户成果，并实现PointClickCare平台的愿景和价值。用通俗的话说就是：我们与客户保持着深厚的关系，定期与他们会面，以确保他们正在实现价值，从而愿意成为我们的客户，永远与我们在一起，并且我们与他们一起发现机会，帮助他们实现目标，也让我们发现我们有哪些其他产品可以帮助他们实现这些目标。</p>
<p>今天，人工智能正以多种方式帮助我们：它为我们节省时间，提供全面的客户洞察，并揭示所有客户的趋势。Gainsight本身是核心平台，我们还有许多其他平台向其提供信息，帮助我们全面了解客户及其动态。我首先要深入探讨的是Gong集成。Gong本身会创建行动项目摘要和自动笔记。这些内容直接填充到Gainsight中，为客户成功经理（CSM）节省了时间，因为他们不必手动操作，从而可以更专注于会议，并且这些行动项目可以直接转换为任务，方便他们跟进。在右侧，您会看到人工智能生成的情感分析。这非常酷，因为它能真正地分析自动笔记并捕捉整体情绪，消除了人们可能对那次对话感受的任何偏见。所以，这对团队来说是很好的洞察。</p>
<p>接下来我们简要讨论的是用Copilot起草邮件。希望大家今天已经都在这么做了。它真的能帮助把想法变得简洁，让邮件更好地触达客户，并真正提升其水平。当我们在Outlook中使用Copilot时，我们还能利用Gainsight Assist将我们起草的邮件直接放入时间线中。我们稍后会讨论为什么时间线对我们如此重要。</p>
<p>时间线，我们现在看到的是一个账户级别的时间线，它记录了账户中发生的一切。这里没有人工智能的魔力，我们稍后会谈到。但它所做的是记录所有这些活动，让我们全面了解账户中发生的事情。所以，无论是他们收到的程序化信息，还是他们如何管理账户风险，处理NPS（净推荐值：一种用于衡量客户忠诚度和满意度的指标。）负面反馈者，以及那些发布的会议记录。所有这些都会进入时间线。现在，这是一个账户视图，你可以看到它能创造多么丰富的信息。如果没有人工智能的“小抄”，你必须逐一查看才能了解情况。但是，有了人工智能的“小抄”，它会给我们一个过去六个月在该账户层面发生的事情的摘要。这非常强大，因为它消除了“近期效应”，即人们往往只回忆上周或上个月发生的事情。很多时候，之后的事情就被遗忘了。所以它提取了一些非常有价值的关键信息，对客户成功经理（CSM）很有用，甚至在我们如何跨职能使用这些信息时也很有价值。所以我们有其他团队，我们可以与他们分享这些信息。想象一下，如果我们有升级事件，如果我们有客户想要讨论产品，我们可以提取这个账户的摘要并与他们分享。我们确实要求客户成功经理（CSM）审视这些信息，并批判性地思考他们所看到的内容。它是否涵盖了所有正确的信息？这里是否缺少了什么？所以，如果他们觉得它没有准确地给出全貌，他们可以选择添加备注。</p>
<p>这个备忘单再次是在账户层面上的，而这正是事情变得超级令人兴奋的地方。他们即将推出，或者说刚刚推出，一种叫做“信号挖掘”的功能，利用Gainsight中的人工智能。信号挖掘让我们能够跨越所有账户的所有时间线进行观察。所以现在我们能够提示它询问关于扩张机会、区域趋势、竞争对手提及、产品提及、宣传引述等问题。所以想象一下，说“嘿，我们想知道哪些客户在谈论皮肤和伤口”，然后输入提示“提供给我过去3个月里所有谈论皮肤和伤口的客户列表，以及他们在谈论什么”，并跨职能提供这些信息。所以我们即将向组织解锁一些非常强大的信息和见解。非常令人兴奋。</p>
<p>总结一下，它为我们节省了时间，提供了全面的客户洞察，并且我们很快就能够看到所有客户的趋势。我们学到的是，人工智能的准确性取决于输入的信息。所以对于客户成功经理来说，如果信息不在Gainsight里，那就等于没有发生。所有信息都输入进去非常重要。我们鼓励您审视今天正在使用的工具，了解它具备哪些人工智能功能，并确保您最大限度地利用它。最后，我只想提一下，我们仍然需要确保我们批判性地审视其输出，检查其完整性和准确性。就此，我愿意接受任何问题。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 太棒了。我们其实有一个来自艾伦的问题。自从开启这些工具以来，团队在时间节省方面有什么感受吗？</p>
<p><strong>帕姆·马丁：</strong> 这是个好问题。我们使用这个“小抄”已经有一段时间了，但我们还没有真正计算过它为我们节省了多少时间。但这绝对是我们需要研究的事情。不过，艾伦，我真正感到兴奋的是能够跨越所有账户进行观察，然后了解这如何为我们节省时间。当我们想到这一点时，这正是我们今天手动在做的事情，即询问：“嘿，客户成功经理们，谁的客户在谈论皮肤和伤口？”现在，我们将能够做到这一点，而无需询问他们，然后只在我们需要深入探讨特定要点或概念时才让他们参与对话。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 太棒了。聊天区对你的用例反响热烈。帕姆，对你有很多很多的积极评价。所以再次感谢你的演讲。</p>
<h3 id="section-2-3-zh">Azure OpenAI 用于客户访谈分析</h3>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 我们的下一个演讲来自市场部的索娜。她今天为我们带来两个用例，一个关于Azure AI Foundry，另一个关于Azure OpenAI GPT。索娜，交给你了！</p>
<p><strong>索娜尔·米斯拉：</strong> 谢谢。大家好。我是索娜尔·米斯拉，今天我们不回到过去，而是深入非结构化数据。我利用Azure的OpenAI，设计了自定义提示，从客户访谈中提取丰富而有意义的见解。这几乎就像拥有一个能穿越时间的助手，他能听取每一个字，并总结出其中的精华。我这个项目使用的工具是Azure的OpenAI。你可能想知道，这到底是什么？可以把Azure OpenAI想象成你自己的数字布朗博士——高度智能、思维敏捷，还有点未来感。它使用提示工程和GPT（生成式预训练变换器：一种能够理解和生成类似人类文本的人工智能模型。）来分解冗长的访谈记录，提取客户的痛点、解决方案的益处、影响指标，甚至值得引用的推荐语，所有这些都在几秒钟内完成。为了向您展示实际操作，我准备了一个小演示。</p>
<p>这是一个演示，展示我们如何利用Azure的OpenAI和生成的定制工程化提示，将访谈记录转化为结构化、可操作的见解。这种方法用自动化提取关键元素，如客户挑战、价值陈述和影响指标，取代了手动分析。在这里的聊天界面中，我输入了从访谈中收集的访谈记录。为了突出显示，例如，客户挑战，我输入了提示，要求它突出显示客户在采用产品之前面临的具体问题、效率低下或挫折。模型能够识别出关于手动负担、更高的教育风险和低效工作流程的引述，这些都是团队可以立即采取行动的见解。</p>
<p>接下来，为了识别解决方案和产品价值，我要求它提取关于解决方案如何改善工作流程的描述。模型能够提取出价值驱动的引述，例如信息共享如何变得无缝、用药错误减少以及护理人员效率提高——这些都是案例研究和营销材料的绝佳素材。此外，为了识别指标和证明点，我输入了提示，要求它列出访谈中提供的数字证据或绩效指标。它能够捕捉到该组织与PointClickCare合作的年数，如何从一个地点开始，扩展到50多个地点，通话时间的减少等，这些都是访谈记录中的精彩指标。最后，为了识别有价值的引述和推荐，我包含了提示，要求它提取这些内容。它能够捕捉到客户提到的每一个引述，从当前的患者和居民护理到减少用药错误，这些都可以再次用于营销材料和客户推荐。总之，我能够开发一个完整的提示库，按主题分类，基于客户挑战、解决方案和价值以及指标。所有这些模板都可以在不同的记录中重复使用，并经过微调或嵌入到搜索管道中，将手动审查时间减少了50%以上。</p>
<p>该项目旨在通过显著减少分析时间，从而交付高影响力的成果，我们通过消除筛选冗长访谈记录的需求来实现这一点。提取出的见解现在具有一致性，可以快速访问，并易于在市场、销售和产品等不同团队之间重复使用。此外，这也确保了内容的质量得到提升，引述更准确，主题更清晰，对人工解读的依赖也更少。现在，你可能想知道其他人如何使用这个功能。</p>
<p>最棒的是，这种方法可以轻松地适应任何处理定性反馈的团队。例如，市场营销部门可以提取引人注目的价值引述。项目团队可以发现反复出现的痛点，而销售团队则可能识别出有影响力的成功指标。所有这些都可以使用同一套提示模板。无论是分析调查、访谈还是反馈表，这种方法都有助于在各个层面简化和增强洞察力的生成。</p>
<p>在创建这个项目时，我还关注了负责任地使用人工智能这一事实，所以这些提示都经过了测试，结果也经过了人工验证。我们优先考虑可解释性，使用中性语言以避免偏见，并确保人类完全掌控，所以没有像比夫偷了体育年鉴那样，出现失控的人工智能改写我们的过去。最后，我要感谢市场营销互动团队，他们帮助我塑造了方法，向我展示了这个项目不仅是一个闪亮的工具，还是一个节省时间、驱动洞察的平台。</p>

<p>当你负责任地使用时。正如布朗博士所说，你的未来还没有写就，所以让它充满洞察力。我非常乐意回答你提出的任何问题。</p>
<h3 id="section-2-4-zh">使用 Azure OpenAI 和 Power Automate 自动化联系人收集</h3>
<p><strong>索娜尔·米斯拉：</strong> 接下来，我很高兴能介绍我的下一个项目，该项目利用Azure的OpenAI和Power Automate自动化收集关键联系人信息。这个项目是作为数字客户成功团队的一部分完成的，我们的目标是减少从自动回复邮件中手动追踪重要联系人的工作量。我们通过Azure的OpenAI GPT，经由Power Automate实现，它是一个低代码工作流平台。GPT模型在自动化流程中被触发，用于解读邮件内容，提取姓名和电子邮件地址等结构化信息，然后将其记录到托管在OneDrive上并可轻松共享的Excel表格中。接下来的演示将向您展示具体操作。</p>
<p>每个月，我们的团队都会发送摘要或其他沟通材料，这会收到自动回复邮件，其中一些邮件会包含重要的联系人或新的沟通点。手动追踪这些信息非常耗时且容易出错，所以我们的自动化系统会扫描每封收到的邮件，提取相关信息，如转发联系人，并将其添加到一个集中的共享Excel表格中，使整个过程变得非常快速和一致。现在我将为您演示。</p>
<p>大家好。今天，我将向大家介绍自动化邮件数据提取的流程。首先，自动化程序被设置为从邮件正文中提取内容，并将其存储在一个Excel表格中，例如我们从自动回复邮件中收到的转发联系人。这有助于简化数据并提高效率。为了组织我们的邮件以进行自动化，我们首先需要创建一个子文件夹。这可以通过点击邮件地址左侧面板上的三个点，然后点击“创建新文件夹”来完成。在这里，我为了这个程序的目的，在我的个人收件箱中创建了“摘要”子文件夹。之后，我们进入共享收件箱，选择我们想要提取数据的邮件。在本次演示中，我使用了客户成功摘要收件箱，里面有许多带有转发联系人的自动回复邮件。所以，我们可以选择正确的邮件，然后将它们移动到我们个人收件箱中创建的子文件夹里。这可以通过点击“移动”或直接拖放到文件夹中来完成。完成后，我需要进入子文件夹，仔细检查邮件是否已注册。之后，您可以返回自动化程序查看每封邮件的状态以及正在提取的数据。在流程运行时，通常需要一些时间。现在我们可以进入Excel表格，查看所有邮件和转发联系人是否已被记录。正文栏通常记录邮件中提到的转发联系人。如果有多位联系人，他们将在正文栏中用逗号隔开。例如，在这封邮件中，我们可以看到这里的转发联系人现已被记录。那些没有转发联系人但仍在该子文件夹中的邮件将不会被记录在Excel表格中。就是这样。这就是我们如何在Outlook中使用自动化邮件数据提取来节省时间和确保数据准确收集的方法。谢谢。</p>
<p>这个自动化项目的影响非常显著，我们每月节省了数小时的手动工作。现在，这个过程只需要几分钟而不是几小时。它提高了数据准确性，降低了遗漏关键联系人的风险，并使我们的团队更加高效。每个人都可以访问实时更新的列表，这加强了内部协调和响应能力。现在，你可能想知道其他人如何使用这个功能。这个功能可以轻松地在其他部门复制使用。例如，人力资源团队可以自动化处理申请回复。支持团队可以从工单回复中提取关键细节，而市场营销团队则可以用来追踪活动报名。这个解决方案的优点在于其可扩展性和低门槛，无需任何编码。</p>
<p>在创建这个项目时，我牢记的另一件事是负责任地使用人工智能。这些提示都经过了测试，结果也经过了人工验证。我们优先考虑可解释性，使用中性语言以避免偏见，并确保人类完全掌控。我还要感谢数字客户成功团队的支持。这个项目向我展示了简单的、负责任的人工智能集成如何能够提高日常工作流程的效率。</p>
<p>此外，感谢市场营销互动团队的鼓励，让我得以展示这个项目。</p>
<p>我很高兴能继续在团队中探索自动化机会。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 嗨，索娜，太棒了。聊天区像往常一样对你的用例反响热烈，我们很高兴你能和我们分享这个。我想让我的聊天窗口弹出来。聊天区还有一些关于与艾伦联系的内容。我想这可能是你这周结束前需要处理的事情。艾伦请求与你联系。</p>
<p>为了让你们能更详细地讨论你的用例。他分享了他对业务中其他类似工作进展的兴奋之情，所以我认为这是一个很好的联系邀请。他们正在尝试使用外部资源来解决这个问题，所以他想了解更多。</p>
<p>之后一定要看看问答区的一些聊天问题。现在请直接回答它们。</p>
<h3 id="section-2-5-zh">Reggie：用于法规事务的生成式人工智能聊天机器人</h3>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 我们的下一个用例来自法规事务部的玛丽和哈泽尔，他们将介绍他们名为Reggie的生成式人工智能聊天机器人。交给你们俩了。</p>
<p><strong>玛丽·亨舍尔：</strong> 我是玛丽·亨舍尔，非常感谢今天能来到这里。我来自法规事务部，和我一起的是哈泽尔，她来自技术支持与服务团队。今天我们非常兴奋地向大家介绍一个由我们法规团队为我们部门开发的AI解决方案。我们最终给它取名为Reggie，它是一个生成式AI聊天机器人。Reggie的成功主要归功于两个部分。首先，Reggie拥有一个能自动保持最新法规的知识库。其次，Reggie利用先进的自然语言理解、上下文感知和生成式AI能力来处理复杂的法规问题。在成熟度方面，Reggie已接近试点阶段。我们首先加载了老年生活法规，一旦我们对结果满意，就会继续添加其他业务线的法规。那么，让我们来深入了解一下问题所在。</p>
<p>法规事务团队的任务是随时了解不断变化的法规环境。如果你昨天参加了全体会议，你就会听到戴夫谈到我们的产品在多大程度上依赖于满足法规要求。这非常重要。我们的团队阅读、影响、解释和翻译法规，为产品、客户成功、客户主管、实施等内部团队提供支持。我们还向客户提供信息，更不用说我们还做了很多其他事情。我们的行业一直受到严格监管，但现在我们看到越来越多的法规下沉到州一级，这加剧了我们的问题。我们需要追踪的法规数量大大增加。举个例子，我在一个老年生活团队，老年生活行业在50个州有65种不同的许可证，而且它们都非常不同。法规体系也不是单一的；有时我们必须阅读多项法规才能了解全貌。法规团队相对较小，所以我们需要一种方法来有效地扩展我们的能力。这似乎是AI解决问题的完美契合点。</p>
<p>我们目前有一个法规知识库，PointClickCare的内部同事可以向我们提交问题，我们会进行解答，但我们希望提供一种更自助的服务模式，只在需要更多背景信息时才动用我们的团队。我们希望它更快、更自助。我们曾与哈泽尔和拉希姆的团队合作开发那个知识库，所以我们真的把雷吉看作是知识库的2.0版。我们从去年夏天开始研究解决方案，考察了几款商业AI产品，但没有一个能解决我们最大的挑战，即如何知道法规何时更新。所有其他商业工具都把向其知识库提供法规的责任推给了我们。我真的认为我们可以做得更好，事实证明我是对的。我联系了迪恩，向他描述了问题，他建议我们让拉希姆的团队来研究这个挑战。</p>
<p>我将谈谈第一部分，即问题的前端：确定法规何时更新。我向拉希姆团队的阿曼迪普·贾吉（Amandeep Jaj）提供了所有老年生活法规和州表格的超链接，他也是哈泽尔的同事。这些链接数量庞大，有数百个。阿曼迪普构建了一个工具，可以连接到所有州的法规，并自动将它们下载到一个知识库中。每晚，脚本会自动运行，检查是否有任何更新，如果有，他的工具就会更新知识库。然后，他构建了一个数据管道，将法规输入到Reggie中，在那里，哈泽尔的工具真正发挥了它的魔力。最重要的是，系统会自动向我的团队发送一封电子邮件通知，附带一个电子表格，指明哪些法规链接已更新。这真是太棒了，而且运行得非常好。现在，我请哈泽尔谈谈她在Reggie方面所做的工作。</p>
<p><strong>哈泽尔·弗洛伦西奥：</strong> 当然。现在我们有了数据，安德鲁·塔尼拉姆和我就为Reggie开发了一个搜索和人工智能管道以及用户界面。正如玛丽提到的，Reggie是一个GenAI网络聊天应用程序，用户可以用它更有效地获取最新的法规问题答案，而无需手动搜索或阅读多页密集的文档。Reggie让即使是非法规专业人士也能轻松理解州级法规。Reggie基于Azure服务、全栈代码和检索增强生成技术构建，这意味着你得到的答案是以可信、干净的数据为基础的。系统利用检索最重要的或相关的信息，然后人工智能模型用这些信息来回应，提供准确且符合上下文的答案。虽然通过在Teams或Microsoft 365中构建自己的co-pilot代理也可以实现类似的功能，但我们决定采用这种方法，因为Reggie对可扩展性、灵活性和报告有要求。这也使我们能够实现更持续的学习能力和对大量人工智能服务和模型的原生支持。玛丽，交给你了。</p>
<p><strong>玛丽·亨舍尔：</strong> 好的，我们来做个演示。[由于音频技术问题，演示由现场解说。] 这就是雷吉，我们的登陆页面，你的个人法规事务助理。我在登陆页面，准备问它一个问题。这是一个关于谁必须审查“居民评估工具”的具体问题。这个规定最近刚刚更新，所以这是一个非常实用的案例。我们问它一个非常复杂的法规问题。在这个例子中，这是马里兰州4月28日最近的一次更新。问题是关于谁需要审查居民评估工具。所以，我问了这个问题。你可以在右下角看到，它确实给了我一个信息，说人工智能生成的内容可能不正确，所以这是我们负责任使用人工智能的一部分。它还给了我两个参考资料，因为我需要验证这是否真的正确。所以我要点击其中一个，然后它会带我到来源，然后我会在来源中找到这个信息。然后它会进一步带我去看实际的州政府网站。</p>
<p>它的工作方式是，它基本上会持续更新，以确保我们拥有最好、最新的法规。我们可以向它们提问，可以验证，然后还有反馈循环。我们可以说，“是的，那很好，那是正确的”，或者如果它在某种程度上不正确或引用错误，我们就会给它一个差评，并说明为什么不正确。我们也可以说是否有不当语言返回，这也是我们负责任使用人工智能的一部分。到目前为止，结果非常令人兴奋。</p>
<p>我们的影响力在于，我们基本上能够有效地扩大我们的团队。我们不能一直增加人手来应对这个问题，而且州一级的法规只会越来越多，这确实让我们难以跟上。一个经验教训是：当我们连接到这些州政府网站时，各个州的做法都略有不同。有些返回HTML，有些返回PDF、DOC；有些有安全设置。有时我们必须通过API（API（应用程序编程接口）：一套允许不同软件应用程序相互通信的规则。）访问。所以阿曼迪普在开始时确实需要手动操作一些，但现在我们站稳了脚跟，他将利用人工智能来加速他的工作，以便我们能引入其他业务线。我们只希望每个有法规问题的人都能从这里开始，向它提问。我们随时准备提供更多背景信息，进行更深入的探讨，但我们认为这确实能为客户节省大量获取答案的时间。现在我可以把话题交给哈泽尔，谈谈RAI（负责任的人工智能）。</p>
<p><strong>哈泽尔·弗洛伦西奥：</strong> 是的，关于负责任地使用人工智能，我们将确保有详细记录的指导方针，说明如何使用Reggie以及Reggie所拥有的数据。我们还在用户界面中加入了免责声明，正如玛丽试图演示的那样，提醒人们必须始终验证人工智能的答案。我们还将通过报告和我们收到的反馈，继续监控和评估Reggie。未来，我们还将进行LLM（大型语言模型：一种基于海量文本数据训练的人工智能模型，用于理解和生成类似人类的语言。）审查，以防有其他或更新的人工智能模型更适合Reggie。在安全方面，目前我们只使用由法规团队批准的来源和内容。此外，Reggie目前仅限内部访问。我们设置了白名单，只接受VPN或办公室流量。另外，我们可以利用Azure AI内容安全功能来增强Reggie的安全性，例如阻止有害的输入或输出，或者在需要时创建自定义的人工智能过滤器，以及可能探索处于预览阶段的“基础性检测”功能，以帮助检测和避免人工智能编造内容等。</p>
<p><strong>玛丽·亨舍尔：</strong> 好的，下一步是什么？下一步是，我们很快就会加入我们其他的业务线：专业护理、药房等等。阿曼迪普要做的另一件事是，他将实际高亮显示法规中发生变化的语言，以便于一目了然地找到。我们将增强反馈功能，以获得更详尽的答案，所以有时我们想提供更多的背景信息。我们希望能够手动上传一些文件。对于某些用例，州政府有时会发布提供者信函或公告，其中包含更多关于法规的背景信息；我们也想上传这些。然后，展望未来，我们真的想开始生成行动，例如，自动创建一个Jira工单，或者自动创建一个Salesforce案例，或者创建一个法规简报。而且，你知道，展望更远的未来，我们有可能在某个时候向我们的客户提供这个服务。就像我说的，现在市面上已经有商业化的工具，人们正在付费使用，这甚至可能成为我们的一个收入来源。借此机会，我要感谢我们法规事务团队的成员，他们一直与我合作这个项目：Tatiana Vasilieva, Robin Roberts, Janiece Hornberger, Jackie Nordhoff, 我自己，Eugene Gonzior，当然还有Donna Weimer。</p>
<p><strong>哈泽尔·弗洛伦西奥：</strong> 技术与支持服务团队的成员包括：Amandeep Chaj、Andrew DeNirum、Clyde Gonsalves、我自己以及Rahim Ashwani。</p>
<p><strong>玛丽·亨舍尔：</strong> 好的。就这些，有什么问题吗？如果有人想亲眼看看，随时告诉我，我可以带你参观演示。</p>
<h2 id="section-3-zh">三、主题演讲：人工智能的经济影响与企业战略</h2>
<p><strong>艾伦·米森：</strong> 谢谢。我感觉戴夫比我更像主讲人。我只是想和团队分享一些见解。感谢给我几分钟时间，在迄今为止非常出色的用例和演示之间稍作休息。我喜欢我们迄今为止在试点和尝试人工智能方面所展现的多样性。我知道我今天的一个目标是让每个人都能学到东西。我知道在第一个小时的展示中，我已经学到了很多。所以希望你们和我一样收获满满。</p>
<p>今天开始时，我和戴夫来回交流时引用了一些名言。我想从一些关于人工智能的有趣事实开始，从几个不同的维度来看。首先是全球范围内关于经济影响和增长的情况。其中一些我之前已经提到过，但如果你看一下全球人工智能市场，去年年底公司的估值约为五千亿美元。预测的增长轨迹是每年约37%。我从事过11个行业，从未见过一个计划在7年内实现37%的复合年增长率。这真是难以置信。我们在一个非常短的时间内看到了一个1.8万亿美元的人工智能公司估值。当我们看到到2030年它对全球经济的预计贡献时，预计将达到近16万亿美元。一些数据显示，这将超过中国和印度的经济总量之和。我认为迈克昨天提出的这个想法，关于“这是否是一时的风尚？”这显然不是一时的风尚。</p>
<p>在生产力方面，预计人工智能将在未来几年内将员工生产力至少提高40%。另一个非常有趣的问题，因为许多组织都在为此苦苦挣扎，是它的价值，即投资回报率。有时候这有点棘手，特别是对于像Copilot这样的实用工具。你每天给某人节省15、20、30分钟的时间。这对一个组织来说如何转化为真正的价值？但是，那些非常有针对性地使用人工智能的组织，开始在投资回报率方面看到转机。74%的组织使用一些更先进的人工智能项目，达到了或超过了他们的投资回报率预期，其中20%的投资回报率实际上超过了30%。我认为这表明我们真的需要深思熟虑。我喜欢实验和我们正在尝试的各种事情的广度，但我确实认为，我们旅程的一部分是对那些对业务最有意义的事情进行优先排序。然后，你知道，戴夫也稍微谈到了这一点。人工智能已经非常、非常迅速地成为资金投入最多的领域。已经有三分之一的风险投资资金直接投向了与人工智能相关的公司，而且是在一个非常、非常短的时间内。它在短短一年内成为第一大领域，这非常引人入胜。</p>
<p>如果我从使用的角度看下一个动态，这更多的是商业用途的视角，到2024年底，约有72%的企业报告在至少一个职能部门使用人工智能，这比2023年有了显著的飞跃。同样，生成式人工智能的采用率也飙升，到2024年底，约有50%的企业使用它们，比2023年增长了33%。所以使用的加速，我们正在看到这一点，拉希姆和我也在一些我们现有的工具（如Copilot）上看到了这一点。我们看到了一个非常积极的利用率增长。仅作另一个数据点，生成式人工智能的年同比增长33%，超过了智能手机的初始采用率。这又是另一个证明这不是一时风尚的观点。这绝对会持续下去。</p>
<p>说到设备，现在将近77%的设备都在使用某种形式的人工智能。前三大商业用例，我想对任何人来说都不会感到惊讶。我们今天已经看到了其中的一些。在效率方面，节省时间是首要任务。内容创作方面，市场营销团队一直在大量使用。产生想法是另一个重要的用例，当然还有简化流程。这些都是常见的应用。在企业界，到目前为止在价值方面受到最积极影响的三个领域是客户支持、软件开发（跨越多个维度，如代码生成、测试，甚至用例开发）和市场营销。这三个领域到目前为止价值最大，尽管我们看到这个代理式旅程的到来，它确实正在影响大多数组织的每个职能部门。顶级工具，ChatGPT，毫不意外，Copy.ai和Jasper AI是在消费者和商业领域使用最多的前三名。</p>
<p>如果我从劳动力的角度看下一个动态，以及这对劳动力有何影响，你听到戴夫之前提出了一个我认为很有趣的评论，关于我们所有的职位描述都在随时变化。我认为这是一个非常有趣的评论。如果我们思考一下创造就业和失业，就业方面将会有很多变动。一些工作可能会消失，但由于人工智能，新的工作岗位正在出现，因此我们每个人作为个体，在自己的个人学习旅程中都应该走在前面。目前普遍认为，由于人工智能，净就业人数实际上将增长10-15%，但很可能会有一些工作岗位消失，同时创造出大量新工作岗位，从而出现相当大的变动。另一件有趣的事情是技能差距。早期的用例之一，特别是在学习方面，实际上是帮助弥合低技能和高技能工人之间的技能差距。我过去见过最明显的例子是，我曾经管理过大型呼叫中心，让一个新来的代表变得富有成效需要相当长的时间。现在，人工智能确实在帮助加速像那样角色的人员变得富有成效，所以他们能更快地成为知识工作者，而不是需要3-5个月的时间，他们能在30到60天内达到那个水平。所以看到这一点真的很有趣。</p>
<p>在社会层面，以及消费者如何看待人工智能方面，84%的美国人实际上每天使用一种或多种由人工智能驱动的设备或服务。55%的美国人每周多次定期与人工智能互动，但只有34%的消费者意识到他们实际上正在直接体验人工智能，我觉得这很 fascinating。虚拟助手是人们互动最多的领域，比如Alexa和Siri。我在与戴夫的聊天中提到过，大约50%的消费者对人工智能持乐观态度，但截至今天，他们中有四分之三的人实际上非常担心错误信息。所以，你之前听到戴夫谈到的那个信任因素，我们所做的RAI（负责任的人工智能）角度，对于在内部以及与客户之间建立信任至关重要。</p>
<p>当我审视医疗保健领域时，我们之前也谈到过一些。戴夫也提供了一些观点，但在我查阅的一些研究中，看到人工智能已经开始在诸如脑部扫描准确率提高一倍、骨骼扫描等方面产生巨大影响，这真是令人震惊。所以，基于人工智能的扫描技术似乎能提供更好的结果，为客户带来更好的治疗效果。门诊评估也是如此。另一个令人着迷的方面是，戴夫提到了预防性治疗，即在患者没有表现出任何症状的情况下进行疾病预测。他们正在讨论人工智能能够预测数千种疾病，在人类开始感到任何症状之前，通过捕捉其他数据信号就能提前发现。这对我来说太 fascinating了。围绕分诊和帮助医生更快地进行分诊的临床聊天机器人。当然，还有一个我们非常关心的地方，那就是大量的行政负担减轻。显然，这在产品方面是我们旅程的重要组成部分，但像微软和谷歌这样的公司也在其中扮演着关键角色，特别是在医疗保健领域。</p>
<p>我只想展示这张幻灯片一秒钟。这是我们的合作伙伴H&F给我们的。我喜欢私募股权公司的其中一点是他们往往非常直接。所以这不仅仅是一种“艺术的可能性”的对话。它更像是，“这是赢家，所以这是你作为组织应该绝对关注的地方，但这也是实验的方向。”这里列出的三大领域，我们已经提到过了。在软件开发方面：编码、测试、安全、项目规划。我想说，在PCC，我们已经开始在很多这些方面看到价值了。虽然现在还为时过早，但我认为无论是在企业技术职能部门，还是在比尔的工程团队中，我们已经开始看到一些价值、一些实验，但也有一些实际的生产力提升。我们甚至在早期项目工作中也看到了价值。我们在OCIO内部做了很多工作，围绕着收集需求、构建用例，并利用人工智能将其转化为项目。所以在软件领域有很多活动，有很多有价值的用例。</p>
<p>客户服务确实是拥有多个直接面向客户的用例的顶级领域，我们正与Elaine和客户支持团队非常积极地合作，围绕我们的一些构思和路线图来帮助他们。然后，市场营销是另一个在利用人工智能方面绝对爆发的领域。我之前提到了这个围绕内容创作的“创意盟友”的想法。有一个例子，一家小型初创公司试图完成大量社交帖子，他们实施了一个人工智能助手来帮助他们。他们在几个小时内完成了50篇社交帖子，而这通常需要他们的员工大约一周的时间来完成。所以，生产力大幅提高。这是在驱动方面。在实验方面，很有趣。我认为这个数据甚至在幻灯片创建后就已经改变了，因为他们肯定指出了很多围绕这种代理式推动和平台推动的实验，今天早上你已经看到了几个例子。我们有合作伙伴和供应商提供我们可以利用的功能。我认为Pam给出的Gainsight例子非常棒。所以你现在看到这开始影响到所有其他公司职能部门。在驱动方面，迄PCC今为止的赢家都集中在一个比较有限的名单上，但你可以在这个实验栏中看到，它真的开始影响到每个人，所有供应商的平台推动和正在发生的代理式推动确实在驱动着很多东西。</p>
<p>到目前为止，PCC的旅程是怎样的？我想说，我们的AI企业战略，迪恩和团队显然早些时候就在产品方面着手了。我们的旅程大概始于15或16个月前。早期，我会说它非常注重助手功能，因为当时的技术水平就是这样。它很大程度上是围绕GenAI能力的问答之旅，比如微软Copilot。它以个人生产力为中心。在24财年，我们启动该平台的第一年，可能有大约10万次Copilot请求，根据我喜欢称之为“微软数学”的算法，他们估计这大约相当于整个组织每位员工每周节省10到15分钟的时间。在25财年，这个数字发生了巨大变化。我们可能会有超过25万次Copilot操作请求，以及另外15万次LLM操作、GPT操作。其影响似乎在5万到6万小时的“辅助小时”或时间节省范围内。所以这让我们从每周节省10到15分钟，增加到看起来接近30分钟。这实际上是年复一年在使用和采用Copilot方面相当不错的增长。你们中有92%的人在持续使用它。即使在最近几个月，我们仍然看到更强劲的加速。自1月以来，我们在Copilot操作方面看到了约125%的增长，辅助小时也翻了一番。</p>
<p>在提示和价值方面，人们目前看到最大价值的领域绝对是与会议相关的。这绝对是列表的首位。它可能占了50%到60%的价值。所以，那些会议摘要之类的东西绝对是首要的。企业搜索是另一个有趣的领域。它在今天的使用中占了很大一部分，我觉得这很有趣，因为现在流传着一个关于人工智能的口号，说：“人工智能是新的用户界面吗？”就像谷歌用一个非常简单的用户界面——一个搜索栏——改变了搜索动态，极大地改变了那种体验一样。人工智能和智能体是否也会改变这一点？你听到戴夫说，我们正在超越人类输入的时代。围绕消费语音数据、执行任务或带回信息有很多活动。传统的员工内部网的想法会消失吗？我们实际上开始在Copilot上看到这一点，人们在Copilot中开始人力资源旅程或提问，将其作为他们的用户界面，而不是去一个更复杂的网站。电子邮件是第三个我们看到大量使用的领域。</p>
<p>我在这里列出的另一个领域是Spark。Spark与你刚才看到的Reggie工具非常相似，但我们去年是从客户服务团队开始的。这对于Rahim的团队来说，其实是一个实验。它是一个基于知识的工具，提供自然语言回复，但我们有点把它作为团队的“盟友”加入。所以它不是在取代客服代表；它实际上是帮助客服代表在回答客户问题时变得更好、更快的一个工具，我想去年它在处理客户服务团队的事务中支持了超过15万个问题。我们通过它看到了平均解决时间、客户满意度和客户努力方面的改进。所以，这是一个小小的实验，但实际上确实带来了一些不错的价值。我们开始越来越多地看到的另一件事是，我们谈到的另一个部分，即应用世界。应用合作伙伴开始在许多领域崭露头角：分析、流程自动化，当然还有软件开发和安全方面。你在这里看到的是2024年向我们提供解决方案的一些供应商。我称之为一波浪潮，但2025年似乎更像一场海啸。我想我之前分享过这个数据点，但实际上在未来6到12个月内，预计80%的软件平台都将具备人工智能功能。因此，你听到戴夫谈到我们既有机遇，坦率地说，也有威胁。如果他们不把钱花在我们身上，他们可能会花在竞争对手身上。从产品方面来看，我知道大家对推出更多能帮助我们客户的工具充满热情。我确实认为，发生的情况是，不仅我们的客户，我认为所有客户的期望都在围绕这一点发生巨大变化，并且期望软件供应商上门时能提供人工智能功能。我想我们内部正在讨论的一个问题是，我们现在是否应该在RFP（征求建议书）中将其作为标准？如果你没有人工智能能力，并且没有积极的路线图，你可能不会被纳入评估范围。所以这是一个让我们在推动合作伙伴方面可以有不同思考方式的方法。</p>
<p>所以，如果我今天来看PCC，在一开始，右侧我们看到的是更像海啸的景象。我想在24年，大概有十几个供应商来找我们谈论人工智能能力。我想说，我不知道我们是否达到了80%，但感觉上现在80%的供应商都在敲我们的门。Gainsight就是一个很好的例子，Pam展示的那些功能，我们刚刚才启用。所以我们有无数关于我们合作伙伴的故事，我确实认为，从这个群体的角度来看，这也是我们应该学习的一部分。我们如何成为我们已有工具中人工智能能力的专家？智能体构建和创建智能体是一个很好的例子，但我认为真正成为Gainsight人工智能如何运作并增加价值的专家，对我们来说也非常重要，因为我们已经在这些平台上进行了重大投资。</p>
<p>如果我思考一下我们今天的处境，我想，正如我之前和戴夫聊天时提到的，我们实际上有很多活动正在进行。我们知道的大约有16个，可能比这个数字还多。我们今天大约有16个职能团队，他们正在进行1到10个不同的用例，他们在尝试、试点。有些已经上线，有些还处于构思阶段。所以我们有超过70个独特的用例，其中很多你们今天都会看到。它们处于不同的进展阶段：构思、概念验证、试点，还有很多已经上线了。我们正在研究的能力在这些用例中非常多样化，我想你们在今天接下来的时间里会对此有一个很好的了解。所以其中一些与洞察力有关。这些平台中的语音和对话智能能力正在飞速发展。我想在SLT会议上，我说过在SLT会议前30天，我们只有一个平台具备对话智能能力。今天，我想我们有五个。这大概是在60到90天的时间里。所以有些东西正在爆炸式增长。我们有人们正在研究的副驾驶。我们有人们正在研究的智能体开发。我们有Cedric正在研究的，令人着迷的智能体基础框架。然后我们甚至有智能体开始与智能体对话，我认为这是一个游戏规则的改变者。你之前听到戴夫谈到过。所以现在不同生态系统中的智能体实际上能够相互交互，这是即将出现的新事物。我们本周刚听到Salesforce关于这件事的重大宣布。如果我们想让微软的智能体与Salesforce的智能体对话，现在这是可能的，而3个月前还不是。所以，这非常令人兴奋。我们有代码生成、客户体验人工智能活动，还有很多其他事情。</p>
<p>我想说我们既有购买工具的活动，也有构建活动，所以两者结合得很好。这很多，但我想说，我们正在努力做的一件事，我认为今天是其开始，就是真正地加速这些想法从构思阶段到实际行动、执行和价值的转化。我们似乎有很多想法还处于早期阶段，正在被尝试或讨论。我们必须能够更有效地完成“我们应该或不应该”的这些周期。我想说，我们一直相当缓慢，我一直回到戴夫对组织速度的热情上，这绝对是我们即使有很多实际活动也需要关注的领域。而且，你知道，我认为我们有活动的另一个领域，辛迪和我今天早上简要地聊过，就是人力资源团队和学习团队带来了一个非常强大的人工智能课程。有数百门课程可供你们选择。所以，如果我们思考这个对话的起源和学习在讨论中的核心地位，我认为我的一个行动项目，我认为也应该是我们所有人的，就是真正利用这些内容，真正开始关注实际的学习和加速我们的学习，并使用我们拥有的工具，并真正帮助告知，将这种赋能能力提升到下一个水平。</p>
<p>所以，在我总结的时候，我想先提出一些想法，或许从我们每个人作为个体开始，然后可能再延伸到一点企业的人工智能优先文化。我认为我们每个人都有个人的旅程，也有一个围绕这个的公司旅程。我确实认为我们应该问自己，我们每个人都应该在今天的会议上离开时真正问自己，我们每个人能做些什么来最大化我们的影响力？我在这里的小口号是，“我们如何利用人工智能来AYI——加速你在组织中的影响力？”对我来说，这是一种对学习、合作、实验的承诺。我们有一个CEO昨天与我们分享说他一直在构建智能体，我认为这是一个相当酷的领导力示范，让我们看到我们应该如何应对这个问题。再次，我认为今天就是关于学习。</p>
<p>如果我从文化和公司的角度多想一点，现在的一个热门词是“AI优先文化”。我对AI优先文化的定义是，将AI作为组织中每一个重大决策、创新和流程的一部分，并且它是组织运作的核心。你之前听到戴夫问我一个问题，关于我们如何思考AI在P2C中的应用。我们已经讨论P2C作为转型项目好几年了，现在我们正处于交付的核心阶段。但一个AI优先的组织会开始应用它，“嘿，我们不要等到做完了再考虑AI。让我们看看现在能做什么来应用它。”所以我认为这是一个非常有价值的思考AI优先文化的起点。我认为AI优先文化也需要对AI有深入的了解：它的优点、缺点、潜在影响是什么？我们需要深思熟虑。这又回到了学习的旅程。它还，戴夫谈到过，是关于重新思考和重新设计工作流程。其中有自动化的方面，但它确实是关于重新思考和重新设计工作。我有点把它等同于，它实际上是拥有精益六西格玛思维模式和应用AI工具的结合。所以我认为这是我们发展这种AI优先文化时需要考虑的另一个重要部分。</p>
<p>我确实认为这也意味着适应并将人工智能作为你日常工作的一部分。Copilot的增长就是一个很好的例子。我们开始看到人们越来越多地使用那个工具，但我认为我们每个人都应该思考，我如何为自己创造一个人工智能习惯？有很多关于如何创造习惯的书，所以我不会详细说明，但我认为我们都应该思考我们如何在生活中围绕人工智能创造那种日常习惯。我也认为文化的一部分就是我们今天正在做的事情，鼓励团队与人工智能合作。今天的会议就是那种个人承诺于持续学习、与人工智能共同发展的典范，我认为这是我们思考方式中一个非常重要的方面，我认为这是成长心态的自然延伸。你今天早上又听到戴夫提到成长心态。</p>
<p>如果我从战略角度多考虑一点，任何战略的首要任务都是领导层的承诺。再次，如果戴夫和迈克的对人工智能的承诺不明确，我不知道你参加了什么会议，因为从组织最高层来看，这已经再清楚不过了，这是一个首要任务。我们目前在公司层面关注的另一件事是愿景，即公司愿景，并制定一个更稳健的战略，以帮助人们理解愿景以及一些指导方针。当我审视我们的公司愿景时，我有两三个想法正在浮现。我们的目标是通过用人工智能增强人类潜力来改变我们的工作场所，以加快我们的步伐，增加我们的能力，并提高我们的效率。这基本上是核心。从战略或公司的角度来看，这也意味着投资，我认为我们今天正在投资时间。我欣赏这个组织的一件事是，当投资有意义时，领导层从不犹豫。所以，投资于培训和工具是首要任务，再次，我认为PCC在这一点上比我去过的其他组织要出色得多，他们不怕进行这些投资。</p>
<p>我认为这确实意味着在人工智能规划方面需要更加稳健，越来越多地制定一个强大的人工智能路线图，我们有一些想法，如何帮助各职能部门加速他们正在做的工作，比如在未来几周内进行各职能部门之间的对话。我们谈到了工具、培训、数据和道德方面的赋能。我认为这是战略的另一个关键部分。然后可能发生的另一件事是，这可能会导致，戴夫之前提到职位描述可能会改变。这是否可能导致一些适度的组织设计？我不知道。你是否会创建卓越中心？你是否有更多的跨职能结构来实际加速？所以，这些是我们正在思考并试图在战略方面获得更多细节的一些事情。</p>
<p>我可能会用另一句名言来结束。我喜欢我的名言。“人工智能不是要取代人类，而是要增强人类的潜力。”我真的认为这与你从戴夫和迈克那里听到的东西有关。迈克昨天评论说，这段旅程的重点是提高我们团队的速度、质量和效率。我认为这是PCC旅程中一个非常重要的方面。速度，你今天早上在我们的对话中听到戴夫提了三两次速度，所以这真的比任何事情都更重要，是提升我们的潜力。</p>
<p>最后的想法。今天是关于想法和可能性的艺术，再次，我希望今天每个人都能学到一些东西，接触到你以前没有想过但你认为可以应用的想法。但我也希望每个人离开时都带着一些问题。金在SLT会议上实际上提出了这些问题，所以我不会居功，但我认为这些问题对我们所有人今天离开这个会议时思考都非常有益。所以你如何设想人工智能在你和你的职能中的角色演变？从个人层面以及你所从事的职能层面来思考。人工智能如何推动团队创新？人工智能如何融入你现有的流程？人工智能可以帮助我们解决哪些具体挑战？我们正试图回到这些职能对话中。我们相信其中一部分是痛点分析，所以我们认为这些会议会有所帮助。人工智能在市场上能为我们提供哪些竞争优势？我知道戴夫现在99%的思考都在这方面，我对此感到非常有信心。然后我们可以利用哪些合作伙伴关系来提升我们的人工智能能力？早些时候，我谈到有多少供应商现在正带着人工智能能力来敲门。所以我们当然应该利用这一点，了解哪些合作伙伴可以帮助我们，或者是否有一个解决方案集成商，他们有学习经验和一些关于他们为客户提供人工智能能力的好故事。所以也要考虑我们可以利用的合作伙伴来帮助我们。说了这么多，感谢今天让我分享我的想法，让我们继续研讨会。</p>
<h2 id="section-4-zh">四、人工智能用例展示：第二部分</h2>
<h3 id="section-4-1-zh">ReliaQuest GrayMatter Agentic AI 用于安全运营</h3>
<p><strong>凯特基·耶内马迪：</strong> 首先是来自安全与信任团队的迦勒和克里斯蒂。他们将为我们介绍ReliaQuest GrayMatter Agentic AI。</p>
<p><strong>刘克里斯蒂：</strong> 我叫克里斯蒂，和我一起的是迦勒。我们都来自安全运营团队。我们专注于处理网络钓鱼邮件以及涉及用户和终端的各种调查，比如可疑登录、账户问题或设备上发生的任何异常情况。今天，我们将讨论如何利用智能体人工智能来加速和简化威胁检测。看这张幻灯片，你可以看到我们日常使用的工具有多少。我们使用像Defender、CrowdStrike、Sentinel、Wiz和Mimecast这样的平台。它们对我们的工作都很重要，但每个平台都有自己的界面，每个工具以不同的方式显示数据。这意味着调查可能需要更长的时间，因为我们需要来回切换。有时我们需要在不同的平台中运行多个查询，并试图手动将所有内容拼凑在一起。我们意识到了这个挑战，并且可以做些什么来改进它。因此，我们购买了ReliaQuest，并将所有日志源输入ReliaQuest。现在ReliaQuest成为了中央平台。它从所有这些工具中提取数据，并使用人工智能对数据进行规范化，我们只需要在一个地方工作。因此，在许多情况下，调查时间从45分钟缩短到了大约20分钟。我们现在有了可重用的 playbook 和清晰的流程，这使得团队中的任何人，无论新老，都更容易上手。</p>
<p>这张幻灯片展示了ReliaQuest如何使用智能体人工智能来调查警报。当警报出现时，流程从规划器组件开始。它就像系统的大脑。它会查看警报的上下文，了解环境，是否有任何类似的过往警报等等。然后它会决定如何进行调查。在规划阶段之后，它会把任务交给实际采取行动的系统部分。这部分会运行搜索，使用工具，并承担执行调查的繁重工作。现在，根据流程中发生的情况，我们会得到三种可能的结果之一。如果结果不清楚，或者某些地方看起来不对劲，系统会回到规划器重新思考方法。如果一切看起来都好，它会建立一个可重用的剧本。如果这不是一个真正的威胁，它会将其标记为误报。这就是智能体人工智能流程在宏观层面上的工作方式，从规划到行动再到结果。我将把它交给迦勒。他将在演示中展示几个例子。</p>
<p><strong>迦勒·瓦尔德玛：</strong> 谢谢，克里斯蒂。我将介绍两个我们使用智能体人工智能的警报示例，这两个示例极大地缩短了调查和解决的平均时间。第一个例子是修改一个敏感文件。如果没有智能体人工智能，这将花费我们很长时间来调查，可能是一个小时，也可能是三个小时，因为我们必须像克里斯蒂之前展示的那样，在多个不同的工具之间切换，查看不同的日志，并试图关联哪个用户执行了此活动以及它发生在哪个设备上。然而，有了智能体人工智能，警报触发后，智能体人工智能可以查看它并采取主动行动。人工智能和智能体人工智能之间的最大区别在于，智能体人工智能能够在没有太多人为干预和指导的情况下采取更主动的措施。因此，ReliaQuest的智能体人工智能会主动生成一个调查计划。它会主动地在我们集成的所有工具中进行切换，然后寻找相关的日志和活动。它会分析攻击者可能执行的不同命令行，以便为我们提供实际发生情况的纯文本描述。它会自动到互联网上丰富可疑的网站、URL或文件，告诉我们它是否认为它们是可疑的。然后它还会给我们一个最终决定，判断这个活动是否是恶意的。</p>
<p>这只是另一个类似警报的例子，但这次是真的阳性。我认为我所见过的智能体人工智能提供的最大好处是，它帮助我们让PCC的所有用户更顺畅地运行。所以，如果一个用户或设备在攻击中受到影响，或者他们点击了一封钓鱼邮件，智能体人工智能能帮助我们更快地让用户恢复正常运行。而在以前，我们必须手动禁用账户，进行可能长达一到三个小时的调查，执行补救措施，并最终让一切恢复在线。但有了智能体人工智能，在我们安全分析师调查警报之前，人工智能就已经介入并调查过了。“好的，这是一个被入侵的用户。他们确实点击了一封钓鱼邮件，”或者像这里看到的，“他们确实执行并运行了这个可疑文件。”然后它能主动为我们隔离或暂停用户的设备，还能主动重置密码。所以，当警报真正到达我们这里时，用户的账户已经被重置，恶意邮件也被隔离了。</p>
<p>因此，正如克里斯蒂之前提到的，对我们来说最大的影响是将我们收到的大多数警报的调查时间缩短到20分钟以内。我们收到的警报比以前更有价值。所以，以前的供应商，我们使用的前一个MSSP，他们基本上会说，“好的，这个用户做了这个活动，你们处理吧。”但有了智能体人工智能，它能够说，“嘿，这个用户执行了这个活动。他们还被看到执行了另一个看起来可疑的相关活动。”人工智能能够为我们做出决定，说，“嘿，综合来看，我相信这个用户的活动表明了妥协或没有。”</p>
<p>我认为我们学到的最大教训是，人工智能不是万能的。你不能让它永远运行而不提供主动反馈。对于ReliaQuest的智能体人工智能，我们为它发送的每一次升级都提供主动反馈。我们会就人工智能的分析是否准确、是否提供了正确的数据、是否缺少了我们希望看到的数据点等提供反馈。当我们向人工智能提供这些数据时，它能够主动学习并适应我们真正希望它运行的用例。我认为这是最大的好处之一，能够主动训练或教导人工智能，使其最大限度地为你服务。在帮助PCC的其他人方面，我建议你从日常工作中退一步，看看你非常重复、频繁地做的那些手动或琐碎的任务，哪些可以自动化，或者你可能可以用人工智能来为你执行。对于我们和负责任地使用人工智能，对于ReliaQuest的智能体人工智能，人工智能采取的每一个行动，我们都有严格的指导方针。所以我们只有特定的预先批准的 playbook 和人工智能能够采取的行动。所有的行动都被记录和保存，然后我们能够调查为什么这个人工智能在这个特定的警报上做出了这个决定。如果出现任何问题，我们能够主动与ReliaQuest合作，对人工智能进行改进。欢迎大家提问。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 太棒了，迦勒和克里斯蒂。我们在问答区有一个问题给你。除了节省时间，这个工具有多准确？你用它发现了更多的真阳性吗？误报有没有引起任何问题？</p>
<p><strong>迦勒·瓦尔德玛：</strong> 这是个很好的问题。我想说它非常准确。误报相当少，因为智能体人工智能在分析警报时，如果确定它们是良性的，就会主动将其作为误报关闭。我们会对那些已关闭的警报进行审计，并验证它们是否被正确关闭，我个人还没有看到一个我认为不应该被关闭的、由智能体人工智能关闭的警报。它可能是一个值得注意的事件，但绝不是恶意的。</p>
<h3 id="section-4-2-zh">利用 Gong 和 Copilot 重新构想客户规划</h3>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 接下来我们有黛西，黛西，请讲。</p>
<p><strong>黛西·杜尔：</strong> 好的。谢谢。我是黛西，一名赋能项目经理。我设计和管理项目，旨在赋能销售和客户成功等面向客户的团队，让他们能发挥出最佳水平。我的重点是提高效率、提升生产力，并创造真正支持我们收入目标的学习体验，无论是增加销售渠道、提高客户保留率，还是帮助团队自信地驾驭复杂流程。我与销售、客户成功、专业服务、产品和市场营销等部门跨职能合作，构建可扩展的培训路径，推出新工具和工作流程，并确保团队在适当的时间获得成功与客户合作所需的一切。今天，我将分享我们如何利用人工智能重新构想一个核心工作流程，具体来说，就是我们如何帮助客户主管通过使用他们已有的工具，节省数小时的规划时间。没有新平台，没有陡峭的学习曲线，只有一个更智能、更有意图的方法。</p>
<p>今年，我们为企业客户服务团队（如销售、客户支持和专业服务）推出了一个新的客户互动模型。目标是在我们支持客户的方式上创造更大的一致性和协调性，特别是在更复杂的战略客户中。随之而来的是需要一种更结构化、更透明的跨团队协作方式，这就是客户规划的用武之地。作为这个新模型的一部分，我们引入了客户规划作为一项关键举措。简而言之，客户规划是一份共享文件，帮助团队明确客户目标，识别风险和障碍，规划关键利益相关者，并记录我们计划如何战略性地与客户互动并发展业务。但我们很快意识到，创建这些客户规划虽然重要，但也非常耗时。客户主管告诉我们，这需要3到5个小时，而大部分时间都花在总结他们已知的信息上，而不是制定战略。所以我们有一个旨在支持更深层次互动和战略的关键举措，但它没有得到有效扩展。这就是我们需要解决的挑战。我们不想放弃这个流程；我们只是需要现代化我们支持它的方式。这促使我们利用人工智能重新思考工作流程。</p>
<p>我们没有引进任何新工具，只是充分利用了我们已有的资源。对于可能不熟悉的人来说，Gong是我们的对话智能平台。它捕捉和转录客户通话，然后利用人工智能来发现趋势，比如正在讨论哪些话题、客户说了多少话，甚至风险或动力的指标。Quip是我们的协作工作空间。客户主管和其他面向客户团队的成员在这里记录客户计划。它是实时的、可编辑的，并且与上下文相关。它还直接与Salesforce集成，因此它成为工作流程的一部分，而不是一个额外的步骤。我们所做的是引入了一个连接这两者的工作流程。Gong为我们提供洞察力，而Copilot则帮助将这些洞察力构建成一个准备好用于Quip的客户计划草稿。这里的目标不是自动化思考，而是节省代表们在总结和格式化上的时间，以便他们可以专注于战略。重要的是，每个计划仍然经过人工筛选。代表们会进行调整和修改，使其成为自己的东西。这仍然是他们的声音，只是有了一个开端。</p>
<p>在向您展示工作流程之前，我想快速强调一下我们通过重新思考方法所取得的成果。首先，我们将过去需要3到5个小时才能完成的客户规划任务，变成了一个销售代表在大约15分钟内就能启动的工作。这一转变让他们有更多时间专注于战略，而不是文档记录。他们可以花更多时间思考如何推动客户关系向前发展，而不仅仅是记录已经发生的事情。我们还引入了一个可重复的 playbook，这意味着团队不再需要从零开始，领导者也可以更轻松地指导一个一致的流程。在此过程中，我们改善了数据卫生。在推广这个流程时，我们发现了一些联系人记录和CRM（客户关系管理：一种用于管理公司与当前和潜在客户的互动和关系的系统。）对齐的问题，否则我们不会注意到这些问题。这帮助我们清理了我们构建洞察力的基础。最后，这种方法是可扩展的。我们为客户规划构建的这套方法可以被客户成功经理用来协助制定成功计划，并收集其他重要的客户洞察力。好了，现在您有了一些背景信息，让我们进入演示环节。</p>
<p>大家好，我是演示黛西。我将为大家简要介绍一下这个工作流程。我已经预加载了所有内容，所以请记住，这可能比我们的客户主管实际操作要快一些，但对他们来说仍然是节省时间的。我已经准备好了一个客户账户，就在Gong里。提醒一下，Gong基本上是我们所有客户互动信息的唯一来源。它保存了我们的通话录音，也包括电子邮件互动。我们正在使用一个Gong摘要器，这基本上是一组提示，我们的客户主管可以一键使用。它会从客户通话和邮件中提取见解。我已经打开了客户计划摘要。需要注意的是，我们创建这个摘要是为了与客户计划模板中的标题保持一致。但基本上，客户主管会提示Gong提取这个摘要，然后它会再次从我们所有的通话和邮件中提取见解。准备好后，他们会全部复制并转到Copilot。我们构建了一个客户计划智能体，并嵌入了三个我们认为在构建客户计划时最能发挥作用的提示。第一个提示是“构建我的初稿”，它会把从Gong提取的信息转换成更适合客户计划的格式。你会注意到每个部分的顶部都有一个摘要，它基本上会删除Gong中项目符号列表中的任何冗余或重复内容。所以这里有摘要。所有内容仍然按部分构建，所以对我们的客户主管来说，复制粘贴非常容易。我想强调的一点是，客户主管在构建客户计划草稿时总是有机会进行审查。回到Gong，这不仅仅是审查要点。他们可以更深入地挖掘，弄清楚Gong具体是从哪里提取这些信息的。</p>
<p>现在我们有了初稿，或许客户主管想要优先考虑他们真正应该关注的部分。我们创建了一个提示，叫做“强化我的客户计划”，这个提示会让客户计划代理审查已构建的内容、哪些部分做得好，并逐节提供建议。你可能已经注意到，在那个提示库里还有第三个提示，它基本上允许客户主管将他们从Gong洞察中获得的信息与一个旧的客户计划结合起来。这真的为他们节省了时间，让他们不必从零开始，并且可以延续之前的客户计划。一旦他们对Copilot提供的内容感到满意，他们就可以开始复制粘贴到Quip客户计划模板中。正如我提到的，我们通过匹配标题，让这个过程变得非常简单。我想强调一点，我们特意省略了执行摘要，因为这才是我们希望客户主管花时间的地方。他们将在这里根据他们从Gong、Salesforce和各种不同来源收集到的所有信息，构建他们的摘要和观点。所以，这非常重要，因为我们有目的地使用我们的人工智能工作流程。它始终是一个支持工具，而不是最终解决方案，这通过省略执行摘要而内嵌在工作流程中。这就是我的工作流程，期待继续接下来的演示。</p>
<p>简单回顾一下，也放大来看，我们把过去需要好几个小时的任务变成了一个15分钟就能启动的开端。但这不仅仅是为了速度。真正的突破在于让销售代表有时间进行战略性思考，并消除了让规划感觉像是一件苦差事的障碍。我们使用人们已经熟悉的工具——Gong、Copilot——来构建这个流程，所以推广非常顺利，而且因为工作流程是可重复的，我们现在正在整个企业销售团队中推广它。但我们也付出了一些代价才学到一些东西，比如干净的CRM数据的重要性。Gong会浮现出与错误联系人相关的见解，这帮助我们发现并解决了更深层次的数据卫生问题。现在，我们正在为其他团队调整这个工作流程：成功计划、区域销售、基于价值的护理进展——任何人们被困在结构而不是战略上的地方。这对我们来说是关键。人工智能给了销售代表一个开端，但团队始终掌控着分享什么以及如何塑造它。人工智能提供支持，但绝不会取代他们的判断。在提问之前，我只想说几句感谢。首先，非常感谢Corey Fosco和Mark Bouchard。是你们在问我们如何为团队节省时间，帮助他们专注于真正重要的事情。这个工作流程的存在是因为你们在为你们的销售代表着想。Samantha Leckie，我的经理，感谢你鼓励我停下来，探索我们如何通过更好的工作流程来改进事情。你的支持为这项工作创造了空间。最后，非常感谢每一位测试、提供反馈并帮助塑造这个流程的AE。没有你们，我们不会有今天的成果。这是一次真正的团队努力，我为我们共同建立的成果感到非常自豪。好了，就这些，我很高兴能接受提问。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 我们聊天区里没有你的问题，只有赞美。有一个问题是：这个智能体是自主的，还是可以学习、调整和再学习？</p>
<p><strong>黛西·杜尔：</strong> 目前，我们构建的它不是自主的，它不会从任何东西中学习。我们基本上是基于提示来构建它的，因为这个智能体的目标是获取见解，并将其格式化以便于我们在Quip中进行客户规划。</p>
<h3 id="section-4-3-zh">人工智能驱动的利用率数据分析</h3>
<p><strong>凯特基·耶内马迪：</strong> 接下来，我们有珍娜。</p>
<p><strong>珍娜·帕利亚：</strong> 大家好！我是珍娜·帕利亚，销售赋能团队的销售赋能经理，今天我非常兴奋能和大家谈论我们的人工智能用例。我的项目是与解决方案架构师杰夫·赖特合作的。我们的人工智能应用将帮助市场推广团队轻松理解客户使用数据，并与客户就业务成果进行更有意义的对话。为此我们做了很多准备工作。例如，上周末我甚至第一次看了《回到未来》，所以我从未像现在这样准备好谈论先进技术。</p>
<p>我想从我们面临的问题开始谈起。360 Insights是一个非常强大的工具，它为我们提供了丰富的数据，包括客户产品使用情况和性能指标。然而，随着数据可用性的增加，高级护理销售和客户成功团队面临着一把双刃剑：信息量巨大，但解读起来也同样费力。销售代表们可能需要花费长达一个小时来解读单个客户通话的使用情况和性能数据。现在，在收入赋能部门，我们的工作是支持市场推广团队，他们的问题就是我们的问题。我们想找到一种方法，让我们的团队能够真正轻松地理解360 Insights中的数据，减少解读数据所花费的时间，并最终将这些时间还给他们，让他们专注于真正重要的事情：我们如何帮助我们的客户提供卓越的护理？于是，人工智能，我们的解决方案应运而生。</p>
<p>我们创建了一支人工智能智能体大军，它们可以为我们的销售代表在解读特定PointClickCare产品数据方面承担所有繁重工作。这些人工智能智能体将来自360 Insights的原始使用数据转化为趋势，然后这些趋势可以与客户的业务成果联系起来。我将把话筒交给我在这个项目上的合作伙伴杰夫·赖特，他录制了一个关于我们感染预防与控制人工智能智能体实际操作的简短演示。</p>
<p>我们一直在开发一个工具，旨在展示卓越成果与我们产品采纳和使用之间的关联性。这里的例子是我们的感染预防与控制分析器。简单来说，我们构建它的目的是为了测试应用程序是否能正常工作。显然，如果我们要更大规模地推广这个工具，我们希望直接连接到数据本身。所以，我将向您展示几个步骤，我们最终也希望将其自动化。但首先，我想向您展示的是，我们将获取一个客户的使用数据。我正在使用一个客户的数据，但我已经对其进行了清理，并确保我们只使用一个假名：CareCorp。所以，我将上传CareCorp的感染预防与控制使用数据，我要求它将这些机构分为绿、黄、红三组。绿色表示使用情况良好，黄色表示中等，红色表示使用情况需要改进。我们要求它将这些机构分组，这样我们就可以看到这些使用组与该工具应影响的结果之间是否存在关联。所以您可以在下面看到，我们有18个机构处于绿色区域，14个处于黄色区域，13个处于红色区域。下一步，我们创建了一个提示，允许我们上传结果数据，以便智能体去查看两者之间是否存在关联。所以，我将上传CareCorp的结果数据，几秒钟后，它会添加到那个表格中，并向我们展示绿色组、黄色组和红色组与感染相关的结果数据。所以，正如您在这里看到的，我们的绿色组在长期住院居民尿路感染百分比和患者因感染返回医院的平均百分比方面表现最好。您可以看到，在这个例子中，我们已经证明了我们解决方案的采纳和使用与这些建筑物的性能结果之间存在相关性。我们希望将此应用于更多的产品，而不仅仅是感染控制，并能够向我们的客户讲述这个伟大的故事。</p>
<p>谢谢，杰夫。很棒的演示。为了更深入地了解我们所看到的情况，总结一下，我们创建的人工智能智能体能够将CareCorp旗下的设施分为三类：红色代表我们的IPC产品使用情况不佳，黄色代表中度使用，绿色代表最佳使用。然后它能够识别趋势，发现处于绿色区域的设施，即那些最佳使用我们IPC产品的设施，表现出最好的结果。他们的长期住院居民尿路感染较少，因感染返回医院的患者百分比较低。因此，这证明了我们解决方案的采纳和有效利用与这些设施性能改善之间存在相关性。</p>
<p>需要注意的是，我们使用人工智能是为了寻找相关性，而非因果关系。虽然我们掌握了这些信息，这很好，但我们不能直接告诉客户，“如果你使用IPC，你的再入院率就会降低。”但我们可以向他们展示他们自己设施内部支持更好业务成果的趋势，并让他们将这些点与我们PointClickCare产品的使用联系起来。同样重要的是要提到，这些人工智能智能体并非旨在取代我们的销售代表所做的工作，而是赋予他们与客户就产品使用及其对业务成果的影响进行更有意义的对话的能力。现在，如果你在销售或客户成功部门，我知道你的问题会是：我到底什么时候才能尝试这个？对此，我想说，请继续关注。我们将在未来几周分享更多细节。这就是我今天想和大家分享的全部内容。我非常感谢你们的时间。我愿意接受提问。</p>
<h3 id="section-4-4-zh">Copado AI 用于软件开发生命周期</h3>
<p><strong>凯特基·耶内马迪：</strong> 接下来，我们有一个非常有趣且富有洞察力的用例，由OCIO的Lipsa介绍，关于一个名为Copado的AI智能体。我很好奇。Lipsa，请讲。</p>
<p><strong>利普萨·米什拉：</strong> 我是利普萨，OCIO的高级经理。这个人工智能工具是Copado AI，我想展示的是如何利用Copado AI来简化我们的软件开发生命周期，从需求接收到开发。我们在软件开发生命周期中有不同的流程。我们有规划、构建、测试，然后是发布和运营。我们想展示如何利用Copado AI来构建不同类型的智能体并实现它们的自动化。Copado AI平台使用五个智能体：计划、构建、测试、发布和运营。它如何帮助加速开发？然后评估质量，减少技术债务，从而提高团队生产力。</p>
<p>我将简要介绍一下我们目前的自动化流程。我们有业务分析师负责需求阶段。然后他们在Jira中创建故事。接着，工程师编写代码、重构、进行单元测试，然后我们将它们部署到生产环境。所有这些都可以通过Copado管道来完成和自动化。让我向您展示一个演示。特别感谢我的队友Damien和Rob，他们完成了这个演示。</p>
<p>利用Copado AI从多个会议记录中提取需求。首先，在一个新的聊天中，我将上传会议记录文件。加载完毕后，我们将输入以下提示：“假设您是一位顶尖的资深Salesforce业务分析师。请分析会议记录，提取已识别和感知到的关于潜在客户管理的业务需求，并使用MoSCoW方法提供一个清晰的句子。然后，生成一个矩阵，展示业务需求、痛点、用例、用例场景、角色之间的可追溯性，并以‘鉴于、当、则’的格式，将用户故事格式化为定义明确的验收标准。”如您所见，它首先使用MoSCoW优先级排序法提供需求，然后是可追溯性矩阵：业务需求、痛点、用例、用例场景、角色、用户故事以及每个故事的验收标准。如您所见，可追溯性矩阵中的业务需求是实际需求的概括版本，因此潜在客户评分模型实施必须实现一个能准确反映潜在客户质量和潜在价值的潜在客户评分模型。</p>
<p>好的，我将从Salesforce实施的角度演示Copado AI平台。我已经生成了聊天记录，因为这需要相当长的时间，但我将简单介绍一下这里突出的功能。所以，基本上，我给了我们的智能体一个提示，让它为我们创建一个用户故事，并给出了一些验收标准。这涉及到一个案例的添加以及在添加评论时将案例状态重新打开为“进行中”。如果案例已关闭超过10天，则用户无法添加评论。它按照我要求的格式写出了用户故事，给出了一些验收标准，并提供了一些技术考量。然后我切换到构建智能体，这是一个可以实际编码的智能体，我让它在CaseComment对象上创建一个触发器，以满足故事的要求。我给了一些我不希望看到的提示，比如调试语句，以及应该有一些错误处理。它思考了很久，然后提出了这个触发器处理程序类，它实现了我要求它使用的触发器框架。它连接到我们的Salesforce沙盒实例来提取和读取元数据，然后它会输出与它相关的东西。它根据评论的插入或更新实现了相应的方法，然后它有一些逻辑，在添加评论时将状态更新为“重新打开”。然后它在这里添加了异常处理，放了一些调试语句，但显然它告诉我们可以将其更改为我们想要的任何框架。然后它在这里实现了触发器，所以这就是那个触发器，它说，“在插入之前、插入之后，等等，运行处理程序类或它之前编写的逻辑。”然后我让它编写一个测试类，这基本上是它生成的代码的单元测试。我告诉它应该作为门户用户运行，所以基本上是作为客户运行，以确保所有安全性的东西都正常工作，并且它应该断言事情按预期发生。所以它就是这么做的。它创建了这个测试类，它有一个设置方法，在其中插入测试数据，创建门户用户，然后它有每个不同场景的单元测试。它也有断言，以确保测试运行后数据如预期。然后我切换到测试智能体，让它为手动测试创建一些测试场景。我告诉它要包括详细的测试步骤，包括Salesforce中的对象和字段引用，包括用户需要访问的任何按钮或页面，以便它非常具体地针对Salesforce。它根据这个用户故事生成了正面和负面测试用例，谈论了登录Salesforce、进入案例选项卡等等。我还有另一个聊天记录，只是为了演示另一个东西，那就是发布智能体，它基本上可以为我们编写发布说明。它连接到我们的Copado实例，该实例存储了我们所有已部署的故事，所以我向它询问了这个发布名称，“发布了什么？”然后它检查了那些用户故事，看了看描述之类的，然后就得出了这些发布说明。谢谢。</p>
<p>我将总结一下我的队友刚才介绍的内容。我们看到了如何使用计划智能体来创建我们的需求，然后从中创建用户故事。我们使用我们的构建智能体来设计和创建我们的代码，并附带测试用例，所以从第一天起就有质量保证，交付速度非常快，文档质量也非常好。然后我们看到了如何使用测试智能体来测试我们编码的内容，确保我们的所有场景都包括了正面场景、负面场景以及任何边缘情况，从而保证我们的质量非常高。接着我们使用我们的部署智能体来确保它上线。我们有发布智能体，它们可以创建我们的发布说明。所以我想说的是，人工智能智能体就像我们的超能力伙伴。我们不必第一天就进入人工智能软件开发生命周期（SDLC）；没有流程。我们可以从小处着手。我们现在最大的痛点是什么？是编写代码文档吗？是创建用户故事吗？是创建你的发布说明吗？也许从那里开始。我们只是想看看如何使用所有这些不同的智能体，让我们的生活更有效率，并确保我们能专注于解决更困难的问题。大家有什么问题吗？</p>
<h3 id="section-4-5-zh">AI 驱动的元数据生成器用于数据治理</h3>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 好的，我们把时间交给朱莉娅和拉卡。我们期待你们的用例，请开始吧。</p>
<p><strong>拉卡·达尔：</strong> 大家好！下午好。我是拉卡，和来自工程部的朱莉娅、本以及汤姆·佐克一起，我们很高兴能向大家介绍一个我们自己构建并命名的工具：一个由人工智能驱动的元数据生成器。现在，这听起来可能有点吓人，但让我稍微简化一下。元数据是让你的人工智能知道它正在阅读的是病历而不是披萨订单的方式。可以把元数据想象成你数据的领英个人资料：它来自哪里，它做什么，以及该联系谁。今天，我们将向您展示我们的工具如何自动化元数据生成，帮助简化治理，提高透明度，并加速我们组织的人工智能准备工作。这项工作目前正处于试点阶段。为了便于理解，特别是对于我们的非技术观众，我们在聊天中分享了一些关键术语和定义，以便更轻松地跟进。</p>
<p>现在，用受治理的、元数据丰富的数据来驱动可信赖的人工智能。元数据是数据治理的基石之一。在人工智能驱动的世界里，你的第一步不是建模或构建生成式人工智能，而是清理你的数据“衣橱”。要构建任何智能系统，特别是一个支持人工智能的、负责任的应用程序，我们需要一个坚实的基础，而这个基础始于数据治理，确保数据在整个组织内是安全的、管理良好的和可信赖的。没有智能的、负责任的人工智能，就不可能有智能的数据治理。治理是你人工智能的私人教练。治理的核心是元数据。它提供了背景信息：你的数据意味着什么，它来自哪里，谁拥有它，以及应该如何使用它。简单来说，可以把元数据想象成你数据的GPS。没有它，你的人工智能就像在盲目驾驶。它就像你数据的字幕；它帮助每个人理解故事，无论他们的角色是什么。请记住，如果人工智能是引擎，那么数据治理就是润滑油。忽略它，你就是在走向灾难。这正是我们的工具——元数据生成器——发挥作用的地方，因为即使是最聪明的人工智能，没有一个好的GPS也走不远。</p>
<p>到目前为止，我谈到了数据治理和元数据的重要性。现在，让我们看看这张幻灯片，了解我们的工具能做什么。我们使用Azure托管的GPT-4和企业身份验证构建了这个工具，这使得它不仅能与基于SQL的系统配合使用，也能与非SQL数据源配合使用。我们工具的一个关键特性是数据血缘。它展示了数据如何在系统间流动、转换和连接。可以把它想象成你数据管道的谷歌地图，让你从源头到目的地以及中间的每一个站点都有清晰的可见性。现在，让我们关注我们的特性。我们使用人工智能自动为表格、视图和存储过程生成通俗易懂的描述。这有助于弥合技术元数据和业务理解之间的差距。其次，我们可视化了数据血缘，以便用户可以看到数据如何在系统间流动和转换。我们添加了业务背景，例如建议的数据质量改进、业务术语映射和PHI（受保护的健康信息：任何可与特定个人关联的健康相关信息。）标记，以使元数据真正有用。最后，我们提供了JSON（JavaScript对象表示法：一种用于存储和传输数据的轻量级格式。）和Markdown格式的导出选项，使其更易于与任何工具、文档或数据目录集成。所有这些功能结合在一起，创建了一个高度可用、灵活和智能的元数据解决方案，为规模化的人工智能治理做好了准备。现在，我的同事朱莉娅将向大家介绍我们团队之前是如何分析元数据以建立数据血缘的，然后会进行工具的现场演示。</p>
<p><strong>朱莉娅·格罗萨：</strong> 谢谢，拉卡。我们团队负责一个名为“绩效洞察”的产品，该产品利用复杂的数据密集型流程为专业护理机构生成分析报告。现在，从事该产品开发的开发人员常常需要通过追踪每个数据表或存储过程的输入和输出来了解数据的精确流向。我们有数据流流程的高级文档，但在拥有这个工具之前，为每个对象都提供详细的逐步文档是不现实的。绘制这个数据流可能需要一名开发人员长达半天的时间，每次成本高达1000美元。因此，这个手动流程凸显了对更好的元数据和数据流分析工具的需求。现在我们将演示我们的工具，并展示我们如何让这个过程变得更加简单。</p>
<p>欢迎使用元数据生成器工具。使用此工具时，首先需要连接到数据库。我已经连接到我们团队在Insights中使用的数据库之一。我将转到“数据库对象”选项卡，这里是所有操作发生的地方。我这里有数据库中所有可用的对象类型，并且可以按对象类型进行筛选。我将生成元数据，并讨论描述和数据血缘，以及它们在工具中是如何生成的。在生成过程中，首先发生的是我们得到一个关于此对象的通俗易懂的描述，它将提供关于表的目的、业务背景、任何可能在机器学习应用中使用的相关标签以及其他信息。我们获取这些信息的方式是，我们从测试环境中获取所有关于列、列类型、主键、外键、索引以及少量样本数据的信息。我们将所有这些信息以提示的形式提供给Azure AI服务，然后得到元数据描述。第二件事是，我们正在生成一个数据流图，显示数据如何流入和流出此对象。您会看到这些信息已经生成。在我们的工具中，它的工作方式是，我们想找到所有的存储过程，这些脚本可以修改表中的数据，我们想找到所有改变、添加或使用此表中信息的脚本。这些脚本可能也从其他表中获取数据，所以我们一步一步地跟踪所有这些连接，直到我们构建出您在这里看到的这个数据库对象网络。这被称为数据血缘。我们还从另一个角度看待它。我们不仅想知道哪些数据流入我们选择的对象（即这个表），我们还想知道这个表中的数据是如何在其他对象中被使用的。这个工具是通过读取所有存储过程，并找到那些源表和目标表，然后创建这些连接来实现的。</p>
<p>让我们看一下生成的元数据。我们可以看到这个通俗易懂的描述，它简要概述了这张表，一些关于它为什么重要的业务背景，我之前提到的那些相关标签，一些数据质量检查，一些关于数据血缘的见解，以及一些数据隐私方面的考虑。在这个数据血缘图中，现在有点小，但我可以回到这个元数据浏览器，它以更大的上下文显示了元数据。这是我们刚刚生成的相同元数据。我们选择的对象是紫色的，源表是绿色的，目标表是红色的，我们的存储过程或那些脚本是橙色的。你可以看到数据是如何从这个表流到那个表，以及这个表是如何在所有这些目标表中被使用的。你可以开始看到，这可能需要一个开发者很长时间才能完成，但用我们的工具就非常快。现在，你可能在想，这个工具怎么这么快就做到了？它是如何读取所有这些存储过程和所有这些数据库对象并获取这些信息的？当我第一次启动这个应用程序并运行时，有一个后台进程正在读取所有这些存储过程对象，并使用人工智能提取源表和目标表。我们将所有这些信息存储在我们的数据库中。所以这个工具一个非常重要的特点是，所有人工智能生成的内容都会被保存在我们的数据库中。我们这样做是因为对人工智能服务的过多调用可能会变得耗时且昂贵。每个对象的人工智能响应只生成一次，之后每次都会重用，因为我们可能有很多用户为同一个对象生成元数据描述，我们不想进行重复调用。你可以看到这个标志表明，这个元数据是最新的，不需要重新生成。如果数据库对象被更新了，它会警告你可能需要重新生成元数据。</p>
<p>我想分享的另一件事是，我们的人工智能模型专门查看列名，以确定这些表中是否存在任何潜在的受保护健康信息（PHI）。所以，你可以看到我选择了另一个表。元数据描述立即出现了，因为这也保存在数据库中；我们不需要再次生成它。你可以看到，在医生名字、中间名等字段中可能存在潜在的受保护健康信息（PHI），用户应该意识到这一点。我想向你展示的这个工具的第二个功能是我们的模式比较功能。这个功能的目的是，如果你正在处理多个数据库对象，并且想了解它们之间的差异，无论是结构上的还是业务背景上的，能够比较它们是很有帮助的。所以，我将选择两个模式，当我选择两个模式时，工具会找到它们之间所有可以比较的共同对象，并且它是基于命名约定来做的。正如你在这里看到的，这两个对象名称除了模式名称不同之外是相似的。所以当我进行模式比较时——这也已经保存到数据库了，就像我提到的，我们将所有响应保存在数据库中——我们得到了关于参数、在这个特定对象中使用的对象、任何逻辑上的差异、输出列，以及使用这两个对象的一些风险和建议的差异摘要。所以，总的来说，这个工具对于开发者获得更好的数据库对象业务背景非常有帮助。它正在准备数据，给它相关的标签，这些标签以后可以在那些机器学习应用中使用。最重要的是，它正在开发那个数据血缘并展示那个数据流，这在你在数据流转换之上构建或修改时是至关重要的。</p>
<p>根据视频中演示的数据库，它专门用于我们的产品“绩效洞察”，该数据库大约有1000个数据库对象。因此，这个工具有潜力为开发人员节省250到4000小时的时间，并节省60,000到100万美元的成本。而且，这仅仅是针对“洞察”的一个数据库。我们的目标是让这个工具可供所有工程团队用于他们各自的数据库，这样每个人都可以从相同的时间和成本节约中受益。对于我们的非工程团队，我们希望我们提供了另一个可以从这次研讨会中学到的例子，即如何分解复杂、重复的工作流程，并沿途为明确定义的步骤使用人工智能。</p>
<p>现在，我们有几项计划中的增强功能，以使这个工具更有价值。首先，我们想增加那个数据血缘图的粒度。目前，它跟踪的是跨表的数据流，但我们想让它跟踪跨列的数据流。这将让开发者更清楚地看到单个列的变更如何影响整个系统。其次，我们想改进我们的元数据本身，并将其分为业务、技术和运营元数据，这样对不同类型的用户来说就更具可操作性。最后，我们想甚至将这个工具的范围扩展到数据库之外。我们希望这个工具能记录任何有某种数据流的存储库的数据流，而这样的存储库有很多。</p>
<p>在负责任的人工智能方面，我们项目最重要的部分是，我们保存了每一个由人工智能生成的结果，并附带时间戳，从而实现了全面的审查和审计。当我们向Azure AI服务发送提示时，我们创建了高度具体、内容丰富的提示，并采用了标准化的输入和输出，从而最大限度地控制生成的回应。但是，这个工具中的大部分逻辑都由我们开发者可以审查的确定性代码处理。所以，完成这个项目后，我们有两个关键的收获。一是，当你对人工智能生成的内容有深刻理解时，人工智能才最有效。例如，在不了解代码中底层库的情况下，很容易依赖人工智能的建议。但我们发现，先审查文档再引导人工智能，最终比在没有足够背景知识的情况下提示它节省了更多时间。最后，我一直在谈论这一点，但我们发现，人工智能在处理小而明确的任务时效果最好，因为它允许我们保持控制，并在过程中验证结果。所以，非常感谢大家参加这次演示，也感谢人工智能研讨会团队给我们机会与大家分享这一切。我们可以回答你们提出的任何其他问题。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 太棒了，拉卡和朱莉娅。我确实有两个问答环节的问题。其中一个是，构建这个需要多少精力？</p>
<p><strong>拉卡·达尔：</strong> 不多。我们开始的时候，我是在一些周六和周日开始的，几乎所有的结构都建好了，因为我们利用了人工智能。但是当我们开始引入图表模块等时，复杂性就出现了。朱莉娅，你愿意分享一下我们是如何学习图表模块以及如何在这方面取得进步的那些输入和发现吗？</p>
<p><strong>朱莉娅·格罗萨：</strong> 是的，我之前提到过，有些技术，比如可视化工具，它使用了一个特定的库，能够先理解那个文档是非常有价值的。这需要花一点时间，但一旦你理解了，你就能更有效地进行提示。我想说，人工智能非常有帮助，并且显著减少了开发时间。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 太棒了，很感激。最后一个问题是，数据库元数据生成器什么时候可用？</p>
<p><strong>拉卡·达尔：</strong> 我们会和我们的总监谈，然后……</p>
<h3 id="section-4-6-zh">Figma 和 Copilot 用于用户体验设计</h3>
<p><strong>凯特基·耶内马迪：</strong> 接下来，我们有珍妮弗、克里西卡、玛雅和查理，用户体验团队！很高兴能听到更多关于Figma和Copilot的消息。</p>
<p><strong>珍妮弗·马加纳 - 产品：</strong> 大家好，我是用户研究与设计团队的查理、玛雅、克里西卡和珍妮弗，我们很高兴能分享我们如何与人工智能合作，以帮助我们更快地行动，更早地发现洞察，并使我们的工作更具包容性。今天，我们专注于产品开发的早期阶段，也就是我们还在确定要构建什么的时候。我们称之为产品发现阶段。这个阶段通常令人不知所措。想法形成缓慢，研究结果分享得太晚，协作虽然有，但都是在孤立的竖井里进行的。这就是为什么我们正在重新思考我们的探索和协调方式。我们正在学习如何与我们称之为“设计伙伴”的人工智能工具合作，以改变我们的协作方式，并更有信心地进行构建。我们每个人都给它分配了一个角色。</p>
<p><strong>玛雅·马迪拉扎：</strong> Figma AI 是我们新推出的人工智能创意教练。它帮助我们快速重组想法，并探索多种设计方向来解决用户问题。我最近用它来探索用户如何在评估中指示文档的位置。我没有画草图，而是用提示来生成一个与我心目中非常接近的设计。这个设计帮助我发现了一个新挑战：我们如何帮助用户不仅选择一个进度记录，而且选择正确的那一个？所以在下一轮，我调整了提示，加入了更多的背景信息，比如谁写的记录，他们的角色，以及日期。然后我意识到，如果用户在选择之前能真正预览整个记录，那不是更好吗？于是我增加了一个预览功能。现在，当用户点击预览时，记录会展开，让他们在链接之前能完整阅读。如你所见，Figma AI 帮助我快速构思、视觉化思考并即时迭代，把一个想法变成了三种不同的变体，我可以与产品团队分享。就这些，我把它交给克里西卡。</p>
<p><strong>克里西卡·苏坦：</strong> 好的，现在我将谈谈我们的下一个设计伙伴，即作为交互/原型合作伙伴的人工智能。这是一个模型。它对于与产品、工程师甚至用户保持一致很有帮助，但一个屏幕并不能展示完整的体验。从静态图像中很难把握功能和流程。通常情况下，这是我们设计师制作原型的时候，但我们往往没有时间或临床背景来构建一些现实的东西。这就是我们使用Figma AI的地方。我使用Figma AI，仅用了半个多小时就将这个模型变成了一个可工作的原型。它不符合我们的常青设计系统或核心，但这没关系。它所做的是让模型活了起来，帮助我们可视化交互、工作流程和现实的内容场景。在我们最近的探索中，我们用它来快速与产品经理就关键想法达成一致。但展望未来，这些原型有潜力用于用户测试和端到端的可行性评估。现在交给珍妮弗。</p>
<p><strong>珍妮弗·马加纳 - 产品：</strong> 谢谢，克里西卡。Discoverly 是一个洞察力翻译器。它是我在 Copilot 中定制的一个人工智能智能体，用来帮助我实时分享研究发现。我来展示一下它的工作原理。</p>
<p>在Discoverly出现之前，我们与客户交谈，高亮显示笔录，总结要点，提炼主题和见解，然后呈现研究结果。现在，我们仍然与客户交谈并高亮显示笔录，这部分不会改变。</p>
<p>可以把它看作是数据标注。基本上，它帮助人工智能准确地解读那些数据。但现在，我能与人工智能合作，在极短的时间内生成那些摘要、主题和见解，并即时跨职能分享，以实现实时协作。</p>
<p>现在我们可以一起做出更好的决定。现在交给查理。</p>
<p><strong>查理·杨：</strong> 谢谢，珍。现在谈谈影响，有了像Figma AI和我们的定制研究Copilot智能体Discoverly这样的工具，我们正通过快速原型制作、更快地综合研究见解以及简化协作来加速发现和迭代，从而腾出时间进行更具战略性、高影响力的设计和研究。转到下一张幻灯片。所以，负责任地使用人工智能。人工智能工具通过告知我们的决策并帮助我们以更快、更智能的速度做更多事情来支持我们的想法。但这不是专业知识的替代品，也不应该取代人类在决策中的洞察力。说到我们学到的教训，实验是我们学习什么有效、什么无效的方式，尤其是在使用人工智能工具时。不断的迭代使我们能够决定如何前进，该放弃什么，尤其是在我们在工作流程中审查这些工具时。接下来是下一个要点，随着人工智能的发展，我们也在发展。我们随着工具的进步，保持着持续学习和调整我们技能的状态。最后，它如何能帮助他人？没有一刀切的解决方案。每个个人和团队都可以根据自己的需求塑造自己版本的“设计伙伴”。如果它不起作用，就继续迭代，否则总有另一个工具在那里。那么，我们的演示就到此结束。感谢大家的参与。我们现在可以开始提问了。</p>
<h3 id="section-4-7-zh">Profit：人工智能驱动的云成本预测</h3>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 好的，我想我们可以把话题交给云财务运营部的戴夫，谈谈Profit。</p>
<p><strong>戴夫·乔多斯：</strong> 好的，非常感谢。我来谈谈我们与一个名为Profit的工具合作的项目，我代表云财务运营团队发言。在深入介绍Profit及其强大功能之前，我想先简单介绍一下云财务运营是什么。我们是SaaS运营部门的一部分，负责云基础设施，我们为云工程、财务团队以及销售和产品等其他一些部门提供支持。我们关注的重点包括云成本的可见性、报告、预测——这个我稍后会详细说明——以及警报。在需要时，我们会构建各种自定义工具和系统来实现这些目标。在做所有这些事情时，我们致力于在全公司范围内实现节约。我们关注合同谈判和承诺折扣等方面。基本上，我们试图帮助公司了解的是，我们在云上的支出是否高效？我们投入到云中的所有这些资金是否为业务带来了价值？这张小图片描绘了美元从云中如雨般落下。实际上，我想象的是这些美元被吸入云中；这更像是事情发展的方向。但我们团队最终所做的是为PointClickCare节省数百万美元的云成本，并确保我们花费的资金能够有效地支持我们的产品和客户。这就为我们团队的身份和工作提供了一些背景信息。</p>
<p>现在我想深入探讨我们解决的一个具体问题，那就是预测我们的云成本。我刚才谈到的很多内容都与跟踪和理解已发生的成本有关。但我们也想知道未来的成本会是多少。对此有两个关键的利益相关者。一个是工程部门，他们需要设定年度预算。总额是4000万美元，所以这绝不是小数目，而且它被分成了100多个不同的项目，所以这个预算设定工作有很多不同的变动部分。工程团队和那些特定产品的经理们也肯定对持续的成本跟踪感兴趣，并且想了解的不仅仅是我们最近花了多少钱，还有我们将要花多少钱，以及这是否与预期和计划相符？说到财务计划和预期，我们还与财务部门密切合作，特别是财务规划与分析团队。他们负责公司的季度预测，而这些预测的一个关键部分就是我们的云成本。我们帮助他们预测这些成本，并向公司的其他部门通报这个谜题的这一部分是什么样子的。现在，这一切都很好，但在云的世界里要困难一些，因为云成本可能是可变的，而且很难理解。它们按天计费，并且会根据各种因素发生很大变化，比如产品使用情况或新技术变革。有时候成本模型本身也会改变。我们从云提供商（如AWS或Azure）那里收到的那些成本，并不直接与我们在PointClickCare关心的事物相关。它们不会告诉我们，“这个产品花了多少钱”，或者“这个预算所有者欠云多少钱”。它是一大堆有些难以理解的信息。所以，我们需要找到一个解决方案。</p>
<p>博士脸上的表情表明我们做到了。我们有一些关键组件，我们能够将它们整合起来应对这个挑战。这三个关键部分是发票数据、PointClickCare的背景信息以及一个人工智能工具。将这些结合起来，我们就能为利益相关者提供有用的预测。发票数据，我们每年收集数百万条记录，告诉我们我们在云上花了多少钱，每一条记录都有几十个维度，所以我们处理的数据相当密集。正如我提到的，这些数据并不能直接告诉我们想要知道的信息。所以，我们引入PointClickCare的背景信息，将所有这些数据条目与有意义的类别对齐，这些类别对我们在PointClickCare很重要：我们的产品、我们的预算所有者、用于财务分析的成本中心。最后，有一个人工智能工具，也就是我们今天在这里的原因。在这个案例中，我们使用的是一个叫做Profit的工具。我稍后会告诉你更多关于它的信息，但基本上，Profit允许我们利用历史输入来生成预测。在这个案例中，我们输入到Profit中的是过去一年的发票数据，加上我之前提到的背景信息，以帮助我们理解数据。输出的是对未来一整年那100多个产品的预测。</p>
<p>这一切在实践中是怎样的？我想先多告诉你一些关于我提到的这个Profit工具的信息。它是由Meta公司开发的，Facebook是他们的主要产品，它是一个开源工具，所以你不需要为它付费。它是免费提供的。它的主要用途是为时间序列数据提供预测，这基本上是围绕时间组织的数据，比如天和月。它的关键特性是它相当快速、准确，并提供自动化结果，所以你不需要进行很多复杂的配置。</p>
<p>将我们的数据输入Profit并得出预测后，我们发现这些预测非常准确。我们追踪了预测与实际支出的对比，发现在6个月的周期内，预测与我们的实际支出相差不到1%，所以它们非常精准。然后，我们把这些预测，你可以在右上角看到一个例子，整合到一个我们开发的自定义成本跟踪系统中，通过这种详细的成本跟踪报告和工具与这些基于Profit的预测相结合，我们能够支持更好的决策。</p>
<p>我想给你们一个关于Profit及其预测实际应用的例子。这是我们正在追踪成本的一个产品。我们可以看到左边的蓝色条形图是到目前为止的成本，然后深蓝色的线代表预测。如果你们只看目前的成本，你们可能会觉得它很稳定，我们不必太担心成本增长，我们情况良好。但如果你们看预测，你们可以看到它实际上预计在财年剩余时间里将上涨25%，从每月大约3000美元涨到4000美元。从总金额来看，这不算多，但从这个特定产品及其表现的角度来看，我们希望能够控制这些成本。如果我们知道这是它的发展方向，我们就可以尽早采取行动，而不是等到九月中旬才发现我们最终的花费超出了我们的计划。</p>
<p>我将分享另一个例子，这个例子在预测方向上可能看起来不那么引人注目，但它也同样重要。这是我们的核心电子健康记录（EHR）产品，也就是我们销售的主要产品。在左侧，您再次可以看到成本似乎相当稳定。那条深蓝色的预测线表明，在今年余下的时间里，成本将有所上升。但现在我想请您注意左侧，Y轴是支出。我们说的是多少钱？这是每个月一百五十万到两百万美元。所以，当我们看到那条深蓝色的趋势线在财年余下的时间里稍微向上爬升时，这种爬升代表着每个月数万甚至数十万美元。如果我们能提前得到一些预警，并能领先一步，那么我们就能省下那笔钱，并将其投资到其他地方，而不是让它在每个月都不经意地流失掉。</p>
<p>我现在想花点时间谈谈负责任地使用人工智能，因为正如所有这些演讲一样，这是我们正在做的任何事情中的一个关键考虑因素。在这种情况下，我一直在谈论我们如何使用Profit。我们得到了这些预测，它们是准确的，有帮助的，非常棒。但我确实想强调，它们并非一成不变。我们不会仅仅拿着这些预测就盲目地往前冲，说：“这就是这个东西的成本。人工智能告诉我们的。我们完事了。”我们使用一个自定义工具向预算所有者展示这些预测，他们可以审查这些预测并根据需要进行调整。例如，如果某个所有者知道他们的产品目前处于早期可用阶段，使用量很少，但将在第四季度进入有限可用阶段，并在九月中旬出现跳跃式增长，那么他们可以在预测中指出，届时成本将相应地跳跃式增长，而Profit或任何类似的人工智能工具都无法预测到这一点，因为它无法从过去的历史结果中得到指示。任何这些手动更改都会从一个月保留到下一个月，所以人工智能结果不会在下次生成时就将其抹去。这意味着我们的预测实际上是人工智能和专家人工输入的结合。人工智能结果为我们提供了一个有用的起点，然后鼓励预算所有者、那些产品专家的调整，在需要的地方进行调整，以确保预测尽可能准确。</p>
<p>那么，这一切的影响是什么？我们为什么这么做？它有何帮助？我想从几个不同的时间维度来看待这个问题。从月度来看，我们有这个成本跟踪工具，然后通过叠加预测信息来加以改进。这些预测是按产品提供的，所以对于那100个产品中的每一个，我们都能得到这个量身定制的预测。它们每个月都会更新，预算所有者可以按月将其实际成本与这些预测进行比较，并根据需要做出响应。正如我所说，如果他们看到预测在攀升，他们可以采取一些主动措施，尽早采取行动来控制这些成本。</p>
<p>在季度基础上，我们为财务规划与分析团队提供预测，然后这些预测会提供给整个业务部门，以便他们了解我们的云成本以及每个季度的变化情况。PointClickCare的领导层可以利用这些信息来调整整个业务的投资，以反映不断变化的成本和优先事项。例如，如果有一个我们认为在第三季度将耗资50万美元的大项目，而到第二季度末我们意识到情况发生了变化，实际上只需要20万美元，那么业务部门就可以知道我们有30万美元的额外资金，而这笔资金是我们之前没有预料到的，我们可以将其投资到更能服务于业务的其他地方。这是从一个季度到下一个季度的情况。然后，在年度基础上，我们极大地简化了所有工程团队的预算流程。这为大约60个工程团队在年度预算期间节省了数周的精力，他们不必从零开始。他们可以从这个由人工智能驱动的预算起点开始，然后结合他们自己对产品在关键部署点情况的了解，并基本上提供那种结合了人工智能和人类专家的预算，其中包含我们拥有的最准确的信息。最后，我们甚至可以看得比一年更远。我们可以展望两、三、五年后，帮助识别一些长期趋势，如果我们了解这些趋势，我们就能知道未来可能会发生什么，我们就可以尽早采取干预措施，以避免成本上升或出现大问题。</p>
<p>我想以这个想法结束：那么，这对我有什么好处呢？如果你是工程或财务岗位的，希望这个答案是显而易见的。以上所有，我们谈到的所有事情——预算、成本跟踪、预测——所有这些功能、所有这些工具都已融入这个我提到的自定义仪表板、这个自定义成本框架中。这一切都供你使用。如果你有任何问题，可以问我。如果你不属于这些团队，并且这一切对你来说都是新的和不熟悉的，我想鼓励你真正思考一下这如何能应用于你工作中的数据和挑战。这个工具的适用性非常广泛。我一直在云成本的背景下谈论它，因为那是我所处的领域，但实际上，它适用于任何你有历史数据并想了解它所指示的朋友的情况。有了这个工具，历史数据输入，预测输出，我们可以结合你的背景、你的问题领域、你的具体关切，并利用Profit的能力来应对你可能遇到的挑战。我想谈几个例子。在云和云财务领域，我们与云提供商，比如Azure，签订了长期合同。我们有一份长期合同，可以在某些领域获得显著的节省，作为交换，我们需要在该云领域做出支出承诺。要签订这份合同，我们需要对我们的长期支出有一个明确的认识，而这个Profit工具能够帮助我们建立这种认识，并在我们逐年履行这份合同时进行跟踪。</p>
<h3 id="section-4-8-zh">GitHub Copilot 用于平台现代化</h3>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 我们的下一个用例来自工程部的Pawandeep和Victor，他们将介绍GitHub Copilot。交给你们俩！</p>
<p><strong>帕万迪普·考尔：</strong> 大家下午好。感谢大家的参与。我叫帕万迪普，和我一起的是来自汤姆·安德拉卡领导下的工程部的维克多。今天，我们想分享一下我们团队一直在做的工作以及在此过程中学到的一些经验。2023年3月，PointClickCare收购了Patient Pattern，作为推进基于价值的护理和更好驱动患者结果的战略投资。在2024年4月早期访问启动后，产品的管理权移交给了我们的工程团队，他们带来了在Java及相关技术方面的强大专业知识。很明显，虽然该产品具有巨大的潜力，但它也带来了一些需要未来认真关注的未预见到的挑战。</p>
<p>从一开始，我们就认识到表面之下隐藏着重大的挑战。随着时间的推移，系统变得复杂，充满了临时修复、变通方案和对PCC标准的演变，这使得改进变得缓慢且不可预测。受Patient Pattern主题启发的前端，缺乏PCC的协同设计风格，导致用户体验不一致。虽然学习像Python和Django这样的新语言不是挑战，但适应框架的实现方式给我们带来了额外的障碍。常规的变更开始需要巨大的努力，并且常常影响我们的性能、可靠性和可扩展性，这清楚地表明，我们需要一个更具可扩展性、更统一的基础，以便更快、更自信地交付改进。就在那时，我们决定尝试一些不同的东西，将人工智能引入我们的转型之旅。</p>
<p>我们仅用两名工程师，分三个重点阶段重建了平台，所有阶段都由人工智能驱动。首先，我们使用GitHub Copilot和SonarCloud来理清这个迷宫，绘制工作流程，进行逐类比较，并构建测试驱动的蓝图。这让每个人，无论是工程师还是业务人员，都能实现精简化。接下来，我们拿出那些蓝图，让AI投入工作，将关键模块从Python迁移到Java，用React（React：一个用于构建用户界面的JavaScript库，特别适用于单页应用程序。）现代化前端，并用Mermaid图将所有东西连接起来，这样我们就能及早发现问题。仅仅一周，我们就有了可工作的原型。最后，我们完善了产品，迭代了性能提升，并捕捉了安全漏洞。除了速度，最突出的是AI为我们的设计带来的清晰度和保证，以及它如何使我们的决策变得非常有影响力。</p>
<p>那么，这次转型对我们的团队和用户意味着什么呢？首先，这次转型可以将过去估计需要400个工程小时的开发工作减少到仅仅20个小时，使我们能够提前数周为客户创造价值。通过改进测试和简化工作流程，我们可以减少支持需求，并增强用户信任。我们的系统可以在相同的硬件上处理两倍的工作量，而不会降低预期的延迟。我们能够自动化30%的重复性任务，这是我们最大的胜利之一。这些好处是基于我们在试点版本中看到的可衡量收益，展示了随着我们扩展这些改进，可能实现的目标。</p>
<p>回首过去，一些教训确实很突出。首先，规划出我们的工作流程起了很大的作用。它将不确定性变成了清晰。其次，人工智能是速度和规模的强大工具，但保证质量的是我们员工的专业知识。最后，快速的胜利很重要。每一次小小的成功都会积累动力，帮助团队保持参与。这种方法并非我们旅程独有。任何PCC团队都可以采取这些步骤，让工作可见，将人工智能与人类判断相结合，并不断前进。就此，我将把话筒交给我的同事，他将向我们现场演示这次转型在实践中的样子。</p>
<p><strong>维克托·塔尔诺夫斯基：</strong> 大家好。今天我将现场演示我们新的React.js应用程序和Spring Boot应用程序。但首先，我将快速介绍一下我们的旧应用程序。我们的旧应用程序已经为我们的客户服务了很长时间。然而，正如潘迪提到的，我们客户的需求已经超出了我们现有框架和应用程序的承载能力。因此，我们决定在React.js和Spring Boot中创建一个新的应用程序。即使只是浏览页面，例如切换标签页，加载也需要一段时间，因为Django只支持服务器端渲染。所以，我们可以做得更好。因此，我们决定创建我们的React.js应用程序。如您所见，它使用了我们的常青样式，这将更好地与整个PCC生态系统融合，并且将提供更加一致的用户体验。另外，正如我提到的渲染问题，React.js允许我们使用一些客户端渲染，这将使我们能够，比如，看看这个，切换标签页的速度有多快。即时切换标签页，从已完成到即将到来。我们可以立即打开居民信息。我们可以立即创建新的认证。搜索也快得多，我认为我们的用户会对此感到非常高兴。我认为这将为他们节省大量时间，他们会对此感到满意。希望他们和我一样满意。</p>
<p>接下来是负责任地使用人工智能。对于我们的项目，以及今天演示的许多项目，我们都展示了我们可以利用这些人工智能工具更快地进行开发。但是，我们需要谨慎。我们绝对需要将在生成代码上节省的时间，投入到架构设计、制作高质量、快速的设计以及安全的设计上。我们真的需要在这方面下功夫，以确保我们不会制造出充满安全漏洞和性能问题的臃肿的人工智能代码。我们不想要那样；我们想要高质量的代码。所以，这绝对是我们花费时间最多的地方之一，就是设计实际的应用程序。最后，我们需要谨慎选择我们使用的人工智能工具。即使这意味着我们不能在工具一发布就使用它们，我们也需要尽职尽责，确保我们没有泄露任何专有代码或任何信息。就此，我愿意接受任何问题。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 谢谢你，帕兰迪普和维克多。我看到一个问题刚刚出现。你用的是什么编码助手？是GitHub Copilot吗？</p>
<p><strong>维克托·塔尔诺夫斯基：</strong> 是的，我们正在使用Copilot。据我所知，这是我们拥有的最强大且经安全部门批准的工具。</p>
<h3 id="section-4-9-zh">使用 Azure GPT 的安全计划助手</h3>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 我们直接把话题交给埃里克。这是埃里克和阿鲁什，他们将通过视频，从产品市场和产品角度，介绍Azure GPT。交给你们了。</p>
<p><strong>埃里克·斯塔比尔：</strong> 好的。我叫埃里克·斯塔比尔，是一名产品市场经理，今天我将代表我自己和高级产品经理阿鲁什·夏尔马，介绍安全计划助手。我们与拉法特·拉朱丁部分合作，利用Copilot Studios来应对我们在为PointClickCare客户推出新安全增强功能时面临的挑战。</p>
<p>当我们推出最新一轮的安全增强功能时，我们收到了来自内部支持团队、客户成功经理和客户的大量问题。但答案往往复杂且具体。它们分散在多个资源中，使得团队难以找到一致、及时的信息，从而减慢了响应时间并增加了支持开销。为了解决这个问题，我们引入了一个由人工智能驱动的智能体，它直接嵌入到Microsoft Teams中，并经过我们所有相关面向客户内容的训练。现在，团队成员不再需要翻阅冗长的常见问题解答、指南和幻灯片，只需简单地询问人工智能，就能收到与上下文相关的回复。这减少了响应时间，提高了信息的一致性，并让员工能够专注于更高价值的工作。</p>
<p>自推出以来，该智能体已支持超过150次会话，内部用户参与率达到75%，满意度评分为4分（满分5分）。在实时办公时间（我们每周举办办公时间，回答客户关于多因素认证（MFA (多因素认证): 一种安全流程，要求用户提供两个或多个验证因素才能获得访问权限。）的问题），它帮助一位小组成员实时回答了大约每分钟一个问题，提高了生产力并减少了客户的麻烦。当然，为了负责任，我们增加了一个免责声明，提醒用户核实人工智能生成内容的准确性，在快速行动的同时保持我们的高标准。就这些，我把演示交给阿鲁什。</p>
<p>让我们深入了解一下如何为您的用例创建一个智能体。在屏幕顶部，您会找到一个可以输入描述并定义智能体目的或目标的部分。接下来，定义安全程序助理的指令。请记住，您的指令越具体，智能体的响应就越准确。您可以开启生成式编排。这使得智能体能够使用生成式人工智能来决定如何响应，从而让用户的对话更加自然流畅。在Copilot Studio中，知识源与生成式答案协同工作。当您添加一个知识源时，您的智能体可以利用企业数据，无论是来自内部系统、公共网站还是外部平台。您可以简单地拖放一个文件，或从下面列出的数据源中选择。在这个设置中，我们添加了SharePoint，以及面向客户的文档和帮助文件。最近，他们还发布了一个新功能，让您也可以集成SFTP服务器。副驾驶智能体中的工具让您的智能体能做的不仅仅是回答问题。它们可以触发工作流、调用API、查询数据库，甚至执行重置密码或更新记录等任务，所有这些都基于用户输入。可以把工具看作是您智能体的手，而生成式人工智能则是大脑。它们共同使智能体不仅能对话，而且真正具备功能。智能体可以通过与其他智能体连接来协同工作。这意味着您的主智能体可以将工作流的特定部分委托给另一个专门处理这些步骤的智能体。这是一种分解复杂流程、保持模块化并确保每个智能体专注于其最擅长的事情，同时仍为用户提供无缝体验的强大方式。一旦您的智能体准备就绪，您可以将其直接发布到Microsoft Teams。这使得组织内的用户可以在他们已经进行协作和沟通的地方轻松访问智能体。它就像一个普通的Teams应用程序一样出现。这是一种将自动化和支持直接带入日常工作对话的快捷方式。</p>
<p>这个智能体不仅仅是为了节省时间；它是为了让我们能够将注意力重新集中在最重要、没有明显答案的问题上。如果你曾想过“有人应该自动化这个搜索”，或者“一定有更聪明的方法”，那么就把这当作你的信号。你就是那个人。去构建你希望拥有的那个智能体吧。好的，谢谢。有什么问题吗？我也很乐意在线下回答。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 我在问答区看到一个问题。这是已经上线的，还是在概念验证阶段？</p>
<p><strong>埃里克·斯塔比尔：</strong> 这已经上线了。是的，我们现在正在使用它。我们已经使用了将近一个月了，并且我们每周都会积极使用它，特别是在我们每周的客户问答环节中。</p>
<h3 id="section-4-10-zh">Pharmacy GPT：一个以数据为中心的副驾驶智能体</h3>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 我们的下一个用例来自技术服务和客户支持部的赛义德、乔丹和鲁本，他们将介绍一个他们构建的以数据为中心的副驾驶智能体。交给你们三位了。</p>
<p><strong>赛义德·哈桑：</strong> 大家下午好。今天和我一起的有乔丹和鲁本。除了我自己，我们还想特别感谢技术服务部的瑞亚和阿什利，他们帮助我们完成了这个智能体。我们构建的这个东西叫做Pharmacy GPT。它是一个副驾驶智能体。我们决定做这个的原因是，PointClickCare的产品组合在不断增长。新产品不断涌现，越来越复杂。随着这种情况的发生，我们需要确保所有面向客户的人员都具备专家级的知识。我们选择了Pharmacy Connect，这是一个很多人都听说过的产品，这就是我们的目标。所以这是一个嵌入到Microsoft Teams中的人工智能智能体。作为一个智能体，任何有权限的人都可以与它开始即时聊天。它经过Pharmacy Connect功能集的训练，它真的像一个知识专家，让每个人都能触手可及地获取知识。它可以用来学习产品的工作原理，也可以作为故障排除资源。在我们深入更多细节之前，我将把它交给鲁本来介绍一些高层架构。</p>
<p><strong>鲁本·维埃拉：</strong> 谢谢，赛义德。我一直在客户支持部门参与多个AI智能体和项目，最近有幸与赛义德及其团队合作构建了Pharmacy GPT。让我们从一个非常宏观的角度来了解一下Pharmacy GPT的内部工作原理。首先，它从第一部分开始，即副驾驶智能体所有者。这些人构建和更新驱动智能体的知识。虽然我构建了智能体的大部分基础设施，但这里的主要工作来自赛义德和团队，以确保我们为其提供高质量的内容。这对这个智能体来说是一项艰巨的任务。一旦知识被策划和整理好，它就会被放入SharePoint。从SharePoint，它会进入认知搜索，也就是索引。这使得智能体能够非常快速地找到相关文章，从而帮助生成用户正在寻找的答案。这基本上是第一部分。第二部分就是终端用户，我们已经与他们分享了Pharmacy GPT，他们可以提问并与之互动以获取所需信息。他们进入Pharmacy GPT，提问。然后那个问题被发送到OpenAI，以解释用户在问什么以及意图是什么。然后，它会与索引中的相关内容进行匹配，我们已经索引了所有的知识文章，以找到最相关的文章来构建答案。然后，答案会非常快地，几乎是实时地，发送回给用户。所以，这就是一个非常宏观的概述。我希望这能给大家一个清晰的概念，也许你们可以实现类似的东西。现在回到你，赛义德。</p>
<p><strong>赛义德·哈桑：</strong> 正如鲁本提到的，智能体的好坏取决于你训练它的内容。所以我们必须想出一个快速生成大家都喜欢的文档的方法。文档是这里每个人生存的祸根。所以我们确实在这里解锁了一条通往快速、详细和准确文档的路径。基本上，我们所做的是，对于每个版本，我们确定我们的交付成果，然后我们选择每个功能，对该功能进行一个15到30分钟的快速转录。通常情况下，你会发现自己用15分钟就能讲清楚一件需要你花五个小时打字的事情。我们进行转录，然后我们将转录内容反馈给Copilot，并从中构建详细的文档。从功能意图到功能逻辑，再到市场营销和销售的话术，再到内部和外部的培训清单、课程大纲，无论是什么，我们实际上都可以在几分钟内使用Copilot完成。当我谈到详细文档时，我指的是非常详细的文档。这些是关于单个功能的10到15到20页的文档。这是非常详细和完整的文档。然后我们去更新我们的数据字典。我们必须构建数据字典，因为虽然你今天可能听到了很多关于你的回应质量取决于提示的说法，但我们想让这个过程对人们来说更容易一些，这样人们就可以用人类的方式与它交谈。我们构建了数据字典，其中我们记录了人们可能用来指代某些事物的缩写或类似术语。一个简单的例子就是“设施”。根据你所处的市场，它们可能被称为专业护理设施、辅助生活设施，或者干脆就叫“家”。我们构建了这些数据字典，所以如果需要，我们会更新它们，然后我们用同样的文档去训练Pharmacy GPT并进行测试。实际上，我们在这里所做的就是用人工智能生成内容来反馈给人工智能。这基本上就是整个过程。这只是我们创建的众多文档之一。你可以看到这是一个11页的文档，一个庞然大物，里面记录了大量的细节，知识含量极高。你屏幕上看到的95%都是Copilot生成的。我们已经创建了一堆这样的文档，所以如果有人需要帮助，想知道我们是怎么做的，随时联系我们，我们非常乐意帮忙。</p>
<p>由于我们以数据为中心，对我们来说最重要的事情是，如何负责任地使用人工智能？首先，再次强调，人工智能可能会产生幻觉，所以我们所做的一件事是，我们所有的回应都会引用其使用的源材料，这样即使它可能产生了幻觉，你也总能访问到实际的源数据，并且可以随时调出并阅读文档。这也解锁了一种奇怪的用例。如果有人用过Confluence，就会知道在里面找到你想要的东西简直是一场灾难。你可以直接使用这个智能体，说：“嘿，你能给我指出任何关于这个主题的文档吗？”然后它就会吐出这个智能体所接触到的最相关、最新的信息。第二件事是，当你查看关于逻辑如何工作的非常详细的文档时，你真的必须确保你的人工智能理解了它。我们在这里也解锁了一个非常巧妙的用例，来验证我们的文档，以确保我们的人工智能正在正确地阅读它。所以我给你一个例子。一旦我们构建了这个文档，我们实际上就问Copilot：“嘿，给我建一个流程图，展示这整个逻辑是什么样子的”，然后它就为你构建出来了，我们用它来验证我们自己的文档。在这个具体的例子中，我们看到它在这里连接了错误的点。所以我们知道，好的，让我们回到文档中去做那个修改。“嘿，你连接的这两个功能点是互斥的，它们不相关，不交互。”所以我们进去，这样我们可以在几秒钟内快速验证文档，去更新它，然后我们让它做完全相同的事情，现在你看到了一个非常不同类型的流程图。这让我们能够非常快速地验证我们的知识来源，以确保它确实在正确地理解它，并且它会给用户提供正确类型的响应。我现在将把它交给乔丹，做一个快速的演示。</p>
<p><strong>乔丹·鲍曼：</strong> 如前所述，您首先需要获得Pharmacy GPT的访问权限。一旦拥有权限，就像被邀请加入Teams聊天一样。然后，您只需在Teams中进入Copilot部分，再进入右侧的智能体列表和Pharmacy GPT。之后您就可以与它聊天了，右下角窗口还保留着您之前的对话记录。这对于回顾前一天的内容或与他人分享您从中学到的信息非常有用。现在，让我们来谈谈您可以与Pharmacy GPT进行的各种对话。也许您是Pharmacy Connect的新手，正在学习它；也许您只是需要复习某个特定主题，或者只是暂时想不起来。由于它接受了Pharmacy Connect所有功能集的训练，您可以直接让它向您描述。正如左侧示例所示，我们询问了一个特定功能。当然，由于这是一个对话，您可以进一步深入，更具体地提问，或者要求它详细阐述某些内容。</p>
<p>现在，或许你对功能很熟悉，并且身处一个更直接面向客户的岗位，客户遇到了问题，或者你正在帮助其他人处理与Pharmacy Connect相关的问题。它可以用来获取如何进行基本故障排除的建议。在右边的例子中，我们提出了一个基本问题，并请求下一步的建议，它能够提供后续步骤，给我们一个起点，至少为我们指明了正确的方向。现在，我们甚至可以更进一步，虽然这还有点实验性，但它实际上可以被用来进行高度技术性的分析，而这种分析在过去只有少数主题专家能够识别和解决。在下一个例子中，我们实际上给它输入了一段来自药房HL7（HL7（健康级别七）：一套用于在软件应用程序之间传输临床和管理数据的国际标准。）消息的片段，该消息以我们不希望的方式填充了一个订单。它实际上能够分析并识别问题，并以一种非常易于理解的格式解释问题。这在某种程度上让任何人都能像专家一样与你的客户或其他人交谈。它使Pharmacy Connect问题的故障排除对其他人来说变得更加容易，并有助于缓解我们所看到的只有少数主题专家能够提供帮助的瓶颈。你也可以在最底部看到，正如我提到的，它列出了它引用的源文档。如果它从多个来源引用，那里就会有多个文档，你可以追溯到源材料来学习，或者验证它提供给你的信息。这些只是你可以使用Pharmacy GPT的几种方式，我们非常兴奋地想知道人们还会用它来做什么。现在已经有好几个团队在使用它了，到目前-为止我们收到了很棒的反馈。我们希望这将继续帮助每个人学习、解决问题，并发展他们自己在Pharmacy Connect方面的技能。非常感谢大家的聆听。我们现在开放提问。</p>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 太棒了，大家。我确实有两个问题想问你们。随着我们在Pharmacy Connect中开发新的工作流程，你们需要重新训练吗？</p>
<p><strong>赛义德·哈桑：</strong> 是的。这涉及到回去重新做文档更新。我们希望我们能从各个团队建立起良好的沟通，我们的产品会经过他们，他们会给我们提供文档，然后我们就可以使用赛义德之前提到的那种方法，更新现有的文档，或者直接把那些新文档插入到SharePoint中来更新所有内容。</p>
<h3 id="section-4-11-zh">Pulse 实施临床指标分析</h3>
<p><strong>凯特基·耶内马迪：</strong> 我相信我是下一位演讲者。我是凯特。</p>
<p><strong>凯特·卡普利亚：</strong> 大家下午好。我叫凯特·卡普利亚，是药房与综合用药管理团队的一名实施顾问。我今天的演讲将重点介绍如何利用Microsoft 365 Copilot应用来分析实施PointClickCare解决方案的设施的Pulse实施临床指标。这个用例目前正处于试点阶段，之前已经与顾问团队进行了审查，并且我也在自己的项目中使用过。</p>
<p>作为项目生命周期的一部分，顾问们正在使用从生产自助服务门户中提取的数据，准备一份实施后指标Excel仪表板。通常，这会在一个为期4周的时间内完成，期间我们会与客户会面，审查和讨论他们数据库的当前健康状况，并确定改进之处。顾问们不仅要花时间生成报告，还要提前验证数据以制定行动计划。这个想法是在今年2月一次跨职能项目经理和顾问的现场会议上产生的，当时我们讨论了如何将人工智能融入实施生命周期。我发现我经常花大量时间审查指标报告，制定个性化建议，并为监控电话做准备。今天，我想向大家展示如何利用Copilot从指标报告中提取绩效指标并生成量身定制的行动计划。</p>
<p>为了演示，我使用了一个预先构建的测试临床仪表板，其中包含两个设施的数据。该仪表板包含五个不同的临床工作流程，每个工作流程又包含左侧列出的多个指标，显示了4周的数据。关于该仪表板需要注意的一点是，它包含宏元素，Copilot无法分析这些元素，因此在运行分析之前必须将其转换为常规的Excel工作簿。演示将回顾如何将准备好的指标报告转化为有意义的、针对具体设施的改进策略，从而提高护理质量、合规性和运营效率。</p>
<p>为了这次演示，我已经输入了我的提示，并且已经附上了工作簿。你可以保存你的提示，也可以输入你的提示。在你的聊天窗口的“查看提示”下，你可以查看提示库，我把我的提示保存在“你的提示”下面。在这个提示中，我概述了一些关于请求的细节。我要求Copilot为每个临床工作流程制定一个行动计划，按设施分开，并包含具体的重点领域、下一步措施以及推荐的支持、操作指南、快速参考指南和其他资源。我要求Copilot查看PointClickCare OneDrive、SharePoint网站和其他工作区。这份报告和分析是基于我将要附加的Pulse实施监控指标文件。我还要求它突出显示每个工作流程的有希望的趋势，包括多个指标，并按设施分开。我已经发送了我的提示并包含了我的文件。我可以继续并删除提示，因为我已经发送了它，然后我将能够审查Copilot生成的分析。</p>
<p>在下面，Copilot分析了上传的报告，并向我提供了以下信息。它包含了每个设施的详细信息，并将其分成了不同的工作流程。它按照要求概述了有希望的趋势，任何重点领域——所以任何我注意到数字可能更高，或者可能有未清除项目的领域，正如这里概述的。任何下一步措施，以及推荐的资源。我们可以看到，它按那些工作流程进行区分，所以我们有跨学科入院、用药管理仪表板、医嘱门户、任何重点领域，然后是用药管理药房医嘱门户，那是我第一个设施的。然后我有了第二个设施的相同信息：有希望的趋势、重点领域、下一步措施和推荐的资源。我们可以向下滚动并审查每个设施概述的所有信息。它问我是否要生成格式化的文档，或者是否要创建幻灯片。如您所见，这种分析使顾问能够为指标审查会议做准备，并讨论设施可以改进的地方，或者突出显示设施做得好的或正在改进的任何领域。所有的信息都已由Copilot生成，它还包括一些推荐的资源、任何必需的下一步措施，所以设施应该采取的任何行动。这些信息也可以在会议上与设施分享，并可以包含在后续电子邮件或与设施的进一步对话中。</p>
<p>您还可以要求Copilot总结要点以获得高层概览，或请求对特定工作流程进行更详细的分解。在这张幻灯片上，我包含了一个输入与分析的快速视觉对比。左边是临床仪表板指标数据，右边是Copilot生成的量身定制的行动计划。那么，为什么这个用例很重要呢？在影响方面，我们看到顾问在准备上线后建议时的效率提高了。顾问可以节省时间，每天为四个设施准备指标时，可以节省8小时工作日的20%。我们还在设施之间实现了标准化的改进规划，从而实现了持续的工作流程优化。最后但同样重要的是，这为实施团队提供了可操作的见解和对支持材料的直接访问，从而提高了生产力，并能在相同的时间内处理三倍多的设施。</p>
<p>在经验教训方面，你确实需要确保使用非常具体和详细的提示，概述要分析的信息，包括但不限于设施和工作流程名称或具体指标。将指标与资源链接也被确定为一个需要改进的领域，因为Copilot无法直接从客户支持门户中提取资源。例如，可以引入SmartZone电子课程，然而，这些信息只能从共享工作区中的文档中提取。根据我的经验，它也可能提取个人云文件和电子邮件附件。资源和建议需要详细审查，以确认它们适用于特定设施的工作流程。例如，你需要考虑专业护理设施与辅助生活设施之间的差异。</p>
<p>它如何能帮助PointClickCare的其他人：通过将指标与具体的操作指南和资源链接起来，人工智能扮演了一个动态导航员的角色，连接了数据和资源，从而减少了培训差距并提高了采用率。可以利用不同的提示来访问培训资源和建议，以促进客户支持团队的学习和发展。它还加速了上线后的监控，所以副驾驶可以自动化第一层的上线后审查，标记趋势并提供支持材料。这个模型可以复制到其他工作流程中，例如实施、客户成功和客户管理团队的计费。为了负责任地使用人工智能，你确实需要确保根据设施的具体细微差别来验证建议。所以在与设施分享计划之前，你需要批准、编辑或注释该计划。你还需要审查参考来源，以检查是否存在受保护的健康信息（PHI）或项目数据，特别要关注Copilot用来生成建议和支持材料的项目。最后，你需要根据生成的响应来完善你的人工智能提示或调整你的指标阈值，因为风险阈值可能因项目而异。总之，这个用例可以减少分析指标以准备监控会议所花费的时间，从而腾出时间进行战略性外联。它还展示了人工智能如何将原始的实施后数据转化为可操作的见解，使团队能够更快地做出基于证据的决策，而无需手动分析，这确保了更高效的审查、改善的护理结果和面向未来的持续改进方法。我现在开放提问。</p>
<h2 id="section-5-zh">五、小组讨论：人工智能在医疗健康领域的未来</h2>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 我有一系列问题要问小组成员。我的第一个问题，是给拉希姆和贾里德的：你们对哪些新的人工智能工具或技术最感兴趣，为什么？</p>
<p><strong>拉希姆·哈什瓦尼：</strong> 我先说吧。首先，感谢邀请。我看了一些很棒的、鼓舞人心的演示，我很期待看到今天将如何帮助加速我们的人工智能故事。回到你的问题，我个人对两种技术感到兴奋。第一种是人工智能视频生成和内容生成。我很久以前就涉足过数字动画，所以那一向是我的兴趣所在。但是现在，仅凭一张二维图片、一段音频和一个提示就能生成的东西，简直令人难以置信。除了那些邪恶的深度伪造内容，一些实际的创意数字内容，如果不是已经的话，也即将与一些工作室相媲美。所以我真的很期待看到这方面的发展。另一个对我们有大量实际应用的领域是自主人工智能智能体。能够消费输入和数据，然后在我们的数字环境中自主计划、推理和行动的智能体。它们的能力越来越强，这对我们来说是一个巨大的机会，可以利用和自动化那些单调乏味的工作，甚至消除它们。一个自主的、面向客户或员工的智能体，它能研究一个问题，不仅能推荐解决方案，还能实际处理工作流程或编写代码来实现解决方案，当然是在人类的指导和护栏下——你必须有人类在其中——但我们可以用同样的资源做更多的事情。我们实际上正在TSS中使用Copilot Studio和ServiceNow对此进行调查和实验。</p>
<p><strong>贾里德·皮尔彻：</strong> 我最兴奋的实际上是用于编码的人工智能，即智能体开发。我认为这为我们作为人类的成长，以及我们作为公司的加速发展提供了很多机会。我认为，作为工程师，我们忘记了很多可以解决的问题。更多地关注战略层面、更高层次可以真正帮助我们。更快地生产代码将是一个令人兴奋的机会，可以解决更多的问题、更多的挑战。我预见到一个时代，我们将能够极大地加快我们的开发速度，以至于首要问题将是如何更好地与之协调。我认为这将是一个关键的焦点，也是我们所有人都必须集思广益、共同解决的问题。但我对智能体开发感到非常兴奋和激动。我认为它不仅为帮助我们公司提供了很多机会，而且在全行业范围内，我们将看到许多伟大的新产品和挑战得到解决和处理。</p>
<p><strong>塞德里克·安：</strong> 在你进入下一个问题之前，为了让这看起来不像是由副驾驶生成的，我认为做人工智能研讨会的酷事就是你可以真正地挑战人工智能，因为这就是我们作为人类所做的。在拉希姆和贾里德提到的所有事情之间加上一个引述，我认为我们需要思考和生活在其中的一件事是，人类的潜力将会发生转变，就像人类历史上其他事物所做的一样。已经发生了转变，我们期望它会继续如此。我们越早接受它，越早与它合作，越早将其作为我们战略、我们关系、我们关怀的一部分，结果就会越好。</p>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 我的下一个问题实际上是给您和贾里德的。您如何展望未来5年人工智能将如何改变内部运营和生产力？</p>
<p><strong>塞德里克·安：</strong> 回顾过去，在未来5年，我们会发现这个十年基本上重新定义了工作。我们定义工作的方式正在被重新定义。人工智能成为工作方式的原生组成部分，不仅仅是辅助或帮助我们做某些事情，而是嵌入到我们所做的一切中。就像Excel在我们需要做电子表格时是事实上的标准一样，人工智能也融入了我们所做的一切。我用来阐述这一点的一个很酷的例子是，你实际上不是去看仪表板了解情况，而是仪表板来找你。当我们意识到这一点时，这将是随着时间的推移，我们将看到嵌入到我们所做的一切中的转变。它不会取代我们所做的事情；我认为它更多的是将我们从繁重的工作中解放出来。我认为这是一个很好的说法，繁重的工作指的是，无论是发送会议记录——这现在绝对可以做得更有效率——还是重复工作，在两个系统中输入条目——比如NetSuite和Salesforce。这正是我们应该期待在未来5年内成为过去的事情。我们总是会进行工作迁移，但同时，迁移会变得更加直观，而不仅仅是感觉繁重。肌肉记忆，我认为这将是挑战之一。我们作为肌肉记忆所做的事情，当你在其上添加人工智能时，在未来5年内，事情会看起来更加无缝、更加符合情境，但同时，你会感觉到某些事情变得无形。让我们准备好，接受并欢迎这种变化。</p>
<p><strong>贾里德·皮尔彻：</strong> 对我来说，这是个有趣的问题。今年年初，我以为我们可能要到明年才会认真考虑智能体软件开发。然后，当我看到Claude 4和Gemini 2.5问世，以及它们的开发水平时，我真的非常震惊。我认为我们进入这个领域的速度比我们预期的要快得多，而作为软件开发者，我们只需要抓紧，因为我们即将看到一些剧烈的、快速的变化。但不要害怕它。顺势而为，让我们一起解决它。根本目标是提高我们的生产力。我与我们的副总裁们交谈时一次又一次地看到这一点。重点是努力提高我们的生产力。我真正希望人工智能能做的一件事，我认为这没有被充分讨论，就是它提示我们并改善我们彼此之间的沟通。这确实是大多数组织都面临的问题——沟通问题。它还需要挑战我们，以便我们了解我们知道什么、不知道什么，以及所有可能的途径。这就是我期望人工智能在抽象层面上为我们做的事情。我只是还不知道它将如何被应用。</p>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 这个问题是给丽莎、贾里德和塞德里克的。团队如何培养一种对人工智能技术开放和创新的文化？</p>
<p><strong>丽莎·贾勒特：</strong> 我先说吧。在我做过人工智能的多个组织中，行之有效的方法是，当你面对一个要解决的问题或需要完成的编码任务时，首先问：“人工智能能做什么？”把这作为你的起点。或者，如果它不能全部完成，它能做一部分吗？然后问：“应该由人工智能来做吗？”因为不是所有事情都必须是人工智能。其他方法是否更适合，比如基于规则的方法？然后就是通过快速实验不断尝试。这其中一部分是心态问题，一部分是行为改变。我做过的另一种实践，我也看到很多人在做，而且我觉得非常有益，就是每天留出一部分时间，比如15分钟，或者一周两次，或者一周一小时，就是读书、读书、再读书。给自己设定一个挑战，然后去实现它，个人层面如此，然后看看你如何能从多个不同维度，在团队中加速这一过程。</p>
<p><strong>塞德里克·安：</strong> 我下一个发言。当我思考这个问题时，我可能会分享领导层的观点。我认为这始于允许团队进行实验、保持好奇心。生命中发生的大事都是从小处开始，然后逐渐变大。当我想到我的一个团队以及这种培养创新文化的想法时，几个月前我们将一个团队引入了技术服务部门，我们要求这个团队思考的一个问题是，“在你们所做的所有事情中，你们会自动化什么或以不同的方式做什么？”然后我们得到了一大堆想法，并尝试了其中的许多。那些被定义为更好、并取得了突破的想法，今天要么被自动化，要么正在成为一个智能体或类似的东西。如果我们允许实验，结果是令人难以置信的。对于我们领导者来说，将这种方法正常化非常重要，并确保当有伟大的新事物出现时，我们也会给予奖励，并且我认为将这一点置于完美之上是重要的。作为一个组织，我们应该感到有能力说，“是的，去构建它吧。”这是我所采取的方法上的一个改变，我希望其他人也能遵循这条路，因为我认为这对我们的团队将产生巨大的影响。</p>
<p><strong>贾里德·皮尔彻：</strong> 我很喜欢我们已经拥有的分享我们所做之事的伟大文化，以及乐于学习和保持脆弱的态度。我们几年前开始了一个人工智能实践社区，它仍在继续。我们会把链接发到频道里。请加入我们，让我们继续对话。我们正试图将这些对话和一般的人工智能对话，特别是在整个工程领域，引入到这个频道集中，所以请加入我们。我认为还有一件事，就是不仅要学习如何应用这些大型语言模型，还要学习它们在底层是如何工作的。这对我们所有人来说，至少在某种程度上，都是非常重要的一课。我们需要理解这一点，才能理解它的局限性是什么，以及我们在它能为我们预测什么、能帮助我们做什么方面缺少了什么。通过一些调整，我们还能实现什么？我们没有想到什么？所以，继续学习，加入我们找到的这些社区。让我们交谈，让对话继续下去。</p>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 这个问题是给丽莎、迪恩和拉希姆的。你们认为人工智能将以何种方式颠覆或增强整个医疗行业？</p>
<p><strong>迪恩·斯劳森：</strong> 我可以从这里开始。我的意思是，我将重点关注我们PointClickCare将如何利用人工智能和我们的产品来颠覆医疗保健行业。我们正在努力解决的一个领域是我称之为“护理人员短缺”的问题。我们最宝贵的资源之一就是护理人员的时间和精力。无论是由于护理人员短缺，还是干扰太多、信息太多，护理质量都会受到影响，护理人员的体验也会受到影响；他们会精疲力竭，这会让情况变得更糟。这是一种恶性循环。我们正在通过在我们的产品中使用人工智能来打破这种循环，从而在生产力和效率方面实现转型性的提升。例如，我们现在正在使用人工智能从非结构化数据中总结和提取最关键的信息，用于各种用例，比如我们在人工智能助手方面的工作。对于急症和支付方，我们有“转院原因”模型。这两项工作都在推进中，但这实际上只是我们能做的事情的皮毛。人工智能可以让警报变得更加智能，减少警报疲劳。很多任务都可以自动化。我们正在研究利用人工智能让MDS护士的角色效率提高10倍。想象一下，一个年薪约10万美元的职位，效率提高10倍。你为客户节省了9万美元。我想我们可以将其中一部分作为软件收入收回。但有了人工智能，我们将通过让从业者专注于他们最擅长的事情，更高效地工作，更好地利用他们的时间，然后让人工智能做它最擅长的事情：总结、优先排序、自动化任务，来颠覆医疗保健。</p>
<p><strong>丽莎·贾勒特：</strong> 迪恩很好地总结了PCC的具体情况，所以我会从更宏观的角度，跨越整个健康生态系统以及我们所涉及的各种流程来谈。我最兴奋的一件事是，人工智能和数据互操作性的进步为我们提供了调整管理规模的机会。在美国——很抱歉，我没有加拿大的统计数据——每花在医疗保健上的1美元，大约有30美分用于行政管理，而不是护理。你把这加到我们花费的数万亿美元上，这真的相当惊人。我认为，通过模型、智能体、以及经过适当优化的智能体人工智能，我们有机会改变这个比例。这是我们历史上调整这个比例的最好机会。这是我认为很了不起的一个领域。另一个领域是整个医疗生态系统，即那些护理过渡。更好的意识，更好地利用相关数据，在过渡前将数据交给正确的人，然后通过这些过渡实现更好的护理。我认为机会，特别是在智能体人工智能方面，非常令人兴奋。我只想在智能体上加个注。认识我的人都知道我常说，智能体人工智能有好用之处，但在医疗保健领域，你必须非常仔细地审视，看它是否真的是最合适的选择，尤其是在自主或半自主工作流程方面。</p>
<p><strong>拉希姆·哈什瓦尼：</strong> 在增强方面，我认为是速度、效率和自动化。自动化那些单调乏味的工作，减轻我们护理人员的行政负担，让他们能真正地提供护理。在效率方面，想想增强影像技术，例如。在某些领域，人工智能实际上在某些方面，比如检测中风或早期癌症方面，表现优于放射科医生。人工智能工具能以更快的速度、可能更高的准确性分析图像，并缩短将信息传递给护理人员的时间。个人经验，你知道，如果你去看医生，需要几天时间才能拿到影像并得到分析结果。如果你在急诊室，可能需要几个小时而不是几天，但你可以立即得到结果。所以，那段时间，那种行政负担被消除了，这样你就可以花更多的时间在那份护理上，而且你能更快地得到信息。这绝对是一个可以被增强和颠覆的领域。</p>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 这个问题是给塞德里克和迪恩的。我们的组织应该采取哪些战略步骤，以在医疗保健领域的人工智能创新中保持领先地位？</p>
<p><strong>塞德里克·安：</strong> 我先说吧。我认为作为一个组织，现在是时候从探索转向将其纳入运营了。探索的时代已经过去。我认为是时候将其投入运营，去尝试，去失败，再来一次。作为一个组织，我们所做的，而且从领导层那里非常清楚，人工智能是一项核心业务战略。它不仅仅是一项倡议；它不是实验室里的创新。我们从戴夫那里听了很多次，所以它来自哪里，并且它将成为我们未来DNA的一部分，这一点非常清楚。当我们思考需要将其嵌入到组织的哪些方面时——无论是入职、实施效率、产品，显然，正如你从丽莎和迪恩那里听到的，还是客户支持的时间表——关键在于将其作为核心业务战略的一部分。我想说的第二点是关于可及性。我认为我们越是普及它的使用，它作为一种实用工具、一种商业形式就越好。提示库就是一个很好的例子。对一些人来说，以某种方式向人工智能提问可能很困难，但当你听到别人是如何做的，它的能力和我们可以用它做的事情就变得更加清晰了。第三点是，当我们有这么多想法，当我们看到所有我们可以用它做的事情时，我认为作为一个组织，我们有责任确保我们做的是能让我们获胜的事情，而不仅仅是做一些很酷的事情或者只是因为我们能做。至关重要的是，这必须是出于正确的原因：降低成本，改善护理，显然，加速成果，更快、更好地实施，提高数据质量。所有事情都以一种能让我们获胜的方式进行，给我们一个在所处市场中获胜的机会。这可能就是我想分享的战略步骤。</p>
<p><strong>迪恩·斯劳森：</strong> 是的，这些都是很好的想法，我认为我将重点关注的是，我们需要投资于我们的方法，以便更快速地迭代这些人工智能能力和相关的用户体验。我们可以做一些工具和客户参与方面的改进，但与我们的客户一起更快地学习是能帮助我们领先的事情。在人工智能这个大伞下有如此广泛的技术。并非所有都是大型语言模型；还有小型语言模型、参数微调模型——我可以继续说下去，有几十种，而且每天都有新的出现。这些都有巨大的潜力，但前提是我们能将正确的技术以正确的方式应用于正确的问题，这是一个跨学科的合作。并非我们期望的每一个人工智能应用都能在实践中，在生产环境中，在规模化的情况下，按照我们想象的方式与真实用户一起工作。我们需要做好准备，对哪些技术可能在哪些产品中解决哪些用户体验问题做出明智、合理的选择，然后我们必须找到更快的方法。我们做出那些有根据的猜测，然后尝试它们，快速迭代。如果我们能比我们的竞争对手更快地收敛到高价值的解决方案上，我们就能赢，而且是大赢。如果我们不能，我们就会输，无论想法有多好。如果我们不能在学习、尝试、迭代和完善方面保持领先于竞争对手和市场，并使它们足够好——不是完美，只是足够好，以至于我们能提供差异化的价值——我们就能做到，但这需要一些专注和投资。</p>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 这个问题是给丽莎、迪恩和拉希姆的。在医疗保健环境中部署人工智能时，我们应该注意哪些道德考量？</p>
<p><strong>丽莎·贾勒特：</strong> 在医疗保健环境中应用这一技术需要考虑很多因素。负责任的人工智能涉及许多不同的维度。对于在座的各位，这里有一个快速指南：PointClickCare是一家经过ONC认证（ONC（国家健康信息技术协调员办公室）：一个促进全国性健康信息技术基础设施的美国政府机构。）的电子健康记录（EHR）提供商。去年，我们必须为一个新的人工智能重点领域完成该认证流程，ONC提出了一个简写，即FADES。F代表公平性（fairness），A代表适当性（appropriate），这是一个很重要的方面，V代表有效性（valid），E代表效率（effective），S代表安全性（safe）。我们的客户期望我们为他们做负责任的事情。他们不一定有资源去深入研究所有这些不同的维度。随着我们产品中人工智能部分的推进，他们期望我们进行测试和工作，使其透明、易于理解，并进行相关的风险管理。要对使用的数据来源保持透明。维度很多，最后一点我要说的是，这不是一次性的。当你在产品中加入人工智能功能时，你不是一次性完成RAI（负责任的人工智能）。你在整个生命周期中都要做，部署后也要继续做，因为情况会变。你可能会增强它，加入一些可能引入其他风险的东西。你必须记录你对这些风险做了什么。你需要能够教育你的用户你做了什么，并让他们了解情况。保持以用户为中心的视角，确保你清晰明了，回答他们的问题和担忧，并主动解决它们，这才是PCC作为思想领袖和市场领导者的机会所在。</p>
<p><strong>迪恩·斯劳森：</strong> 是的，我可以补充一点。那是个很棒的总结。我的意思是，你问的是道德考量，对我来说，那些是其使用背后的道德原则：比如公平、尊重隐私，以及思考社会影响。我们实践这些道德考量的方式，正是通过拥有丽莎刚才谈到的那一套负责任的人工智能原则。那些原则关注问责制、安全性、透明度、安全性，当然还有法规遵从性和人类监督。然后就是我们的诚信问题。当我们部署一个人工智能能力时，它是否做到了我们所说的？它是否既安全又有效？最终，为了在我们的AI使用中做到有道德和负责任，我们需要有一个清晰的价值主张，然后我们必须验证我们的解决方案是否兑现了那个承诺，并且没有有害的副作用。我们还需要统一我们的信息。我们不想过度承诺。这需要教育我们的客户，让他们了解我们的解决方案能做什么，不能做什么，如何使用，以及如何不使用。我们都看到了关于AI被用来不公平地拒绝索赔或在临床模型上过度承诺的负面新闻。但通过在AI的道德和责任方面走正道，我们真的可以使我们的产品，最终是我们的品牌，与所有那些AI炒作者区分开来。这对我们来说是一个很好的机会。</p>
<p><strong>拉希姆·哈什瓦尼：</strong> 都是很好的观点。我或许只想强调一下透明度。很多时候，人工智能模型或工具都在一个黑箱里运作，发生在幕后。并不一定清楚或容易理解一个由人工智能生成的决定或建议是如何做出的。患者应该了解人工智能是如何被用于他们的护理的。临床医生应该能够解释为什么一个人工智能工具为一个特定的治疗做出了推荐，以及导致那个推荐的因素是什么。这些工具不仅需要提供来源，还需要提供得出那个结论的推理过程。否则，你就是在破坏知情同意。那种透明度是关键。我在外面没有看到太多这样的东西，但我认为这对我们来说很重要，需要考虑。</p>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 实际上，在问答环节中出现了一个与这个对话非常契合的问题。问题是，我们如何在快速发展人工智能和保护客户的受保护健康信息（PHI）之间取得平衡？我们如何能确定大型语言模型（LLM）和模型不会与它们所托管和预训练的平台共享这些数据？</p>
<p><strong>迪恩·斯劳森：</strong> 是的，我可以稍微谈谈这个。这是高级技术小组和产品研究的一个重点。我们与法律、隐私和信息安全部门非常密切地合作，以确保我们有适当的流程和控制措施。首先，我们要确保我们有权使用数据，确保我们只在有适当控制的环境中使用数据，并且只用于我们有权使用的目的。严格的测试——我们做过红队演练，我们做其他类型的测试。这对我们来说是每天都首要考虑的事情。显然，我们客户的受保护健康信息（PHI）以及患者、居民或成员的PHI，不仅在法律上是我们保护的责任，在道德上也是。我们不希望我们的任何信息泄露或被不当使用。我只想说，这是我们工作的重点。</p>
<p><strong>丽莎·贾勒特：</strong> 我同意迪恩的看法。这与我们之前谈到的“开始、中间、之后”等信息是一致的。这并非一次性的工作。你在开发过程中就在做，但你也有义务在整个功能生命周期中继续这样做，以确保它持续保持安全可靠。至于速度，它是一个因素，但我们不会发布我们认为不安全或会危及受保护健康信息（PHI）的东西。</p>
<p><strong>塞德里克·安：</strong> 我们应该经常问自己的一个问题是，如果我们不希望这个人工智能工具、智能体或功能为我们自己的亲人做决定，那么就先不要部署它。</p>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 数据源中的偏见有多大的顾虑，以及如何确保人工智能的输出能提供公平的护理？如果历史数据确实存在偏见，我们该如何应对？</p>
<p><strong>丽莎·贾勒特：</strong> 我先说，然后我把它交给迪恩，因为我们从不同的角度看待这个问题。这是我们分析我们要解决的问题的一部分。我们有什么样的数据来做这件事？我们如何确保它没有偏见？以及我们如何前进？但这一切也都回溯到那些数据使用权。我们必须了解我们是否可以使用数据，我们有什么样的数据，以及在我们前进之前如何确保它没有偏见。我把它交给迪恩，因为他在这方面更深入。</p>
<p><strong>迪恩·斯劳森：</strong> 这也有技术方面的原因，因为正如问题中提到的，医疗数据中存在偏见。这是我们无法完全消除的，因为今天的数据主要是由人类参与生成的，而人类有偏见。这是我们在人工智能模型开发过程中主动关注的事情。我们进行二元分类，看看不同的群体是否对模型产生不同的输出。这是我们衡量和评估的事情，也是我们在部署后继续衡量的事情，因为人口、数据或偏见可能会发生变化，或者稍后会引入偏见。这也是我们努力减轻的事情。有时你可以改变模型的阈值并解决大部分偏见问题，或者很多时候是通过适当的沟通，让用户了解他们需要注意什么，因为你无法100%消除偏见。我们显然不希望发布对任何群体有害的东西，但我们也想创造更大的利益。这始终是一个关注的焦点和平衡，以确保我们发布的东西是负责任的，并且用户了解其任何局限性。</p>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 还有一个问题。Azure Studio对我们用户来说非常受限，只能使用聊天机器人。我们该与谁合作，以获取它提供的其他强大功能？</p>
<p><strong>拉希姆·哈什瓦尼：</strong> 老实说，联系我们。直接联系我，我们可以和你一起努力。显然，我们会对此负责并公平。外面有一些模型，我们可能不想启用，因为它们的来源问题，但我们当然可以帮助解锁一些功能。</p>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 你认为人工智能会使人类寿命更长，提高我们当前寿命的生活质量，还是两者兼而有之？</p>
<p><strong>迪恩·斯劳森：</strong> 这是个推测性的问题，但我非常希望并乐观地认为，不是人工智能本身，而是我们对人工智能的适当使用，具有巨大的潜力。我希望它能延长我们的寿命，并随之提高我们的生活质量。我认为，在医疗技术中使用人工智能和其他技术，有许多创新可以同时解决这两个问题。</p>
<p><strong>丽莎·贾勒特：</strong> 我想补充一点，迪恩说的都对，但我们仍然是人。所以，在人工智能或大型语言模型（LLM）真正从根本上改变我们的行为并鼓励我们改善健康之前，我认为两者都有机会对更广泛的人口健康产生影响。</p>
<p><strong>塞德里克·安：</strong> 我看到两件事。第一，活得更长可能更多的是活得更好。关于我们如何增加可以活动、思考、联系的年岁，并保持独立性，这一点值得一说。在我们的用例中，仅从PointClickCare的角度来看，并为我们的使命考虑，当你通过人工智能把时间还给你的临床医生时，突然之间你的摩擦就少了。当你从患者可以期望的角度思考时，你就有了一个主动的护理模式。最后，分享一下我拜访客户时所看到的，当你考虑到我们软件帮助照顾的所有弱势群体时，尊严是其中一个核心问题。当我们增强并提供所有这些工具时，这不仅仅是让生命更长，而是让生命更好。</p>
<p><strong>贾里德·皮尔彻：</strong> 我认为人工智能不仅能帮助我们回答我们已知的问题、做总结、辅助通知等，它在未来最大的影响之一将是帮助我们理解我们所不知道的。如果我们能真正抓住这一点，那么我们或许能回答我们甚至还没有问过的问题。这就是我希望看到的，然后这可能会转化为更长的寿命。</p>
<p><strong>阿鲁萨·卡兹米-伊沙克：</strong> 你会给过去的自己什么关于拥抱人工智能的建议？</p>
<p><strong>拉希姆·哈什瓦尼：</strong> 如果我能跳上那台德罗宁汽车回去，除了赌OKC赢得NBA总冠军，我会说，投入进去。就像，每天都用人工智能，并且分享。也推动别人去用。我可能会说，“嘿，我刚试了这个。你在干嘛？嗯，把它装到你手机上。就现在！现在就做！”然后让人们真正地拥抱它，比我们想象的还要早。建立那种肌肉记忆，养成那种习惯，接受它。</p>
<p><strong>塞德里克·安：</strong> 我会采取同样的方法。我会坐上我的德罗宁汽车，回去投资OpenAI。说真的，我认为我会用好奇心来对抗确定性。当我开始研究它时，我有很多偏见和想法，比如，“这真的会成为现实吗？”并且没有在我应该开始的时候开始。回到过去，我会更加好奇，并不断尝试，直到我们取得成功。</p>
<p><strong>迪恩·斯劳森：</strong> 我想首先，如果我现在能和过去的我对话，我会说：“好消息，你至少能活到2025年上半年。”但更重要的是，我会让我自己知道：“嘿，你将生活在世界软件创新最伟大的时代。”你所能支配的技术将拥有前所未有的潜力，可以创造有意义的价值，改变世界。我只会告诉自己，要花更多时间尽可能多地学习，尝试新事物，进行实验。有些事情你只能通过尝试和犯错来学习。我或许可以犯更多的错误，学到更多。犯错是可以的，但不去尝试是不行的。我可能会在我的职业生涯早期说，也许应该更深入一些。我记得我作为加州大学洛杉矶分校的研究生时，有幸上了一位人工智能早期领域的先驱朱迪亚·珀尔的课。他是贝叶斯网络的发明者，后来还获得了图灵奖。那是一堂有趣的课，然后我转向了其他事情。我一直都参与人工智能，但在我预见到今天发生的事情时，我可能会在某个特定的技术领域更深入地研究。相反，我更像一个通才未来学家，但这对我来说也还不错。我想说，对我们所有人来说，一个好的建议是，继续关注地平线。新事物总是在不断涌现。明智地押注。</p>
<p><strong>贾里德·皮尔彻：</strong> 我认为这正在开始流行，但人工智能不是一时的风尚。我两年前以为它可能是，所以我犹豫了一段时间。我确实加入了，但不是全身心投入，只是稍微试探了一下。所以，我会对过去的我对自己说，全身心投入，学习你能学到的一切关于大型语言模型（LLM）、关于智能体的东西，然后尽早地去推动边界。这就是我会告诉自己的。</p>
<h2 id="section-6-zh">六、闭幕词</h2>
<p><strong>玛丽娜·斯托扬诺维奇：</strong> 我们即将结束一个非凡的活动。这是PointClickCare的首次此类活动，我想花点时间回顾一下我们今天共同走过的旅程，以及我们光明而激动人心的未来。我将引用我们今天的主题——《回到未来》中的标志性二人组：布朗博士和马蒂·麦克弗莱。其中一件引人注目的事情是，“你的未来由你创造，所以把它创造得美好。”这即使在今天也是非常真实和睿智的建议。正如你所看到的，我们正站在一些令人难以置信的技术进步的边缘。谁能想到10年前我们会坐在这里谈论我们的小机器人助手能帮助我们做的所有事情？当我们回到1985年，思考他们对2025年的想象时，他们想象的是飞行汽车、悬浮滑板和自动系鞋带的鞋子，以及各种其他无限的可能性。尽管我们没有飞行汽车，但我们正在看到的创新确实非同寻常，我们只能看到它在未来几年加速发展。我想布朗博士会很高兴看到人工智能如何改变我们的世界，从彻底改变医疗保健，真正撼动其固有模式，到通过智能助手和自动驾驶汽车增强我们的日常生活，所有这些我们有时甚至没有注意到的乐趣。我认为马蒂·麦克弗莱会对人工智能带来的无穷无尽的创造力、创新和所有那些美妙事物感到兴奋。既然我们今天看到了如此令人难以置信的创造力，我们可以肯定地说，马蒂·麦克弗莱会为我们今天感到骄傲。但他们也会有他们的担忧，再次，我们今天已经谈到了很多这些话题。布朗博士可能会担心人工智能的伦理影响，比如确保所有这些技术都得到负责任的使用，并且不侵犯个人隐私。正如艾伦之前提到的，真正照顾好我们的个人信息和客户的信息。马蒂·麦克弗莱可能会担心人工智能有可能扩大那些能够接触到这些技术的人和那些不能接触到这些技术的人之间的差距。他们俩都会敦促我们所有人在应对这些挑战时保持警惕和积极主动。我们不要忘记，布朗博士可能会提醒我们避免任何通量电容器的意外。我们不希望意外地把我们的人工智能送回石器时代，或者更糟，送到拨号上网是常态的时代。马蒂·麦克弗莱会开玩笑说要确保人工智能不会对无糖百事可乐产生兴趣，因为谁想为一种已经不存在的苏打水付钱呢？</p>
<p>现在，我们将把话题交给我们的布朗博士，他有着更棒的发型。我们将把话题交给辛迪·普朗克特博士。她将从她的角度做一些总结性发言。</p>
<p><strong>辛迪·普朗克特博士：</strong> 非常感谢，玛丽娜。我想花点时间感谢并祝贺所有为今天的活动做出贡献的人：我们的策划委员会、我们的审查委员会、我们今天的演讲者——非常勇敢，感谢你们提交案例研究并与公司其他人分享。感谢我们的小组成员，以及我们依赖的众多顾问，是他们让今天的活动如此成功。所以，感谢所有帮助确保我们能够将人工智能研讨会带到PointClickCare的人。</p>
<p>提醒一下，任何新的人工智能工具都必须经过我们安全团队的审查，才能广泛使用，并且只能使用经过批准的人工智能工具。对于某些工具，它们需要购买许可证，所以这需要预算，并且你需要使用BuySmart流程。某些人工智能工具在数据质量、完整性和可扩展性方面需要额外的考虑。任何使用个人可识别信息（PPI）或受保护健康信息（PHI）的工具都需要特别考虑法规遵从性和隐私。我们今天在所有的案例研究中都看到了这一点，我们的小组成员也谈到了这一点。负责任和合乎道德地使用人工智能是必须的。始终仔细检查人工智能生成的响应，并确保它们是准确和可靠的，这是至关重要的。这有助于维护信息的完整性，并防止错误信息的传播，这对于可靠的内容至关重要。</p>
<p>展望未来，我认为今天帮助我们敞开了怀抱。让我们拥抱布朗博士和马蒂所体现的那种好奇、探索和创新的精神。让我们继续挑战可能的极限，并始终努力让我们的世界变得更美好，帮助每一位提供者提供卓越的护理。再次感谢所有提交用例的人，感谢我们敬业的审阅小组，感谢我们的组织者，以及感谢你们，我们所有的与会者，是你们让这次活动取得了成功。我们大家一起，正在塑造PointClickCare人工智能的未来，我迫不及-待地想看到我们接下来能取得什么成就。记住，未来掌握在我们手中。让我们把它创造得美好。非常感谢大家。</p>
`;


(function() {
    // --- Content Injection and Language Switching ---
    const enDiv = document.getElementById('content-en');
    const zhDiv = document.getElementById('content-zh');
    const enBtn = document.getElementById('lang-en-btn');
    const zhBtn = document.getElementById('lang-zh-btn');

    enDiv.innerHTML = enContent.trim();
    zhDiv.innerHTML = zhContent.trim();

    function switchLang(lang) {
        if (lang === 'en') {
            enDiv.classList.add('active');
            zhDiv.classList.remove('active');
            enBtn.classList.add('active');
            zhBtn.classList.remove('active');
        } else {
            zhDiv.classList.add('active');
            enDiv.classList.remove('active');
            zhBtn.classList.add('active');
            enBtn.classList.remove('active');
        }
        generateToc();
    }

    enBtn.addEventListener('click', () => switchLang('en'));
    zhBtn.addEventListener('click', () => switchLang('zh'));

    // --- TOC Generation ---
    function generateToc() {
        const activeContent = document.querySelector('.content-en.active, .content-zh.active');
        if (!activeContent) return;

        const headings = activeContent.querySelectorAll('h2, h3');
        const tocList = document.getElementById('toc-list');
        tocList.innerHTML = '';

        headings.forEach(heading => {
            const li = document.createElement('li');
            const a = document.createElement('a');
            a.textContent = heading.textContent;
            a.href = '#' + heading.id;
            li.style.marginLeft = (heading.tagName === 'H3') ? '20px' : '0';
            li.appendChild(a);
            tocList.appendChild(li);
        });

        // Smooth scroll for TOC links
        tocList.querySelectorAll('a').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
            });
        });
    }

    // --- Stats Calculation ---
    function calculateStats() {
        const fullText = enContent.replace(/<[^>]*>/g, " ").replace(/\s+/g, " ").trim();
        const wordCount = fullText.split(' ').length;
        const readingTime = Math.ceil(wordCount / 200);
        const zhText = zhContent.replace(/<[^>]*>/g, " ").replace(/\s+/g, " ").trim();
        const charCount = zhText.length;

        const statsDisplay = document.getElementById('stats-display');
        statsDisplay.innerHTML = `
        Word Count: ${wordCount} | Character Count: ${charCount} | Reading Time: ~${readingTime} min
    `;
    }

    // --- Markdown Conversion and Copy ---
    function htmlToMarkdown(htmlContent) {
        let markdown = htmlContent;
        // Process strong/bold
        markdown = markdown.replace(/<strong>(.*?)<\/strong>/g, '**$1**');

        // Process headings
        markdown = markdown.replace(/<h2[^>]*>(.*?)<\/h2>/g, '\n## $1\n');
        markdown = markdown.replace(/<h3[^>]*>(.*?)<\/h3>/g, '\n### $1\n');

        // Process paragraphs
        markdown = markdown.replace(/<p>(.*?)<\/p>/g, '\n$1\n');
        
        // Process list items
        markdown = markdown.replace(/<li>(.*?)<\/li>/g, '* $1\n');

        // Clean up extra whitespace and decode HTML entities
        markdown = markdown.replace(/(\n\s*){3,}/g, '\n\n');
        const tempDiv = document.createElement('div');
        tempDiv.innerHTML = markdown;
        markdown = tempDiv.textContent || tempDiv.innerText || "";

        return markdown.trim();
    }

    document.getElementById('copy-button').addEventListener('click', () => {
        const activeLang = enDiv.classList.contains('active') ? 'en' : 'zh';
        const contentToCopy = activeLang === 'en' ? enContent : zhContent;
        const markdown = htmlToMarkdown(contentToCopy);

        navigator.clipboard.writeText(markdown).then(() => {
            const button = document.getElementById('copy-button');
            const originalText = button.textContent;
            button.textContent = 'Copied!';
            setTimeout(() => {
                button.textContent = originalText;
            }, 2000);
        }).catch(err => {
            console.error('Failed to copy text: ', err);
        });
    });

    // --- Initial Load ---
    switchLang('en'); // Default to English
    calculateStats();

})();

</script>

</body>
</html>

