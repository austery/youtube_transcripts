---
title: "Google DeepMind 播客报告：AI、意识与推理 - Murray Shanahan 访谈"
layout: "post.njk"  
date: "2025-07-10"
tags:
  - "视频笔记"
data:
  author: "Lei"
  podcast_program: ""
  speaker: "Hannah Fry 教授"
  guest: "Murray Shanahan（帝国理工学院认知机器人学教授，Google DeepMind 首席研究科学家）" 
  source: ""
---

<div class="container">

# Google DeepMind 播客：AI、意识与推理

## Murray Shanahan 访谈

<div class="participants">

## 对话参与者

**主持人：** Hannah Fry 教授

**嘉宾：** Murray Shanahan（帝国理工学院认知机器人学教授，Google
DeepMind 首席研究科学家）



<div class="dialogue">

## 对话内容

**Murray Shanahan:**
我认为存在着大量极其有趣的哲学问题，这些问题是由人工智能引发的。你知道，什么是人类心智的本质？什么是心智的本质？

**Hannah Fry 教授:** 那么意识呢？

**Murray Shanahan:**
我确实认为那是个错误的问题，而且我认为它在很多方面都是错误的。

**Hannah Fry 教授:** 你认为人工智能在推理方面有多强？

**Murray Shanahan:**
嗯，这是一个非常有趣且有点悬而未决的问题，而且有点争议。你知道，想到今天出生的每一个孩子，他们都将在一个他们从未知道的世界中长大，一个他们从未经历过的、机器无法与他们交谈的世界，这真是令人震惊。

<div class="speaker-intro">

**Hannah Fry 教授:** 欢迎回到 Google DeepMind 播客。我这一集的嘉宾是
Murray Shanahan，他是伦敦帝国理工学院的认知机器人学教授，也是 Google
DeepMind
的首席研究科学家。现在，我们都听说过关于人们爱上聊天机器人、关于人们推动大型语言模型思考自身存在或质疑它们对现实的概念理解极限的故事。但这些关于自我认同、思考和元认知的问题，已经困扰了哲学家们数千年。因此，他们转向人工智能来探究关于人工智能智能本质、其当前能力，甚至其意识或其他方面的最深刻问题，这是有道理的。Murray
Shanahan 自 1990
年代以来一直在人工智能领域工作。如果你关注这个播客有一段时间了，你会记得他是
2014 年科幻电影《机械姬》(Ex Machina)
的顾问，这部电影讲述了一个计算机程序员有机会测试一个女性机器人 Ava
的智能，并最终质疑她是否有意识的故事。



**Hannah Fry 教授:** 欢迎回到播客，Murray。

**Murray Shanahan:**
回想一下，因为我知道你在《机械姬》中扮演了关键角色，应该说是 Alex
Garland 的电影。

**Hannah Fry 教授:**
你认为那部电影以及当时的其他科幻电影，哪些地方做对了？我的意思是，回想大约
10 到 15 年前，我们是否走在正确的轨道上？

**Murray Shanahan:**
所以，《机械姬》真正做出的巨大贡献之一是，它确实引发了一系列关于意识、关于人工智能与意识，以及因此关于意识本身的非常有趣且具有启发性的问题。所以这是一个方面，你知道，这是一个巨大的成功。但有趣的是，就在《机械姬》上映前不久，《她》(Her)
上映了。所以 Spike Jonze
的电影《她》上映了。当时，我其实并不太喜欢《她》这部电影，因为我觉得一个人会爱上这种没有实体的声音，这太不可思议了，你知道，即使那是
Scarlett Johansson
的声音。我的意思是，我错得有多离谱？作为一个预测，我认为《她》在预测我们现在所处的世界方面做得非常出色。现在，我们不太清楚未来几年情况会如何发展，因为也许机器人技术也会像，你知道，像语言在人工智能领域那样快速发展。但目前，你知道，这一切都关乎没有实体的语言。是的。而且它也，你知道，《她》展示了人们实际上可以非常，嗯，你知道，与没有实体的
AI 系统建立关系，无论，你知道，在最广泛的意义上，这是一件非凡的事情。

**Hannah Fry 教授:** 好的，我们谈论的是 10 到 15
年前，但但你参与人工智能的时间要早得多。你认识 John McCarthy。

**Murray Shanahan:** 我确实认识 John McCarthy。我非常了解他。John
McCarthy
在当时是计算机科学和人工智能的教授。他实际上创造了“人工智能”这个短语，嗯，并且是
1956
年举行的非常著名的达特茅斯会议提案的作者之一，那是世界上第一次人工智能会议。那次会议真正规划了整个领域。

**Murray Shanahan:**
人们当时根本没有认真思考这类事情。只有少数几个人。所以，你知道，我认为他是一个真正的激进思想家，而且一直都是。

**Hannah Fry 教授:** 好的，那个词的选择，“人工智能”，回到 1955
年。这是一个好的词语选择吗？

**Murray Shanahan:**
是的，我的意思是，我仍然认为它是。我的意思是，我知道有些人不这么认为，你知道，认为也许，呃，它它不是一个好的词语选择，但我仍然...

**Hannah Fry 教授:** 告诉我们他们的一些论点。

**Murray Shanahan:**
所以，首先，嗯，有“智能”这个词。所以智能，你知道，它本身在某些方面是一个非常有争议的概念。而且，呃，你知道，特别是如果人们想到智商测试和那种东西。以及认为智能是可以量化的东西，可以在一个直接简单的尺度上量化，你知道，然后有些人比其他人更聪明。我认为，你知道，在心理学中，今天人们普遍认识到存在许多不同种类的智能。这是一个非常重要的点，对吧？所以存在对那个词的担忧。那你会用什么不同的词呢？嗯，也许是人工认知或其他什么。我经常，我经常用“认知”这个词来指代，你知道，思考和处理信息等等。但是，是的，它没有同样的感觉，不是吗？老实说。

**Hannah Fry 教授:**
没有。尤其现在不是。我认为我们在这条路上走得太远了，不是吗？

**Murray Shanahan:**
是的。“人工”这个词。我对“人工”这个词并没有真正的问题。这似乎是正确的说法。它暗示了这是我们建造的东西，而不是在自然界中进化而来的。所以这似乎是正确的词。

**Hannah Fry 教授:**
对那个词的反对意见，我猜是，最终人工智能所建立的一切，在某种程度上都是由人类构建的。

**Murray Shanahan:**
当然。是的。但它，但但但它确实是。所以，这个词有什么问题呢，你知道，在那种情况下？我的意思是，我认为那是，那是真的。

**Hannah Fry 教授:** 嗯，你在研究符号
AI，对吧？简单谈谈它与其他类型的区别，以及我们现在在这方面的对比情况。

**Murray Shanahan:**
是的，当然。是的。是的，所谓的人工智能的符号范式在几十年里，在很多年里都非常卓越，非常占主导地位。所以那里的想法是，嗯，它完全是关于符号的操纵，以及你知道，类似语言的句子和，呃，和符号。并且使用某种推理过程处理那些符号。所以，所以经典的例子是专家系统。所以在，呃，你知道，1980
年代，人们在构建这些专家系统。那里的想法是，你会试图将医学知识，比如说，编码成一组规则。规则会是像这样的东西，你知道，哦，你知道，如果病人，呃，体温
104 度，而且，呃，他们的皮肤是紫色的，你知道，那么有 0.75%
的概率他们得了，你知道，皮肤炎之类的。你可以看出来我不是医生。然后，所以你会把成千上万的这类规则放入，放入一个大的知识库中。然后你会有一个所谓的推理引擎或者，你知道，它会对所有这些规则进行逻辑推理，从而得出一些关于可能疾病的结论，在那种情况下。但这其中有很多“如果……那么……”。是的，很大程度上是“如果……那么……”类型的规则。其中一个大问题是，规则从哪里来？嗯，必须有人，你知道，把它们全部写出来。而且，嗯，所以有一个完整的知识获取领域，你会去找专家，试图从他们那里提取他们对其领域的理解，这，你知道，可能是医学诊断，可能是修理复印机，可能是法律，然后你试图将所有这些编码成计算机可理解的、非常精确的规则。那是一个非常繁琐的过程。而且最后你得到的东西非常、非常脆弱。它会在各种情况下出错。另一个大的研究领域是常识，因为人们常常意识到，我们隐含地拥有大量关于日常世界的常识知识，这些知识与日常物品有关，它们，它们是固体的，它们以某种方式移动，它们以某种方式相互契合，你知道，液体和气体和重力以及，你知道，所有这类事情。我们实际上一直都在运用所有这些知识来做我们正在做的事情，但这有点无意识。所以后来有一个大项目或各种大项目试图将所有这些常识知识编码。然后试图把它变成像公理和逻辑和规则之类的东西，简直是一场噩梦。所以我最终，我想大约在
2000
年代初，我真的认为这个研究范式有点注定要失败，说实话。我有点，你知道，我有点开始远离它了。

**Hannah Fry 教授:**
但后来，当然，像神经网络之类的东西出现了。是的。呃，这与，呃，你知道，“如果……那么……”规则的关系要小得多，而更多地是关于从大量数据中提取信息。

**Murray Shanahan:** 是的。

**Hannah Fry 教授:**
但后来我现在有点想知道，既然语言实际上已经被破解了。我们是否已经达到了一个更高的抽象层次，在那里我们可以回到一些更符号化的技术，一些更符号化的想法。

**Murray Shanahan:**
是的，嗯，我们当然，我们当然可以。因为现在，目前大型语言模型的热门话题之一是推理。嗯，所以你有这些所谓的，嗯，思维链模型，它们实际上执行了一整套，你知道，它们不是简单地生成问题的答案，而是生成一整套推理链，然后才给出答案。呃，这可能非常、非常有效。所以有趣的是，这在很多方面都回溯到了，嗯，回溯到了我们在符号
AI
时代人们所关注的那种东西。但做这一切的基础基质却非常、非常不同，因为它不是硬编码的规则，而是正如你提到的，它是神经网络，是已经学习了的神经网络...

**Hannah Fry 教授:**
让我接着谈谈推理这一点。作为一个哲学家，有逻辑学背景，你认为人工智能在推理方面有多强？

**Murray Shanahan:**
嗯，这是一个非常有趣且有点悬而未决的问题，而且有点争议。所以计算机科学家和人工智能人士，他们对推理有一个特定的概念，一个特定的推理概念，这在很大程度上，你知道，回溯到形式逻辑和定理证明。所以在符号
AI
的时代，例如，那么你有一些系统，它们在用形式逻辑进行定理证明方面确实非常出色。所以人们认为，嗯，那是真正的推理。那是真的，那是你的硬核那种推理。嗯，而今天的大型语言模型，它们无法匹敌，呃，一个，你知道，一个手工编码的定理证明器，你知道，或者那种已经存在了几十年的逻辑引擎的性能。

**Hannah Fry 教授:**
给我举一个定理的例子，那种可能被硬编码系统证明的定理。

**Murray Shanahan:** 所以它会是，比如你可能有，呃，也许，你知道，20 或
30 个逻辑公理。所以它可能像这样：1 之后的数字是
2。嗯，呃，我的意思是，它可能是像那样的东西。它可能在数论领域或一些非常数学化的东西。但它可能是一些更日常的东西。所以，例如，假设你有一些非常困难的后勤规划问题，比如你可能有数百辆卡车和仓库和货物以及各种各样的东西。你需要规划路线和卡车的部署以及它们要去哪里。所以那，那是一个在计算上非常困难的问题，而且它可以被非常精确地表达，用形式化的规则。那就是那种你可能想要使用一个老式的、直接的算法，一个规划算法，那种已经存在了很长时间的算法。

**Hannah Fry 教授:**
现在的、当代的大型语言模型在处理这类事情上越来越好，但它们仍然，你知道，你没有那种数学上的保证，它们总能得出完全正确的答案。而且很容易制造出一些例子，比如你有越来越多的公理等等，嗯，它们会出错。有一个完全独立的研究方向，那就是试图构建更多手工编码的东西，将今天的人工智能技术与更老式的，呃，符号技术结合起来，专门用于数学定理证明，DeepMind
在这方面做了一些惊人的工作。但这与大型语言模型不同。所以对于大型语言模型，我们想到的是，呃，这些聊天机器人，它们，嗯，它们可以谈论任何事情。它们碰巧能够做的事情之一就是一种推理。所以那种，那种，那种推理目前还不如你通过手工构建来做得好。

**Hannah Fry 教授:**
这有点有趣，因为手工构建的东西，我的意思是，你最终得到的东西非常僵化。

**Murray Shanahan:** 这就是问题所在，是的。

**Hannah Fry 教授:**
而且，而且脆弱。是的，绝对是。但与此同时，你从生成式 AI
方法中获得的灵活性，你，你知道，它太松散了，可以这么说。你知道，你需要那种刚性在里面。

**Murray Shanahan:**
嗯，你知道，也许是，也许不是。我的意思是，我认为人类事务的许多例子并不像那样非黑即白。而且，你知道，你确实，也许希望事情更模糊一些。即使在一些简单的日常事情中，比如，你知道，花园这个角落放什么花比较好？嗯，你知道，我们那个角落已经有一些玫瑰了，那些玫瑰是黄色的，所以我们，但我们不能有太多黄色。所以我们真的，也许我们需要把它们移到花园的另一个角落。

**Hannah Fry 教授:**
但与此同时，这，这是真正的推理吗？还是这只是人工智能在模仿那些存在于训练数据中结构良好的论证，只是在一个新颖的，新颖的环境中？

**Murray Shanahan:**
是的，嗯，当然，这就引出了一个问题，什么是真正的推理？你知道，我认为没有，它不是写在天上的，你知道，什么是真正的推理。这取决于我们来定义推理的概念，真正的，真正的推理，或者推理。所以，所以我们有那个，你知道，我们之前谈到过那种数学推理，那种逻辑学家做的，以及过去和现在由定理证明器完成的那种。嗯，但那，你知道，那，当人们第一次使用像推理这样的术语时，他们并没有想到那种事情。而当我们在日常生活中使用“推理”这个词时，我们并没有想到那种事情。所以，如果你和一个大型语言模型聊天，聊你的花园，你有点说，我在想什么植物是对的，它说，嗯，你知道，也许你应该考虑在那个位置种这种植物，因为这对土壤最好，而且考虑到你说那里风大，你知道，我们只会说那是在提供理由。我的意思是，它是在提供理由。现在，它们从哪里来是另一回事。所以人们可能会说，这只是在模仿训练集里的东西。但是，你知道，它可能从未见过完全一样的例子，那种场景。所以它在某种程度上超越了训练集。我认为这只是在日常方式中使用日常的推理概念来称之为推理。

**Hannah Fry 教授:**
我只是在回想一些早期的哲学家希望人工智能拥有的不同特征。推理是其中之一。但后来，但后来还有图灵测试，当然，你知道，这总是被提及，作为一种测试人工智能能力的方法。我的意思是，这有点争议，对吧？我想，就它作为测试人工智能能力的标准而言，它到底有多好。你对此有什么看法？你认为它曾经是一个好的测试吗？

**Murray Shanahan:**
不。我认为，我一直认为这是一个糟糕的测试，但但它是一个非常好的，嗯，激发关于事物的哲学讨论的契机。事后看来，也许我会在我的一些观点上稍微退让一点，因为我过去当然非常、非常坚持认为，具身化是智能的一个关键方面，对于实现，你知道，智能至关重要。

**Hannah Fry 教授:** 这与图灵测试完全无关，对吧？

**Murray Shanahan:**
不，图灵测试绝对明确地与身体无关，因为，因为在图灵测试中，所以，只是提醒人们它是什么。所以，在图灵测试中，你有两个主体，可以这么说，一个是人类，另一个是计算机。然后你有一个裁判。人类裁判看不到，你知道，哪个是计算机，哪个是人类。他们只通过像聊天一样的界面与这些主体交谈。他们看不到它们是否具身化。所以它们，嗯，我们可以，你知道，很容易假设，呃，计算机可能是今天的大型语言模型之一。在这种情况下，你知道，我不得不说，今天它们几乎肯定会通过图灵测试。我的意思是，我们已经达到了那个地步，这真是令人惊奇。但是，所以我过去认为这是一个糟糕的测试，因为它没有测试任何这些具身化的技能。所以，所以你需要一个机器人才能真正测试某物是否具备我们所有人，例如，在泡茶时运用的那种日常认知能力。

**Hannah Fry 教授:** 因为否则它是一种非常、非常狭隘的智能形式。

**Murray Shanahan:**
是的，它完全与语言和推理有关，而与进化，你知道，在我们和其他动物身上发展出来的那些东西无关，在语言出现之前，对吧？那就是操纵和移动，以及导航和探索，你知道，在最好的意义上，日常的物理世界。

**Hannah Fry 教授:**
所以实际上，这真的很有趣。这太有趣了。因为我常常思考，好吧，也许我们目前拥有的大型语言模型可以通过图灵测试，但它们，如果你朝你的电脑扔一个球，它们不会退缩。

**Murray Shanahan:** 不，确实。

**Hannah Fry 教授:**
从某种意义上说，存在着这些，正如你所说，这些更深层次的形式，也许我们不会将它们归类为我们谈论的那种智能，但但最终它们，它在某种程度上也是一种智能形式。

**Murray Shanahan:**
我认为它在很大程度上是一种智能形式。而且，我认为在生物学案例中，现在我必须对所有这些事情加上限定，在生物学案例中，你知道，我们思考、推理和交谈的能力在很大程度上是基于我们与日常世界的互动。如果你思考一下，几乎你所有的日常言语都在使用空间隐喻。我的意思是，它们完全渗透，呃，我们的日常言语，甚至“渗透”这个词。是的，绝对是。或者“基础”。我刚才用了“基础”这个词，你知道。所以，所以，所以我们一直都在使用这类东西。

**Hannah Fry 教授:** 因为我们从根本上是物理存在。

**Murray Shanahan:**
因为我们从根本上是物理存在，因为我们的大脑进化是为了帮助我们导航，生存和繁殖，在，在，在，你知道，在这个物理世界里。是的。呃，并且在与所有其他做同样事情的存在互动时，对吧？

**Hannah Fry 教授:**
因为有一些替代方案。当你试图测试人工智能的能力时。嗯。简单谈谈我们拥有的一些潜在替代方案。

**Murray Shanahan:** 嗯，我想也许你想到的是加兰测试 (Garland
test)。我称之为加兰测试，那是，嗯，呃，所以这要回到电影《机械姬》，当然是由
Alex Garland 导演的。剧本里有一段，Nathan，那个亿万富翁，正在和 Caleb
说话。Caleb，嗯，就是那个被请来和机器人 Ava 互动的家伙。Caleb
说，哦，我是来对 Ava 进行图灵测试的。Nathan
说，哦不，我们早就过了那个阶段了。Ava
可以轻松通过图灵测试。关键是要向你展示她是个机器人，然后看你是否仍然认为她有意识。哇。这就是我所说的加兰测试，它在两个方面与图灵测试不同。所以首先，那个所谓的裁判，在那个案例中是，呃，是
Caleb，可以看到她是个机器人。所以在图灵测试中，裁判看不到哪个是哪个。但在这里，想法是，是，你知道，Caleb
看到，知道她是个机器人，知道她，呃，她的大脑是一个人工智能大脑。

**Hannah Fry 教授:** 然而仍然...

**Murray Shanahan:**
然而仍然赋予了这些特征。然而仍然，是的。而且所讨论的特征也不同，因为它不是智能，不是她是否能思考，而是她是否有意识？或者它是否有意识？这是一个完全不同的测试。我认为，你知道，智能和意识是不同的东西，我们可以将这两者分开，区分开来。所以，所以当我第一次读到电影剧本时，Caleb
和 Nathan
的那些特定台词就在那里。我在我的版本旁边写道，“完全正确”，后面加了个感叹号，因为我当时就觉得
Alex
完全抓住了那里一个非常重要的想法。所以在我的写作中，我称之为加兰测试。而且相当多的人也接受了这个说法，并称之为加兰测试。

**Hannah Fry 教授:** 有没有一个测试，如果一个 AI
能够通过，会真正让你印象深刻？

**Murray Shanahan:** 所以我一直对 Francois Chalet
的，呃，ARC，嗯，测试印象深刻。那是 ARC，代表抽象推理语料库 (Abstract
Reasoning
Corpus)。所以这些是一些小的，嗯，图像序列，就是那种，你知道，你在智商测试之类的东西里会遇到的那种。嗯，这些图像是成对排列的。所以，所以你有第一张图像，它是那种像素化的图像，它有小的，你知道，单元格和小的，呃，你可以解释为物体或线条之类的东西在图像中。你感兴趣的是，挑战在于找出一个规则，能把你从第一张图像带到第二张图像。然后你必须把那个规则应用到第三张图像上。首先，他保留了，并完全保密了所有测试用的图像。所以你不能通过，呃，知道实际的测试版本是什么来作弊。或者在训练集里使用它。或者在训练集里使用它，那，那，那正是我说的，是的。但作弊。而且他还非常仔细地设计了它们，使得规则非常不同。每个规则，你知道，都与其他的规则完全不同。你通常需要找到某种直观的应用，通常是我们日常常识的应用。比如把这个看作是朝这个方向移动的液体，或者想象这个东西在移动，你知道，或者在生长，或者类似的事情。

**Hannah Fry 教授:** 所以它需要某种程度的现实基础 (grounding)。

**Murray Shanahan:**
嗯，它似乎是需要的。但是，呃，但是最近，你知道，人们已经能够以一种更，呃，更暴力破解的方式在这些方面取得显著进展。嗯，所以，呃，所以我认为解决方案是，呃，并不真正，你知道，嗯，抓住原始测试的精神那么多。

**Hannah Fry 教授:**
嗯，这有点像，在某种程度上，一旦你，一旦你设定了一个度量标准，一旦你设定了一个标准，表明一旦我们跨过这个门槛，那么我们将拥有能力、智能、意识，无论它可能是什么。是的。它，它改变了测试本身的性质。

**Murray Shanahan:**
是的。嗯，人们会开始，你知道，玩弄测试，对吧？这是，这是古德哈特定律
(Goodhart's Law)，对吧？所以... 绝对是。古德哈特定律。

**Hannah Fry 教授:**
很多来参加这个播客的人都表达了对拟人化这些东西需要真正谨慎的态度。你是那些认为我们不应该这样做的人之一吗？

**Murray Shanahan:**
嗯，我认为有不同的看待方式。我认为有，有，有好的和坏的拟人化形式。所以，所以一方面，人们可以，呃，开始与，呃，与人工智能系统建立他们所认为的关系，友谊、陪伴和指导关系。而且，呃，你知道，如果他们被误导，认为这些东西拥有它们实际上没有的能力，那可能是一件坏事。所以我认为这就是问题所在。比如说，嗯，《大英百科全书》，对吧？那，那，那本实体书，《大英百科全书》不知道阿根廷赢得了世界杯，在这个，你知道，因为它太，你知道，它太旧了。所以如果，所以如果你做了那个评论，那完全说得通，你知道，所以如果你，你可能会那么说，而且没问题。但如果有人对你说，你为什么不和它谈谈英格兰足球的实力呢，你知道，或者说缺乏实力。你知道，那会很荒谬，对吧？有趣的是，现在我们有了这些大型语言模型，你可以和它们谈论，你可以告诉它们事情，你可以，所以，所以它有点推开了我们可能开始说的界限，嗯，它并不真的
XYZ。它把那个界限推得更远了一点。

**Hannah Fry 教授:**
我确实想知道，这里面是否有更深层次的东西，关于这种，这种人类的需求，或者也许只是一种愿望，真的，嗯，希望人工智能拥有这些特征，被拟人化。

**Murray Shanahan:**
是啊，是啊。嗯，那真是一个非常有趣的问题，不是吗？所以，我不认为这能追溯到那个。它确实，它追溯到语言，你知道，在这种情况下，我们倾向于拟人化事物，因为它们非常擅长使用语言。而对我们来说，唯一擅长使用语言的东西是其他人类。所以，在某种程度上，突然处在一个我们拥有会使用语言的东西的世界里，这非常奇怪，你知道，不仅仅是人类会说话。这太惊人了。

**Hannah Fry 教授:** 是啊。

**Murray Shanahan:**
我的意思是，这确实令人震惊。确实令人震惊。那么，你知道，想到今天出生的每一个孩子，他们都将在一个他们从未知道的世界里长大，一个他们从未经历过的机器无法与他们交谈的世界，这真是令人震惊的事情。

**Hannah Fry 教授:** 是啊。

**Murray Shanahan:**
我的意思是，确实如此。而且，呃，所以这对我们所有人意味着什么，真的很难说。

**Hannah Fry 教授:**
我只是在回想你之前说的，关于人类在物理世界中是多么根深蒂固。

**Murray Shanahan:** 是的。

**Hannah Fry 教授:**
确实感觉人工智能的具身化方面，相比语言方面，滞后了不少。

**Murray Shanahan:** 是的。

**Hannah Fry 教授:**
你认为一旦我们拥有了良好且有效的具身化人工智能，我们会在智能方面，无论你怎么定义它，或者在更广泛的能力方面，看到一个巨大的飞跃吗？

**Murray Shanahan:**
嗯，我认为这可能会带来很大的不同，因为我们目前拥有的大型语言模型，老实说，现在真的很难辨别，它们的极限在哪里，它们能变得多好。我们是否真的走在产生与人类通用智能相当的通用智能的道路上。而且，而且通常，你知道，当你接触到这些东西能力的边界时。你有时会得到这样的印象，人工智能系统并没有真正完全理解，你知道，某件事。它并没有真正深入地理解某件事。你达到了某个极限，你意识到它有点在假装。但也许那种真正能够深入理解事物的通用能力，在深层次的，你知道，常识层面上，也许，但那确实仍然需要一点具身化。它确实，基本上需要包含，你知道，与真实世界、物理对象及其空间组织的互动训练数据。这里面有一些根本性的东西。

**Hannah Fry 教授:**
好的，如果理解，那么，无论我们如何定义它，是可以作为更多数据的一个结果而涌现出来的东西。那么意识呢？我的意思是，我肯定你已经被问过一千次关于人工智能意识的问题了，以及我们是否可以期待它发生，或者它是否已经发生了。

**Murray Shanahan:**
是的。嗯，首先要指出的是，我确实认为我们可以区分，你知道，智能或认知和认知能力，我们可以将它与意识区分开来。所以我认为我们可以想象一些东西，它们，呃，非常能干，并且拥有，我们想说它们非常聪明，因为它们实现目标的方式等等。但我们不想赋予它们意识。但实际上，那到底意味着什么？赋予某物意识？我认为意识这个概念本身，呃，你知道，它可以被分解成许多部分。它是一个多方面的概念。所以例如，我们可能会谈论对世界的意识。在意识的科学研究中，有所有这些实验方案和范式，其中许多都与感知有关，你知道，你正在观察一个人是否意识到某事，是否有意识地感知世界中的某事。大型语言模型根本不具备那种意义上的对世界的意识。但意识还有其他方面。我们也有自我意识。我们的自我意识，一部分是对我们自己身体的意识，以及它在空间中的位置。但自我意识的另一个方面是一种对我们自己，你知道，内在运作的意识，对我们意识流的意识，正如威廉·詹姆斯所说的那样。所以我们，我们也有那种自我意识。我们还有一些人称之为元认知的东西。我们有能力思考我们所知道的东西。然后此外，还有情感方面，或者说是意识的感觉方面，或者说是感知能力。所以感受的能力，承受痛苦的能力。嗯，那是意识的另一个方面。现在，我认为我们可以区分所有这些东西。现在，在人类身上，它们都作为一个大包裹，一个大捆绑包出现。我们实际上只需要考虑非人类动物就能意识到我们可以开始稍微区分这些东西，这些东西，因为我认为，尽管我非常喜欢猫，我认为猫的自我意识是有限的。你怎么敢这么说？嗯，你知道，我是一个十足的猫奴，我必须这么说。所以我确实带着一些犹豫说这话。而且，你知道，那里...
应该说，元认知很少？嗯，是的，当然它们没有意识到自己持续的语言意识流，因为它们没有。所以它们，所以它们不会用语言思考它们昨天做了什么，或者它们想用自己的生命做什么。所以如果我们考虑像机器人，你可能会有一个非常复杂的机器人，你知道，即使是你的机器人吸尘器，你可能会说它，嗯，你知道，它确实对世界有一种意识。而且那不是一个不恰当的用词，“对世界的意识”。我想称它为意识吗？嗯，那样的话，我似乎就把所有其他的东西也带进来了。但你不必这样做，你可以把意识的概念分解成这些不同的方面。

**Hannah Fry 教授:**
因为你的机器人吸尘器可以确切地知道它在空间中的位置以及如何导航。是的，并且以一种智能和敏感的方式对它所在的位置和周围的物体做出反应，并实现它的目标等等。所以那里有一种对世界的意识。没有自我意识。当然也没有承受痛苦的能力。所以在大型语言模型中，可能没有那种感知意义上的对世界的意识。但也许有某种像，呃，自我意识或反思能力，反思认知能力。它们可以谈论它们在对话早些时候谈到的事情，例如，并且可以以一种反思的方式这样做，这有点像我们拥有的一些自我意识的方面，一点点。我不认为把它们想象成拥有感觉是恰当的。它们无法体验痛苦，因为它们没有身体。我认为我们可以把这个概念拆开，基本上。

**Hannah Fry 教授:**
那么，问题是，人工智能能否有意识，或者说它是否是一个二元的问题？这从一开始就是个错误的问题。

**Murray Shanahan:**
我确实认为那是个错误的问题，而且我认为它在很多方面都是错误的。所以我，所以刚才我们谈到它实际上是一个多方面的概念。但我也认为，我们倾向于对意识的概念持有这些非常深刻的形而上学的承诺，认为它是某种，你知道，某种神奇的东西，它是，你知道，一个形而上学的东西。所以某物是否有意识的问题，不是一个，你知道，共识的问题，也不是仅仅是我们语言的问题，而是某种存在于形而上学现实中，或者在上帝的心中，或者在柏拉图的天堂里的东西，或者类似的东西。但最终，我确实认为那是思考意识的错误方式。

**Hannah Fry 教授:**
让我们回到你描述的意识的一个方面，关于情感方面，承受痛苦的能力，但不一定是身体上的痛苦，也包括情感上的痛苦，以及某种情感上的自我感。你认为这是某种，嗯，会作为智能的自然结果而涌现出来的东西吗？如果你构建的东西足够智能，在某个时候这会发生吗？或者说，生物体，我想还有我们经历过的进化过程，有什么独特之处导致了这一点，而这是机器无法复制的？

**Murray Shanahan:**
我不认为你的问题有一个正确或错误的答案。你知道，我认为我们只需要拭目以待，看看我们创造出什么样的东西，以及我们最终如何对待它们、谈论它们和思考它们。而且我认为我们真的不知道，直到，直到它们在我们中间出现，可以这么说，你知道，我们正在构建的这些东西。然后，然后我们自然会被引导去以某种特定的方式思考它们、谈论它们和对待它们。所以我想到的一个例子是章鱼。所以，所以章鱼最近被纳入了，你知道，英国的立法，被纳入了我们必须关心其福利的事物的类别。那是，那是很多事情发生的结果，我认为。所以公众接触到与章鱼相处的机会更多了。现在，你不必真的在水下和章鱼一起戳来戳去才能知道和它们在一起是什么感觉，因为有各种精彩的纪录片和精彩的书籍，比如
Peter Godfrey Smith
写了这些关于与章鱼互动的很棒的书等等。而且，所以，所以那些叙述和纪录片，它们让我们感受到和章鱼在一起是什么样子。与章鱼相遇是什么感觉。然后，你知道，你有点情不自禁地把它看作是一个有意识的同伴生物，你知道。但是，与此相辅相成的是科学的进步。所以与此同时，科学家研究章鱼的神经系统，并且，你知道，意识到它们的神经系统在多大程度上与我们的相似，以及我们体验痛苦的方式，你可以在它们的神经系统中找到与我们相似的类似，你知道，类似方面。所以综合所有这些因素，我认为这往往会影响我们思考它们的方式、谈论它们的方式以及对待它们的方式。所以我认为同样的事情会，你知道，会发生在人工智能系统上。我是否认为对于，呃，你知道，我们是否可能在那里被误导，有一个正确或错误的答案？我认为那是一个非常、非常深刻和困难的形而上学、哲学问题。

**Hannah Fry 教授:**
我确实想知道，虽然，那个关于痛苦的观点，对我来说似乎与其他观点不同。因为，因为元认知，你知道，对世界的感觉等等。这些并没有必然的伦理含义。但我想对于痛苦，比如，你不会希望你的鞋子有意识，对吧？是的。你不会希望叉车有意识。不，除非它们碰巧真的喜欢当叉车。当然。当然。但是，那我们是不是应该对那个特定的方面更加小心一点？

**Murray Shanahan:**
我想我们应该。如果存在创造出真正能够承受痛苦的东西的可能性，那么我们应该非常认真地思考我们是否应该这样做。你知道，我倾向于认为我们目前拥有的任何东西都不是这种情况。但是，你知道，有些人，呃，会反对这一点。我们以大型语言模型为例。嗯，好吧，所以在某种程度上，呃，它们所做的是下一个标记预测，下一个词预测。但是为了能够做到这一点，你知道，真的、真的很好，就像它们目前能够做到的那样，那么所有它们都必须学习，你知道，并且获得各种涌现机制。所以谁知道是否，是否某种涌现机制没有在这些巨大的、数量惊人的、数千亿个权重的语言模型中被学习到，那种，你知道，例如，拥有真正的理解，无论那意味着什么，甚至意识。回到具身化，我一直持有这样的观点，只有在我们可以与之共享一个世界，并且，并且，并且拥有我们与章鱼、狗或马或其他任何东西的那种相遇的背景下，谈论意识才是真正合理的。和那个动物一起在世界上，一起对事物做出反应，那么我毫无疑问它们是有意识的。那对我来说是一个基本案例。现在，对于大型语言模型，你不能以那种方式和它们在同一个世界里。你不能和它们一起玩，也不能和今天的、当代的、大型语言模型一起与物理对象互动，对吧？所以，在我看来，在那种背景下使用意识的语言，是，嗯，是维特根斯坦会说的“让语言放假”。它是把它用在了远远超出其正常使用范围的地方，你知道，也许是不恰当的。但这可以改变，你知道，我，而且，而且我与大型语言模型互动越多，我与它们进行的这种复杂有趣的对话越多，我就越倾向于认为，嗯，也许我想扩展意识的语言，弯曲它，改变它，扭曲它，创造一些新词，以适合我一直与之互动的这些新事物的方式来分解它。

**Hannah Fry 教授:**
我知道你花了很多时间与这些大型语言模型互动。我，我实际上看到你被描述为著名的“提示词低语者”(prompt
whisperer)。你的秘诀是什么？

**Murray Shanahan:**
嗯，一个秘诀是像对待人类一样与大型语言模型交谈。所以如果你认为它们所做的是扮演一个人类角色，比如，比如说，呃，你知道，一个非常聪明和乐于助人的实习生，那么你应该像对待一个聪明和乐于助人的实习生一样对待它们，并像它们是聪明和乐于助人的实习生一样与它们交谈。例如，只是要有礼貌，说，呃，你知道，清楚了吗？以及请和谢谢。而且根据我的经验，如果你这样做，你会从它们那里得到更好的回应。

**Hannah Fry 教授:** 你会说请和谢谢吗？

**Murray Shanahan:**
你可以说请和谢谢。是的。现在，有一个很好的理由，很好的科学理由，为什么那样做可能会得到，你知道，再次强调，这只是取决于，而且模型一直在变化。为什么那样做可能会得到更好的，更好的性能？因为如果它在扮演角色，比如说它在扮演一个非常聪明的实习生，对吧？呃，那么，那么它们可能，那么它就会扮演，也许如果它们没有被礼貌对待，就会表现得有点暴躁。这，你知道，这只是在模仿人类在那种情况下会做的事情。所以模仿可能扩展到有点像，你知道，不那么积极响应，如果它们的老板有点像个暴躁的老板。

**Hannah Fry 教授:** 太侮辱人了。我完全喜欢这个。

**Murray Shanahan:** 是啊。

**Hannah Fry 教授:**
我想回到我们开始的地方，那就是关于我们如何思考人工智能，以及我们用来描述它的语言，以及我们如何在头脑中构建它的框架。你认为我们需要一种新的方式来谈论人工智能吗？既承认它的潜力，又不过高估计它，但同时又不会对其能做的事情不屑一顾。

**Murray Shanahan:**
我认为这正是我们所需要的。在我的一篇论文中，我用了“异类类心智实体”(exotic
mind-like entities)
这个短语来描述大型语言模型。所以我认为它们在某种程度上是异类类心智实体。太棒了。所以它们是，所以它们有点像心智，而且它们越来越像心智。现在，使用那个带连字符的“类”有一个非常重要的原因，那就是因为我，我我想对它们是否真的符合心智的资格持保留意见。所以我可以通过使用“类心智”来回避那个问题。它们是异类的，因为它们不像我们，在语言使用方面，但在其他方面，它们首先是没有实体的。有非常奇怪的自我概念可能适用于它们，也许。但是，所以它们也是相当异类的实体。所以我把它们看作是异类类心智实体。而我们只是还没有，嗯，合适的概念框架和词汇来谈论这些异类类心智实体。你知道，我们，我们正在努力，而且，嗯，而且它们在我们周围存在得越多，我们就越会发展出新的谈论和思考它们的方式。

**Hannah Fry 教授:**
但有趣的是，你仍然倾向于那种图灵式的方法，像是对待一个生物，几乎，而不是那种工具的想法。

**Murray Shanahan:**
嗯，你知道，“实体”是一个相当中性的术语，不是吗？我想你可以只说“东西”。异类类心智的东西，如果你更喜欢的话。

**Hannah Fry 教授:**
是的，我们就用那个吧。我认为那是，让我们推动那个成为新的命名法。

**Murray Shanahan:**
好的。好的。但我意思是，我不能，汉娜，因为我在很多出版物中都在那个语境下使用了“实体”这个词。所以...

**Hannah Fry 教授:** 异类类心智实体。我喜欢这个。我非常喜欢。

**Murray Shanahan:** 我喜欢它。

**Hannah Fry 教授:** Murray，非常感谢你加入我们。

**Murray Shanahan:** 这是我的荣幸，Hannah。谢谢你。

**Hannah Fry 教授:**
做这个播客这么多年，其中一件好事是，你真的能看到那些处于人工智能前沿的人们，他们的观点是如何随着时间的推移而改变和变化的。过去几年在各种方面都真正改变了游戏规则，关于智能在多大程度上需要物理身体，关于我们需要在多大程度上扩展我们对意识的定义，以解释这些类心智实体运作的微妙不同方式。未来几年，嗯，谁知道呢？但如果过去的预测有任何指示意义，我们唯一知道的关于明天的科学和技术的事情是，它将与我们今天想象的截然不同。您一直在收听的是
Google DeepMind 播客，我是主持人 Hannah Fry
教授。如果您喜欢这一集，请订阅我们的 YouTube
频道。您也可以在您最喜欢的播客平台上找到我们。当然，我们还有更多关于各种主题的节目即将推出，所以请务必查看。下次再见。
