---
title: "AI的使用方法与能力边界"
layout: "post.njk"  
date: "2025-07-10"
tags:
  - "视频笔记"
  - "AI"
  - "Prompt Engineering"
  - "思维链"
  - "RAG"
  - "工作流"
data:
  author: "Lei"
  podcast_program: ""
  speaker: ""
  guest: "" 
  source: ""
---

# AI的使用方法与能力边界

## 引言：AI付费现状与讨论范围

首先，我想了解一下在座各位中已经为AI服务付费的朋友。看来，这部分人群数量可观。那么，每月付费超过20美元，例如同时订阅两三个服务，月支出达到五六十美元的用户也为数不少。这表明，今天在场的许多人可能已经对AI进行了较为深度的使用。

然而，今天我主要探讨的是AI在编程领域之外的应用，因为我并非程序员，我的工作主要集中在AI如何与语言输出等领域相结合。至于AI在编程方面的应用，我了解不多，因此将重点讨论其他方面。关于建立交流群的事宜，考虑到内容需要融会贯通，我们后续再作商议。

## AI的核心能力与想象力的关系

当前AI的能力上限，与其自身技术水平的关联度相对较小，而更多地取决于使用者的想象力——即您能设想AI以何种方式服务于您的需求。实际上，AI的现有性能已远超多数人的想象，很多时候，我们仅仅是未能想到AI可以如此运用。

大多数人在使用AI时，会沿用过去使用搜索引擎的习惯，以一种搜索引擎的心态来与其交互，即通过“某事物是什么样”这类自然语言问题进行提问。这种方式并非不可行，且在最新版本的AI中效果尚可。但是，若固守此种心态，可能无法充分发挥AI的潜能。

因此，今天分享的内容，或许在掌握核心方法后，大家关于AI的多数疑问都可以直接向AI本身寻求答案，而无需再求助于他人，因为这些问题AI大多能够解答。

## AI技术演进：从提示词工程到自然语言交互

在此，我想强调一个关键的转变。AI技术初期，例如前年OpenAI刚问世时，曾出现一个名为“提示词工程师”（Prompt
Engineer）的职业，他们负责设计如同“咒语”般的提示词，不同的提示词会产生迥异的结果。当时，网络上甚至涌现了许多相关的付费知识产品，部分价格不菲，高达万元以上，专门教授如何编写提示词。然而，时至今日，所有这些方法论都已过时，不再是必需的。现在，用户完全可以使用更自然的语言与AI进行交互。这主要归功于“思路链”（Chain
of
Thought）技术的出现与发展，它极大地提升了AI的实用性。正是从那时起，提示词工程的技术门槛大幅降低，使得普通用户的AI应用变得异常便捷，进而催生了AI更为广泛和深入的用途。

## AI的基本原理：预测下一个词而非真正思考

首先，我将简要介绍当前AI技术的基本逻辑。我不敢断言能讲清其技术原理，因为背后涉及诸多复杂层面，我只能阐述其技术逻辑。

大家或许还记得，OpenAI的ChatGPT刚推出时，确实令人惊艳。但同时，人们也发现它在处理一些非常简单的问题时会出错，例如无法判断32和38哪个数字更大，或者6在7之前还是之后。这不禁让人困惑：如此强大的工具，为何连如此基础的问题都无法解答？尽管这些问题现在已有所改善，但偶尔仍会发生，让人感觉AI在简单问题上表现不佳，却在复杂任务上能力超群。

这种现象与其基本原理有关。了解这一原理不仅是获取知识，更重要的是，它直接关系到您如何与AI进行有效协作。明晰其原理后，您便会理解为何采用类似搜索引擎的自然语言提问方式，可能并非发挥AI最大性能的最佳途径。

AI的本质，许多人称其拥有思考能力、数学能力等，这些说法并不完全准确。其核心机制非常简单：**预测下一个最可能出现的字词**。正如之前节目中讨论过的例子：“这个小狗很可…”，AI可能会预测“爱”；“这个人真可…”，可能会预测“恶”；“午夜凶铃真可…”，则可能预测“怕”。这说明人类语言本身存在一定的规律性。当AI被训练去掌握这些语言规律时，这个过程与我们通常理解的“思考”并无直接关联。

所谓的“思考模型”是如何训练出来的呢？其训练方法大致如下：假设我们将一个办公室内的所有书籍都输入给AI。随机选取一本书，如《宗教改革史》，再从中随机选取第四页某句话的前半部分，让AI尝试补全下一个字，并检验其补全的内容是否与原文一致。AI便是通过这种方式训练出来的。一个训练有素的模型，应能准确补完句子，与原文相符，这便算训练成功。当然，实际训练所用的文本量远超此例，至少是人类目前可获取的所有资料，包括将视频内容转换为文字后输入。基础模型（Base
Model）的训练就是如此。因此，要判断这个模型是否具备思考能力，取决于如何定义“思考”。但总体而言，它绝非人类意义上的思考能力。该模型的基本能力可以理解为：人类语言遵循一定的函数分布规律，通过按此顺序排列语言，模型能够输出和生成具有相似函数分布的语言。这便是AI的基本运作方式。

从这个角度出发，就能理解为什么单纯使用自然语言提问，可能不是最大化AI性能的最佳方法。

## AI的“倾向性”与可操控性

既然我们明白了AI的运作方式，那么当我们希望使用大型语言模型AI来获取某些文本时，其结果就取决于我们提供给它的内容。这些内容可以分为两部分：第一，您的具体要求是什么；第二，您是否为其提供了真正符合您要求的材料。以写文章为例，假设您阅读了一份世界银行的报告，认为中国经济存在风险，并且希望AI生成的文章能与该报告的观点相关。一个有效的方法就是直接将报告内容粘贴给AI。以这份报告作为切入点，效果会非常好。也就是说，除了您简短的指令外，您还为AI提供了一个优质的语言分布和函数分布范例，引导它生成类似的函数分布内容。

向AI提供参考材料（如报告）至关重要。因为无论打字速度多快，人脑思考的速度也难以跟上，因此用户能够输入的提示词（prompting）内容是非常有限的。我们之前提到，用户可能只输入一句话，而AI通过“思路链”可能会生成数百万字或数百万个Token（词元）的中间过程，最终才输出结果。这里就涉及到精确掌控的问题。如果用户输入的仅是20个字或20个Token，而AI内部处理了百万Token，最终生成2000个Token的文本，那么初始输入的20个Token对最终结果的影响力（dependency）相对较小。相反，如果用户提供的是2000个Token的详细输入，AI同样处理百万Token并输出2000个Token，那么最终结果与初始输入的依赖性就会显著增强。例如，只输入“我要一篇关于中国经济的文章”这几个字，最终输出与这几个字的依赖性就很低。由于AI的“思路链”中间过程内容极长，Token量巨大，因此初始输入的重要性不言而喻。过于简略的输入会导致其与最终输出的依赖性相对较低。

增强这种依赖性主要有两种方式：其一是提供相关材料，如果您认为某份材料内容优质且希望输出与其相关，就将其粘贴给AI；其二则是我们接下来要讨论的，如何清晰、准确地描述您的具体需求。

## 如何高效使用AI：拆分任务与迭代优化

现在我们来探讨如何更有效地使用AI。如前所述，使用AI的门槛已不再是提示词工程的能力，而完全在于您的想象力——即您能想到AI可以如何运用。如果仅仅将AI当作搜索引擎，用它来查询“某事是什么样”、“某事为何如此”，那么您的想象力就未能充分发挥。

### 任务拆分的重要性

举一个简单的例子来说明想象力的作用。假设我要求AI写一篇文章。最直观的方式是告诉它：“我要写一篇关于中国财政的文章，结论是中国经济将在明年内崩溃，请写一篇文章。”AI能够完成这个任务吗？能，但效果好吗？通常不好。效果不佳并非因为要求的问题过于复杂，而是因为您没有提供足够的内容支撑。当然，现在的AI已经可以通过“思路链”自行搜索大量信息并生成一篇看起来不错的文章。但关键在于，我们应如何理解AI的工作过程，以便更好地与其协作，这一点至关重要。

我们知道，AI的运作基于“思路链”，它已经具备了一定的“思考”过程，或者说，它会生成一连串的内部提示词，并将前一节的输出作为后一节的输入。这个内部提示词的数量是极其庞大的。如今的AI通常不会将这些内部提示词完全展示出来，因为这可能涉及模型蒸馏和知识产权问题，它们只会快速闪过。如果这些内部提示词真的被展示出来，其数量将是巨大的。

因此，要让AI更好地满足您的要求，一个有效的方法是对其“思路链”进行部分切分。这相当于让AI先用大量内部提示词生成一个中间产物，再结合这个中间产物和新的提示词生成最终您想要的成果。以写文章为例，先让AI生成提纲，再基于提纲和其他信息生成全文，其效果远好于直接让AI生成全文。为什么直接生成全文效果不佳？使用AI如同烹饪，一次尝试可能味道过咸，下次就需要减少盐量；只不过AI“烹饪”速度快，几分钟就能出结果。AI很难一次性生成完全符合您期望的结果，通常需要反复修改提示词。因此，**拥有良好的修改提示词能力**，成为了使用AI的一项核心技能。这种修改并非早期那种魔法咒语式的技巧，而是指您能否理解修改哪个词汇会对生成结果产生何种影响。如果您只是给出一个笼统的指令，最终生成的文章不合心意，那么修改起来会非常困难。因此，如何有效地控制提示词、中间结果以及中间结果与最终结果之间的关系，成为一个至关重要的问题。

以写文章为例，我们常常需要控制文章的结构。那么，最好先让AI生成提纲，再利用提纲来生成正文。这样，如果文章中某一段落不符合要求，您可以直接在提纲层面进行修改。但如果您只是笼统地说“我要写一篇文章”，而其中某段不想要，就很难精确调整。这便是AI工作流程中的一个关键环节。我举的例子与人类写提纲的工作流程相似，但AI的应用中会出现大量与传统工作流程不同的情况，关键在于您如何引导AI通过“思路链”一步步产生结果。将一个直接的任务分解为多个步骤，使您有能力在中间环节进行质量管理，当生成结果不满意时，知道如何调整相应的指令，这是使用AI最核心的技能。目前，使用AI的最大门槛和人与人之间使用效果的最大差异，就在于是否懂得如何调试AI的输出结果。如果您掌握了调试技巧，就能迅速让AI生成符合要求的内容；反之则效果不佳。

### 调试AI输出：清晰描述需求

关于调试AI输出，这是一个非常有趣的话题。早期AI需要复杂的提示词工程，调试方法如同念咒。现在则不然，调试方法更像是您指挥下属工作（当然，您未必有下属），或者像上司指示您：“这个不行，要如何改进。”这并非玩笑话，很多类似上司含糊指令的调试方式效果不佳，例如“要高端大气上档次”、“更专业一点”。如果您给出这类模糊的要求，AI也无法理解您的真实意图，如同要求“五彩斑斓的黑”一样。

这意味着，AI正在检验我们的一种能力：即使您不亲自产出结果，但您是否懂得如何清晰描述您想要的结果，这已成为一项非常重要的能力。例如，您说“这个太专业了”，这种反馈毫无用处。您必须明确自己想要的是什么。这是一个颇具哲学意味的问题：**您是否知道自己想要什么？**无论如何，使用AI的过程就是在拷问您这一点。当然，您最初可能不清楚具体标准，这个问题也可以在过程中询问AI。但总而言之，要引导AI输出最终结果，关键在于您提供了什么给AI。

### 提供优质输入：材料与明确要求

我们提供给AI的内容可以分为两部分：第一，您的具体要求是什么；第二，您是否提供了真正符合您要求的材料。再次以写文章为例，假设您阅读了一份世界银行关于中国经济风险的报告，觉得非常好，并希望AI生成的文章能体现该报告的观点。最直接的方法就是将报告文件粘贴给AI。以这份报告作为切入点，效果会非常好。也就是说，除了您的指令外，您还为AI提供了一个优质的语言分布范例，引导它产生类似的语言模式。

向AI粘贴参考材料至关重要。因为即使打字速度再快，人脑思考的速度也难以跟上，因此用户能够输入的提示词内容是非常有限的。我们之前提到，用户可能只输入一句话，而AI通过“思路链”可能会生成数百万词元（Token）的中间过程，最终才输出结果。这里就涉及到精确掌控的问题。如果用户输入的仅是20个词元，而AI内部处理了百万词元，最终生成2000词元的文本，那么初始输入的20个词元对最终结果的影响力（依赖性）相对较小。相反，如果用户提供的是2000个词元的详细输入，AI同样处理百万词元并输出2000词元，那么最终结果与初始输入的依赖性就会显著增强。例如，只输入“我要一篇中国经济的文章”，最终输出与这几个字的依赖性就很低。由于AI的“思路链”中间过程内容极长，词元量巨大，因此初始输入的重要性不言而喻。过于简略的输入会导致其与最终输出的依赖性相对较低。

增强这种依赖性主要有两种方式：其一是提供相关材料，如果您认为某份材料内容优质且希望输出与其相关，就将其粘贴给AI；其二则是清晰、准确地描述您的具体需求。

### 利用AI的结构化偏好

以NotebookLM为例，这是一款可以将书籍内容生成摘要（包括语音摘要）的对话式AI产品，非常出色。然而，它同样有一个提示词输入框。如果您能在其中给出明确要求，它生成的摘要质量会更高。我发现，与其要求它生成特定时长（例如20分钟以上，它可能依然只生成6分钟），不如要求它输出的内容具有特定结构，例如“1、2、3、4、5”这样的列表式结构。长期使用后您会发现，AI对结构化信息非常敏感。当前的大型语言模型及其调试方法，都对结构化输出表现出高度的敏感性。因此，无论是撰写文章还是生成任何类型的内容，如果您具备将需求结构化的能力，其输出结果通常会远胜于平铺直叙或描述性的指令。这种结构化的能力并非单一方向，而是多维度的。

如果您使用过OpenAI的某些高级研究工具（例如，提及的DeepResearch，可能是指类似Perplexity
AI或具备深度搜索能力的GPT功能），会发现它们在交互时，有时会反问用户几个问题。其中一个常见的问题可能是关于输出格式的，例如：“您需要的是论文形式、新闻报告形式，还是表格形式？”这表明AI在微调（fine-tune）阶段，已经针对输出内容的结构化进行了优化。由此可见，在向AI提出要求时，既有用户自身的需求，也有AI本身的“偏好”，例如对结构化输出的偏好。您需要向AI提出诸多要求，而这些要求，如果AI使用经验不足，可能自己也无法明确。这种情况下，最好直接询问AI。

### 让AI辅助生成提示词

现在使用AI，我有一个特别有用的技巧：**不要自己费力编写复杂的提示词，而是将您的基本需求以简单的方式告知AI（例如ChatGPT），让它为您生成更优化的提示词。**举例来说，如果您想写一篇关于中国财政脆弱性的分析文章，并希望AI先生成文章提纲。您可以问ChatGPT：“如果我要让您（另一个AI实例或同一AI）生成一篇关于中国财政脆弱性分析的文章提纲，我应该使用什么样的提示词？”AI可能会给出一个非常详尽的提示词建议，例如：“请研究某年到某年的数据，考虑以下几个方面，搜索这些内容……”等等，内容可能非常长。将这一长串由AI生成的提示词再输入给AI（例如ChatGPT本身或其他模型）来生成提纲，其效果绝对比您自己编写的简短提示词要好得多。这并非智商问题，而是因为AI生成的提示词本身可能长达千字，包含了许多细节和引导，这是个人难以在短时间内构思和输入的。命令的准确性和详尽程度，对于需要最终结果与初始意图高度相关的任务尤为重要。

此外，这上千字的提示词本身也是一个重要的质量检查点。您最好仔细阅读AI生成的提示词，确认它是否准确反映了您的真实需求。这个过程相对容易修改，例如，如果您发现其中几句话不符合您的意图，可以直接修改这部分提示词，从而使后续生成的提纲更符合您的期望。

这又回到了AI的工作流程问题。我所举的例子（写提纲）与人类的传统工作流程相似。但在实际应用中，会出现大量与人类日常工作流程不同的情况。关键在于您如何引导AI通过“思路链”逐步产生结果，如何将一个直接的任务分解为多个步骤，从而使您有能力在中间环节进行质量管理，并在生成结果不满意时，知道如何调整相应的指令。这正是当前使用AI最核心的技能，也是不同用户之间使用效果差异的主要原因。如果您掌握了调试AI结果的技巧，就能迅速让AI生成符合要求的内容；反之则效果不佳。

调试AI输出的过程，就像向上司或下属明确指令一样。模糊的指令如“高端大气上档次”或“更专业一点”，AI是无法理解的，如同要求“五彩斑斓的黑”。AI的使用，实际上是在检验我们描述需求的能力。您不一定需要亲自产出结果，但必须懂得如何清晰地描述您想要的结果。这是一个核心能力。您必须明确自己想要什么，这是一个标准。当然，如果您不确定，也可以在过程中向AI咨询。总而言之，引导AI输出最终结果，取决于您为AI提供了什么，这包括您的明确要求和相关的优质材料。
