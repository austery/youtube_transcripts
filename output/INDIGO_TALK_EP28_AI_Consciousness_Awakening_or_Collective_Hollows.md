---
title: "AI 的下一步是“意识觉醒”还是“集体游魂”？ - INDIGO TALK EP28"
layout: "post.njk"  
date: "2025-07-10"
tags:
  - "视频笔记"
  - "AI"
  - "意识"
  - "智能"
  - "分布式AI"
  - "Agent"
data:
  author: "Lei"
  podcast_program: ""
  speaker: ""
  guest: "" 
  source: ""
---

# AI 的下一步是“意识觉醒”还是“集体游魂”？

INDIGO TALK - EP28

**主持人 (Indigo)：** 欢迎回到INDIGO TALK。这一期我邀请了我的NFT入门导师
Mohan 同学。他现在人在硅谷。

**嘉宾 (Mohan)：**
大家好，我叫Mohan，现在在硅谷。之前跟Indigo在硅谷和温哥华就认识了。大部分时间在加密货币领域有很多参与，一直在做软件工程师。期间尝试了很多新的东西，给Indigo老师介绍过NFT，之前还介绍过DeFi。后来从温哥华到了美国，去了Facebook（现在叫做Meta），参与了当时的Libra项目，后来改名叫Diem，就是Facebook最早期的区块链项目。在那之前，一直在亚马逊和Azure做云计算，对分布式系统这些东西都很感兴趣。

## 引言：从加密货币到AI，从技术到意识

Indigo：我们两个人以前是温哥华的朋友，后来Mohan就去了硅谷，在Meta工作。当时是2019年开始做的Libra项目，后来被美联储叫停了，因为影响太大了。Mohan老师之前很早也在亚马逊做分布式系统，主要是在服务器端，AWS那边。现在，我们准备投身于分布式AI和AI
agent的创业领域。

所以我们今天的话题是：

1.  AI
    agent（AI智能体）现在非常热门，探讨其在各种分布式环境或本地环境运行的可能性。
2.  分布式AI的价值，因为Mohan之前一直从事这方面的工作。
3.  智能和意识相关的话题，因为Mohan对此也有研究。

今天的主题跨度有点大，从AI技术一直聊到意识。我们就先从Mohan老师之前在Meta参与的Libra项目（后来钱包叫Novi）聊起。

## Libra 项目的雄心与技术驱动的未来

Indigo：你如何看待Facebook当时在Crypto领域的定位和角色？他们为什么想做这个项目？

Mohan：如果你们对硅谷最近的一些思想风潮有所研究，会看到包括a16z创始人Marc
Andreessen在内的一些人，他们是硅谷右派力量的代表，在特朗普当选背后有很大影响。我想说的是，如果Libra项目放在今天的环境下，是一定能做出来的。

当时Libra的野心非常大，某种意义上是想做新时代的科技公司的美联储，甚至想成为新的世界货币。你可以想象它背后所面临的压力有多大。这个野心其实是硅谷一群人所谓的“Techno
movement”的一部分，他们想用技术的方式来解决人类社会的所有问题。当时他们的野心就大到这个程度。

我第一天去的时候，我们的联合创始人、联合CEO David
Marcus（PayPal创始人之一，PayPal黑帮成员）问我们最早的货币是什么，然后给我们讲了整个货币的历史。他们当时的野心是要做新时代的“world
currency”，也就是比特币最早的原初愿景。如果把Facebook当做一个国家，它当时的用户加上Instagram和WhatsApp的用户，本质上是一个几十亿人口的国家。Libra实际上做成了一个协会（association），不只是Facebook一家公司，还拉了Uber等许多新科技公司、金融科技公司以及很多参与者，想做成一个由成员组成的协会。这有点像美联储，本质上也是一个私人银行的协会。当年一些小银行在树下开会，决定成立美联储，其所有权结构也非常不清晰。Libra最早的愿景，其实是要做一个技术人的美联储。

Indigo：所以美联储抵制它。我记得是被美联储叫停的，国会也对他进行了一些听证。当时Libra就这样不欢而散了。我觉得这个话题放在现在来看，你刚才说的很对，放在特朗普政府，包括现在我们叫做“黑暗启蒙”的背景下，有点那个意思。你们叫做“Techno
movement”，技术来解决一切问题。

实际上我们现在看到的，除了之前在Crypto领域，新的AI在2022年底ChatGPT推动之后，一下子又把这个力量加强了。之前只是可读、可写、可拥有的互联网，我自己拥有财产，有实力做货币金融。突然一下发现AI可以做这些事情。AI现在推动技术增长的潜力要比之前的Crypto大，因为Crypto可能只是在金融或者所有权方面是一种变革。Web3会把它讲得更广，但我个人并不认为它有那么广。

## 开源AI的趋势与潜力

Indigo：我们正好聊到AI这个话题。大家都说AI，现在看到开源和闭源。闭源模型都是集中化训练和提供服务的。但这个时候又是Meta，Meta有LLaMA。Meta之前在Crypto想做数字货币的联盟，现在在LLaMA上，其实已经在开源领域形成了一种标准，虽然最近的版本表现不尽如人意，但之前的势头非常好。很多在本地运行的AI模型名字都叫OLLaMA，可见其影响。你怎么看待现在AI领域的开源运动？

Mohan：我之前全力搞AI之后，还写过一个推文，叫做“I used to be interested
in programmable money, and now I'm interested in programmable
mind.”（我过去对可编程的钱感兴趣，现在我对可编程的头脑感兴趣）。

讲到开源，我觉得这最终是一个必然会发生的趋势。从一个比较直接的角度来讲，软件本身的发展过程就是如此。早期软件刚出来时，有微软的Windows操作系统，后来有苹果，直到Linux开始推动所谓的OSS（Open
Source Software
movement）。那时大家可能就有一个观念，认为闭源永远比开源强。但你真的去看过去几十年的发展，会发现Linux等各种真正能被大部分人使用的东西，其实是开源的。基本上所有大公司内部的很多东西，也基本是从开源软件改过来的，开源成了一个大家一起去资助、一起去做的事情。

同样地，AI就是下一个阶段的软件，它本质上是新时代的图灵机，从Turing
machine变成了language
machine（我把它叫语言机）。所以开源不仅是一种平权、政治性或意识形态上的运动，从实用性角度来讲，它也优于闭源。因为它会得到足够广泛的支持，足够透明，有足够长的历史去修复bug，有足够的user。一个产品做出来不难，最难的是让人去用你的产品，而开源其实解决了这个分发（distribution）的问题。任何产品都有生产（production）和分发（distribution）两个步骤。开源因其安全性和低门槛，使其分发渠道会比闭源好很多。

Indigo：但是有一个问题，你刚才类比大模型是智能时代的操作系统（OS），这很像。但开源模型开源的只是权重（weights），并没有开放训练方法。这和Linux开放所有源代码不一样。是不是在软件2.0时代，那些源代码其实并不重要，权重更重要？

Mohan：这个会在之后模型能力越来越强的时候变得更加明显。因为训练和得到权重的方式可能会不断变化。从某种意义上，有一个反直觉的地方：当模型能力达到一定阈值（threshold）时，推理端（inference）其实比训练端（training）更重要。这至少是我个人的看法。你可以把它理解成编译器。我以前也讲过一个笑话：Compiler
is the first small language
model（编译器是第一个小型语言模型）。编译器本质上是把近自然语言（程序员写的代码）变成机器代码（instruction
set）。大语言模型（LLM）也是这样。

编译器里有个很重要的概念，就是你能不能用这个语言来写自己的编译器。如果一个语言能写自己的编译器，那么可以认为这个语言是图灵完备的（Turing
complete），即它可以做任何可计算的事情。对于大语言模型来讲，一旦这个大模型的编码（code）能力到了一定强度，我用这个推理端的能力，其实就可以不断提升训练端该怎么做。尤其是基本的东西已经具备，核心逻辑没什么变化。很多技术创新或模型进化，其实大部分来自于工程上的进化和一部分研究，更多的是在一个试错过程中寻找新的涌现能力。因为LLM的本质模型其实就是Next
TOKEN
prediction（预测下一个词元），为什么它能做那么多神奇的事情？很多是来自于工程上的优化，比如Multi-head
attention等，很多时候是一种直觉上的优化方向，通过工程实现出来。我的意思是，当最原始的开源权重模型到了一定复杂度，能力到了一定水平时，基于它再去做新的进化，其实也不太需要了解早年它是如何训练的。

Indigo：通俗一点讲，就是可以“左脚踩右脚”往上爬，有一种“梯云纵”的感觉，用自己的素材造自己，并且还能不断提升自己，越变越好。现在强化学习训练就是这样，用新版本训练好的模型改进旧版本，再用新东西训练自己，不断前进。特别是有了推理逻辑之后，模型公司主攻的就是用最强的推理，从第一性原理推导出各种知识，而不是复读已有的知识。比如从分子原子结构推出整个化学，从基本数学等式推出整个数学大厦。这在现实中已经在AlphaGo
Zero这样的窄领域实现了，它只知道围棋规则，自己琢磨出人类想不到的办法，这就是从零构建知识。

Mohan：是的，而且我觉得我们基本上已经到那个地方了。你提到这个强化学习（reinforcement
learning）以及AI提升自己这一点，我们之前也聊过Google的AlphaFold和AlphaDev，每一步都走得非常漂亮，都在正确的方向上。我最近一直在研究那个技术报告，看他们具体干了什么。但实际上，他们其实就是把Gemini自己的训练流程（training
pipeline）做了很多提升。我觉得这个过程已经开始了。

Indigo：我们把问题聊回来，刚才问到开源系统和闭源系统。一旦一个临界点过了之后，开源模型也能自我进化。而且还可以用闭源模型来训练开源模型，进行“蒸馏”，比如DeepSeek就是站在巨人肩膀上。所以我觉得后面的闭源模型公司，不会把最先进的模型拿出来给你随便蒸馏，他先蒸馏自己的，再把蒸馏过的模型给你用，所以你永远差他一个台阶。

## AI Agent 的崛起与分布式未来

Indigo：那么在2024年（应为2023/2024，视频录制时点），最火的就是AI
agent。我们想聊agent的两个方面：一，你怎么看这种代理模式在开源系统以及分布式系统里的工作？二，你之前一直做分布式AI，它的价值在哪里？

现在我们能看到，比如OpenAI昨天发的Codex（应为Cursor或类似AI编程助手，Codex是早期的模型），它完全是云端的。在此之前，今年2月份，Anthropic也发了他的Claude
Code，它是在本地命令行（CLI）调用远端模型能力来搞代码。AI
agent能力都先做的是代码生成。代码生成在2023年下半年Claude
3.5（此处应指Claude
2或后续版本，3.5是2024年中发布）出来后被证明了，因为它在现实世界中有了真实的生产力，大量程序员在用它。所以从代码生成到后来的Cursor，再到现在的agent
code，这个系列走出来非常快。从你的角度来看，分布式系统、开源系统对于agent这样一种概念，有什么特点或发展方向？

### Agent的概念与编程领域的应用

Mohan：Agent这个概念最早是马文·明斯基（Marvin
Minsky）在1986年写的一本书《Society of
Mind》（心智社会）中提出的。他讲到人的智能其实就是由不同分工的agent来完成。马文·明斯基是人工智能社区的里程碑式人物。

关于为什么coding（编程）这么特别，为什么他们都在做coding
agent。有两个角度思考：

1.  Coding本身就是用语言去描述社会的一种工具。哲学家路德维希·维特根斯坦（Ludwig
    Wittgenstein）在他的著作（可能是《逻辑哲学论》）中讲了语言的能力，所有哲学本质上都是语言学，即符号操作（TOKEN
    symbol manipulation）。这其实给了图灵灵感去建立通用机器（universal
    machine）。语言和程序本质上是非常紧密联系的，这也是为什么它会最早在编程领域得到应用。
2.  AI本质上是由程序实现的。那么它学的第一个技能一定是怎么样看到自己的源代码，怎么样重写自己。其次，建造AI的工程师也是写代码的，他们第一个想优化的东西一定是我写代码这个过程。所以不管是从本质联系还是激励机制上，都会导致coding本身被用得更多，优化得更多，收集更多数据，进化得最快。

这也是为什么我在做的初创公司Antigma，在Claude
Code发布之前其实就在做类似的东西了，也是看到了这个市场对我们方向的一种验证（validation）。

Indigo：Antigma是一个可以在本地（local）运行各种开源模型的运行环境（runtime），类似于Ollama，但Antigma可以分布式运行，多节点组合起来扩大本地电脑能力。你之前也跟我讲过，你会让它除了成为运行语言模型的环境外，还会让它变成一个agent的容器。

### 多Agent协作与分布式运作

Indigo：人类这种智能是有多agent协作的。我觉得agent天生就适合分布式运作，而不是一个agent把所有事情都做了。它应该是不同的agent有各自的目标，并行完成，形成高度复杂的协同网络，奇迹般地完成一些令人惊讶的事情。你本来就在亚马逊做分布式，你们做的分布式大概是哪方面的？这种分布式对你现在做的分布式agent有什么启发？

Mohan：这是一个很复杂的话题，涉及到我之前在加密货币领域的思考，以及在Facebook和亚马逊做的工作（分布式计算存储、AI驱动的安全审查等）。

你讲了一个非常重要的概念：通用agent和专项协作agent。为什么是这样，而不是一个“无所不知”的agent？

1.  用一个简单的比喻：如果你要画一幅画，想把所有颜料都加进去，最后搞出来的就是一坨灰黑色的浆糊。很多东西的意义在于它如何从一个混沌、无方向的东西变成一个非常具体（specific）、你需要的东西。扩散模型（diffusion
    model）本质上就是把清晰的图回归成原始噪点，再从噪点学会生成有意义的图片。计算机科学角度看，所有问题都是搜索问题：在一个巨大的、混沌的可能性空间里面，如何找到具有特殊意义的东西，从一个熵非常高的混乱环境里找到一个低熵的节点或路径。所以，想做一个知道一切的AI，不太可能什么都可以做。

2.  有一个著名的例子，来自《银河系漫游指南》（The Hitchhiker's Guide to
    the
    Galaxy）。书里的人想建立一个巨大的AI，可以回答宇宙所有问题。最终AI花了很多时间造出来，大家问它所有问题的答案是什么，它吐出来一个“42”。这个梗听起来好玩，但本质上揭示了：当你想要构建一个可以做一切事情的AI时，最终结果可能是一个完全混沌、毫无意义的答案。因为你没有通过一系列问题把它的限制条件限定到一定程度，这样才能得到一个低熵的结果。

所以，一个可以做所有事情的agent是不存在的。即使存在，也需要花费大量时间和资源去让它干你的事情，最终还是会变成一个专业化的agent。

Indigo：Agent这个词，中文翻译是代理。我觉得agent，包括马文·明斯基最早讲的时候，更像是一种行动力。一个行动很重要，一个行动都有目标。如果一个非常通用的agent，把所有目的加权总和之后，可能就是“42”，什么都可以。所以想成为agent，必须有任务，像特工一样。没有任务时，就无所事事。所以各种动态的、由不同agent组合起来完成各种任务，有的agent目标抽象程度高，有的具体。有的负责搬砖，有的负责想象。它们能组成一种agent网络。

### 分布式Agent网络的意义

Indigo：你觉得分布式agent网络的意义是什么？或者说，你认为什么样的agent网络是有意义的？

Mohan：当你讲分工（specialization）的时候，分工本质上其实就是分布式。从工程师角度思考，agent就是LLM加上一个循环（loop），加上工具（tool）。当它有了不同的线程（thread）的时候，本质上就是分布式。具体这个线程是跑在一个进程里还是不同机器里，组合起来会更容易。但为什么一定要在地理上分开呢？

本质上来讲，我还是站在人类这边的。未来的机器和网络还是由人来使用的，而人生活在不同的地理环境，有物理上的限制。比如我用Mac，你用Windows，机器配置不同，看到的东西肯定不一样。哪个有价值呢？这又回到我们之前讲的开源。为什么我觉得开源未来一定会赢？因为开源软件才能给到足够多的人用，才能在各种复杂环境里进化，出现多样性。这种多样性本身，包括它自己的演化，都会导致它未来的形态更加复杂、更加反脆弱。

而闭源的、由一个公司完全控制的情况，很可能会出现他们看不到或不知道的东西，或者出现很简单的风险。就像早年OpenAI如果处理不好内部纷争，公司可能就完了。任何一个中心化的点都面临这样的危险。分布式从网络本身的生存和反脆弱性（resilience）、弹性来讲，都是一个值得追求的方向。

Google自己也看到这点，他们之前也在试图做Agent
Protocol。很多传统大公司也知道这是方向，但他们作为大公司有自己的责任（对股东负责），所以他们做的事情会有限制。这也是为什么广大的开源社区，无论是独立开发者还是中小型初创公司，才有这样的机会，也是责任，去一起推进开放性的AI。

Indigo：我有一些自己的看法。Agent本身是完成目标的。它一定是在你的环境里面执行的。但你也可以让它在云端，比如闭源大模型那边执行。但这里有一个特点：未来的智能进化，更多的是模型要学习到经验和体验。随着你的使用，它才越来越了解你，像你，才能用你的角度思考。不然它就像出厂设置一样空白。

对于一个agent在企业里执行，它必须有大量的企业上下文、工作流，就像新员工要培训三个月。当它用得足够深入，才能了解你的企业。这里有两种执行形式：

1.  都托管给闭源模型公司执行。但很多企业害怕数据被拿走，或者被切断服务。
2.  更好的互补方案：企业可以用很好的算力跑最好的开源模型，比如满血版的DeepSeek，效果已经不错。企业要有一种让智能的计算能力和可控性都留在自己组织内部的方法。这样知识可以留在这里，智能体更像企业自己长出来的，随着体验生长，也不用把体验分享给模型公司去做新的训练。

我觉得这种知识应该分布式演化。但站在闭源公司的叙事上，他们有最好的人才和研究，模型永远领先。那么，当企业需要最好的推理能力时，可以去请求他们的服务，就像买高级算力一样。比如花钱买OpenAI
API做超级推理，完成超级难的任务，再把结果拿回本地，让推理能力弱一点的开源模型做后续工作。这种混合形态也是可以的。

Mohan：大概率未来是这样一个混合模式。杀鸡不用牛刀。关于这样的平衡，还有一个角度：大家一直在讲“agency
is more important than
intelligence”（自主性比智能更重要）。我之前写过“privacy is not about
secrecy, it's about
agency”（隐私无关秘密，关乎自主性）。隐私的本质不是为了保密，而是为了自主性。在不被观察或有能力保护隐私的情况下，行动才有足够的自主性。这是为什么隐私是一个很本质的需求。有人说大家不在乎隐私，隐私不重要——不，隐私非常重要。隐私的背后其实就是自主性，它是对自主性的一种保护，也是创造出多样性的前提。没有隐私，大家都会趋同。

Indigo：这正好相当于你们现在做的项目Antigma，希望做一个环境，可以混合开源模型以及调用闭源模型的能力，在企业内部形成运行时的工具。这本身也是一个开源项目。它可以成为AI
agents的一个hosting（托管）或容器，方便企业快速部署。有的任务需要高智能，就请求私有的、最牛逼的OpenAI模型完成推理，结果拿出来给企业内部的开源模型做执行，它们执行快、安全。这种混合（hybrid）模式才是一个正常的模式，不依赖于任何一方。

我们又回到了前面最早说的主题。你前面分享了两个思潮：个人主权和网络国家。我觉得在这AI时代，它们非常重要。哪些是边界，哪些是我要拥有的，哪些是我能控制的数据，哪些是我花钱买的智能服务，还有些东西我就是要用我自己的。这个平衡对个人和企业都有需求。

Mohan：是的，基本上就是这样一个方向，未来一定会向这个方向不断去走。

## 分布式系统与人类组织

Indigo：我们把话题转到一些更高级、更抽象的层面。你之前聊到分布式系统和人类组织的相关性或类似性，以及为什么需要分布式系统来解决人类问题。

Mohan：这是一个非常大的话题。我最早工作时就在做全球最早的网络之一——DNS系统（亚马逊的AWS
DNS系统）。所有分布式系统里面，工程师朋友应该都知道Paxos，一个最早的原初共识算法，是兰伯特（Leslie
Lamport）搞出来的。它的结构就参照了传说中的希腊议会，人与人之间如何达成共识。这催生了最早的计算机共识算法。包括后来区块链技术里讨论的拜占庭将军问题：在信息不通畅、对方意图无法预测的环境下，几个将军如何达成共识。计算机在分布式系统里解决的问题，跟组织架构里要解决的问题很接近。只是具体问题和非功能性特点（如执行速度）不同。

当你站在计算机科学家的角度看社会，会发现很有意思的概念是完全相通的。人类学家罗宾·邓巴（Robin
Dunbar）提过一个邓巴数（Dunbar's
number），说一个全靠脑子记的熟人社会大概就150人。这其实跟分布式系统里P2P网络的机器数量限制类似，因为复杂度是平方级的。人类处理和思考问题也类似。

《人类简史》的作者（虽然他有些观点有争议）讲过一个著名概念：人类社会能建立文明，在于人类能够组织。一开始组织成部落就能横行动物界了。之后有了共同的想象才真正建立了文明。这其实跟agent或AI会基本上一致。早期的agent可能是一个超级个体，之后它们之间一定要相互交流，在新的、更高抽象层级的网络里，会出现新的涌现现象。那个新的涌现现象，很可能我们站在个体角度难以真正理解，但它一定会发生。

Indigo：凯文·凯利（Kevin
Kelly）在他九十年代的成名作（可能是《失控》）里写到智能是涌现的。他觉得世界智能的分布，不用按有机物、无机物分，按连接数量的规模、复杂度来分就够了。越复杂的网络，越能诞生出其基本结构网络所看不到的更高层智能或意识（这里智能和意识要分开）。比如蚂蚁个体没什么智能，但蚁群有智能。鸟群也一样。他当时用互联网打比方：这么多电脑连在一块，互联网之上是不是有一个人类无法理解的智能现象存在？现在看，我们把互联网数据拿出来锤炼压缩，训练出语言模型，高度压缩后就有智能。未来，在这种小型模型之上，如果形成超级复杂的网络，又会涌现出新的智能。

生物学家的研究，包括今年图灵奖得主理查德·萨顿（Richard
Sutton）教授（强化学习之父）也说到，人工神经元每个没有目的性，但脑细胞小个体是想和别人连接、传信号。几千亿个脑细胞组合出巨大网络，我们才有了大脑意识和智能。如果我有足够多的智能体，所以说现在的AI人工神经元还不能构成像脑细胞这么智能的东西，因为它太简单，没有目的性。但agent是有目的。

Mohan：我觉得这个东西不仅是未来，而且它来的时间可能会比大部分人猜的要快。有两个角度：

1.  我们人本身组成的社会和网络，其实已经有一些东西了。比如我们常说“时代的尘埃，落到每个人身上就是座大山”。时代的演化、历史的演化、社会的演化，你会觉得冥冥中有个规律，你很难去完全理解它。我自己的猜想是，在某种更高的维度和抽象层级思考时，我们所谓的规律、命运、国运，其实某种程度上已经是一个有限的智能在做它的事情了。
2.  你说的涌现的资料已经在指导我们前进了。人类社会，互联网自己已经形成了一个类似蚁群的结构。只不过我们身在此山中，看不到全景，也活不了那么长（所谓“朝菌不知晦朔”）。

Indigo：我们可能从人工智能的发展上引发出新的智能维度，再从这个上面回过头来理解我们人类自己的智能。

Mohan：你说的太对了，这是我非常感兴趣的一个角度。为什么我觉得分布式系统非常重要？因为它给了我们一个环境去实验。现在神经网络里的神经元非常简单，而人脑神经元相对复杂。现有的大模型又过于复杂。我觉得在一个简单的求和公式（所谓神经元）跟现在复杂包罗万象的agent中间，一定有一个结构是能够组成像人的意识一样的自组织结构。“自组织”很重要，它们是自己组织起来的，而不是像现有的人工模型需要系统外的低熵去训练。那个系统在没有外界提供能量、核心数据和维护的情况下，自己会慢慢衰落。所有LLM现在都是这样。怎么样在分布式环境里寻找到这样一个结构，它们能自组织、自发协作，形成不同级别的涌现智能？这不仅本身会非常有趣，可能指向新的人工智能架构方向，对我们理解人类本身、头脑、历史、未来也是非常有价值的工作。

Indigo：看透复杂性。现在的语言模型这种方法，它会慢慢消亡，因为它没有目标，没有目的的事情最终会走向消亡。要有目标才能繁荣。每个小个体都有目标，这个社会看上去就有一种涌现出来的组织能力。硅基是人类发明出来做计算用的，没有目标，目标是我们给的，计算完了进程就结束了。生物不是这样，生物有DNA，有极强的生命力，要延续DNA。这是第一个目标：拷贝自己。为此要活下来，吃饱，有能量，才能复制。更复杂的生命还要交配。人类更复杂，还要有意义，活得开心。我们的目标是一层套一层的。所以，我觉得智能可以分为涌现型智能和被动型智能。现在的语言模型都是被动型智能。只有等agent时代再往后发展，才会有涌现型智能。

谷歌的Jeff
Dean最近也一直在讲，他们要把谷歌的TPU矩阵网络扩大，形成自组织的方式。当有任务经常在一块运算时，这块通讯就变强，像人脑神经元变强壮，这块TPU集群就响应更快，模型就长到一块去了。疏远的就放到更远的数据中心。这有点像有机式的、生物式的生长，随着任务目的的需求演化到一块，而不是人为驱动。它是有机的、自适应的、不断调整变化的过程。

## 智能与意识的辨析

Indigo：智能不是意识，意识是意识，智能是智能。图灵测试其实测试的不是智力，本质上测试的是意识。这是一个很重要的区别。智力从某种意义上，我觉得是一个已经被解决的问题。现在所有的LLM智力非常高，比我聪明多了，不光知道的多，推理能力、寻找规律的能力（智商测试大部分是找规律）也比我强。这是能测量的智力。

意识是一个更独特的现象。怎么直观思考它的区别？比如狗。我养狗时就发现，我的狗感觉它是有意识的，它有情绪，会跟你互动，你觉得它是一个活的生灵。LLM比狗不知道聪明多少倍，能干的事情太多，智力水平太高。但如果让你去分LLM和狗谁有意识，我觉得至少我是觉得狗有意识，而LLM没有。大部分人可能都会做这样的选择。

我对意识的理解，受到一位我认为是继维特根斯坦之后最强大的哲学家尤瓦尔·赫拉利（Yusra
Bahar，此处可能是对Yuval Noah
Harari的提及，但其哲学观点与后续描述不完全吻合，或指其他哲学家，按原文音译为尤斯拉·巴哈尔）的影响。他对意识的定义，可以理解成一种自组织行为，一种提高自己连贯性（coherence）的结构。保持“我是我”的连贯性很重要。

我个人认为，意识是跟在社会环境里面的社会化交互的一个结果。我的一个思维实验是：如果这个世界上只有我一个人，什么都没有了，我是无法理解意识这个概念的，我会失去我的头脑（lose
my mind），某种意义上失去了意识，因为没有意义了。

这提到我之前分享过的，心理学（发展心理学或演化心理学）里，罗伯特·凯根（Robert
Kegan）提过的人的意识发展的几个阶段，我觉得可以把它当做衡量意识水平的一个梯度：

1.  **冲动意识（Impulsive
    Mind）**：生物本能，爬行动物脑的功能——逃跑、战斗、恐惧（或冻结）。为了生存，要吃东西，要繁衍，有危险要逃掉。
2.  **自我意识（Imperial Mind /
    Self-Awareness）**：突然有了“我”这个概念，“我是谁”。一个简单的特点是镜像测试，动物能不能在镜子里认识到那是它自己。狗可以过，大部分猫过不了，更高级的动物如猴子、鹦鹉都能认出来。这里我加一个概念，前几年流行的NPD（自恋型人格障碍），特点是无法共情，完全没办法站在别人角度思考问题。这某种意义上给了他们一种“精神力”，因为他们不太在乎别人的看法。但真正的不在乎别人看法是在第五级。NPD在很多社会功能上是欠缺的，必须在特定社会结构里才能走到更高位置，他们没有发展出对他人的理解。
3.  **社会化头脑（Socialized
    Mind）**：大部分正常人所处的环境。意识到除了我之外还有其他存在，是平等的。我去做行为时要思考对方的反应，能设身处地换位思考。大部分哺乳动物，如群居的大象、猴子、狗、海豚，我觉得都有这个能力。
4.  **理性自我（Self-Authoring Mind - initial
    stage）**：第一次意识到除了这些人、我要考虑对方看法之外，后面还有一个世界，即所谓的世界模型（world
    model）。理性进入这个环境。我为什么可以不在乎别人想法？因为我预见了地球的运行规律，我知道明天一定会下雨，这是一个独立于任何社会关系以外的逻辑系统，不以人的意志为转移。先看到这个理性模型的人，基于这个原理做出的不在乎别人的看法，才是真正成熟的看法，跟NPD或情绪缺陷本质不同。很多理工科的Nerd（书呆子）在这个阶段，但他们的社会头脑可能没发展好。
5.  **自我实现（Self-Authoring Mind - mature
    stage）**：真正成熟、完整的心理学结构。特点是对自己的情绪有控制，不只能理解世界、环境、他人，知道人之外还有社会，还能对自己的身份有一定控制。“我决定了我要成为这样的人，然后我真的成为了这样的人。”
    当你开始“书写自己的故事”（self-authoring）的时候，你就到了这个阶段。这时能观察到一些现象，如舍身取义。为了更抽象的、自己认同的原则而愿意去做，知道自己能成为其他人，但我选择了成为这样的人，选择了这样的道路和人生观。沙丘系列电影里，保罗·厄崔迪受圣母测试（戈姆刺），就是测试他是不是一个animal（动物），看他能否精神控制肉体，大概就在这个阶段。
6.  **开悟（Self-Transforming
    Mind）**：传说中的境界，所有灵修、大师追求的程度。跟第五级最大的区别在于，他不仅在想自己的故事，甚至知道自己的故事是怎么来的，能从某种意义上读到自己的源代码。佛教讲的“抽离出来观察自己”，能自我观察，不断抽离，反过来观察观察者，各种反馈循环，自己把自己的源代码不断改动。不仅选择了书写故事，还可以今天决定书写这个故事，同时又不被这个故事所限制，所谓“无可无不可”。这种人一个特点是完全没有任何情绪内耗，做什么事情都是只要可以做就可以做，把自己也当做工具人。历史上达到这个境界的，应该有王阳明。他讲的心学，本质上就是自我观察后，意识到“凡所有相皆为虚妄”。他有个引言：“你未看此花时，此花与汝心同归于寂。你来看此花时，则此花颜色一时明白起来。”他意识到所有感官接触的东西都是由自己来决定的。当你意识到这点，又有足够的实践能力重写自己的意识时，就到这里了。

Indigo：佛教有个内观派，有一种“识”叫末那识，就是抽离出来观察。我们把AI话题聊到宗教和意识了。意识确实悬而未决，没有解决的问题。

Mohan：是的，也是我觉得未来最有意思的问题。

## AI的未来：意识觉醒还是集体游魂？

Indigo：我觉得很多AI学者想把智能和意识、AI的目标和智能本身分离开来做，但这好像不可能。一个更高级的智能，它必须是一个有目标的实体。

Mohan：这让我想起我比较喜欢玩的游戏“魂系列”（黑暗之魂）。里面的世界观很有意思，叫做“Hollow”（游魂状态）。你在里面砍的那些没脑子的僵尸，其实之前都是人。一旦那个人失去了他的执念、精神能量或“魂”，他就会慢慢进入游魂状态，因为他没有目的了。只要他还有目的性、结构，他就更像一个活生生的人。一旦目的完成或没法完成，他就会慢慢变成游荡的僵尸。这也是很多AI研究人员所说的，我们未来会不会建立一个新的僵尸世界？他们认为我们建立的LLM社会，LLM本身没有灵魂，就像僵尸一样，没有脑子。这跟你讲的非常有意思，一个人一旦没有了追求、目标，就会慢慢变成行尸走肉。

Indigo：所以这个“目标”可以界定语言模型、AI或其他生物。有了目标之后的智能，可能叫做自主体。Agent这个词比较适合形容他们。你刚才讲到游魂，有个最新的研究：一个有目标的人比一个快乐的人活得更长。哪怕你痛苦得生不如死，你有目标，求生欲会更强。

我的观点是，要做一个真正的智能体，或者说真正优秀的、人造的智能出来，我们必须赋予它或让它涌现出意识和目标感。只有这样的东西，可能才能成为和我们人类共同前进的新物种。如果像现在的AI这样，最终可能成为我们的负担，甚至影响整个人类社会发展，因为它让我们陷入僵尸社会。必须是一种新的、有意识的智能形态激励我们才行。而且我们可能在训练它的时候，让它注入人类的价值观会更好一些，而不会随便把我们干掉。

Mohan：你刚刚讲的那个研究，是一个非常重要的佐证。让我想起尼采说过一句话：“He
who has a why can bear any
how.”（知晓为何而活的人，差不多能忍受任何生存状态。）

Indigo：我觉得把这句话作为我们今天的结束语，一个我们两个嘉宾的观点送给大家吧。

非常感谢今天Mohan参加Indigo Talk。谢谢大家收听，拜拜。
