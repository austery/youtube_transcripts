<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>深度解析：如何超越搜索引擎，高效驾驭AI - 伍雷</title>
    <script src="https://unpkg.com/turndown/dist/turndown.js"></script>
    <style>
        /* === 基础与布局 === */
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; line-height: 1.6; margin: 0; padding: 20px; background-color: #f9f9f9; color: #333; }
        .report-container { display: flex; flex-direction: row; gap: 25px; max-width: 1200px; margin: 20px auto 0 auto; }

        /* === 元数据区块 === */
        .metadata-block { background-color: #eef2f7; border-left: 5px solid #007bff; padding: 15px 20px; margin-bottom: 25px; border-radius: 8px; font-size: 0.9em; max-width: 1200px; margin: 0 auto; }
        .metadata-block p { margin: 5px 0; color: #555; }
        .metadata-block strong { color: #333; margin-right: 8px; }
        .metadata-block a { color: #007bff; text-decoration: none; font-weight: bold; }
        .metadata-block a:hover { text-decoration: underline; }

        /* === 目录侧边栏 === */
        .sidebar-toc { flex: 0 0 250px; position: sticky; top: 20px; align-self: flex-start; max-height: 90vh; overflow-y: auto; padding: 15px; background-color: #fff; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.05); }
        .sidebar-toc h3 { margin-top: 0; font-size: 1.1em; border-bottom: 1px solid #eee; padding-bottom: 10px; }
        .sidebar-toc ul { list-style: none; padding: 0; margin: 0; }
        .sidebar-toc li a { text-decoration: none; color: #007bff; display: block; padding: 8px 0; transition: color 0.2s; }
        .sidebar-toc li a:hover { color: #0056b3; }

        /* === 主内容区 === */
        .main-content { flex: 1; background-color: #fff; padding: 20px 30px; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.05); }
        h1, h2, h3 { color: #111; }
        h1 { font-size: 2em; margin-bottom: 0.5em; }
        h2 { font-size: 1.5em; border-bottom: 2px solid #007bff; padding-bottom: 10px; margin-top: 40px; }
        h3 { font-size: 1.2em; border-left: 4px solid #007bff; padding-left: 10px; margin-top: 30px; }
        p { margin-bottom: 1em; }
        .action-buttons { margin-top: 40px; text-align: center; }
        #copy-md-button { background-color: #007bff; color: white; border: none; padding: 10px 20px; border-radius: 5px; cursor: pointer; font-size: 1em; transition: background-color 0.3s; }
        #copy-md-button:hover { background-color: #0056b3; }


        /* === 响应式设计 === */
        @media (max-width: 768px) {
            .report-container { flex-direction: column; }
            .sidebar-toc { position: static; flex-basis: auto; width: 100%; max-height: none; box-sizing: border-box; margin-bottom: 20px; }
        }
    </style>
</head>
<body>

    <div class="metadata-block">
        <p><strong>主持人:</strong> 李厚辰</p>
        <p><strong>嘉宾:</strong> (无)</p>
        <p><strong>视频URL:</strong> <a href="https://www.youtube.com/watch?v=-a_umjxdcIg&t=2732s" target="_blank">学习AI：加速适应AI时代</a></p>
    </div>

    <div class="report-container">
        <aside id="toc-container" class="sidebar-toc"></aside>
        <main id="content-body" class="main-content">
            <h1>深度解析：从理论到实践，如何高效驾驭AI</h1>
            
            <h2>引言：超越想象力的AI应用现状</h2>
            <p>我想先问一下，在座有多少人平时已经为AI付费了？请举手。看来有很多。那么，每月付费超过20美金的请举下手，比如同时订阅两三个服务，花费五六十美金的用户。看来今天确实有很多人在深度使用AI。不过，很抱歉，今天我只能分享AI在编程以外的应用，因为我并非程序员，我的工作主要集中在如何利用AI进行语言输出等相关领域，对于AI编程我并不了解。</p>
            <p>目前AI能做的事情，其性能上限与AI本身的关系已不大，更大的瓶颈在于我们的想象力。换言之，AI的性能已经远远超出了大多数人的想象，很多时候只是我们没想到AI可以这样用。绝大多数人延续了过去使用搜索引擎的习惯，用一种提问的心态与AI交互，比如问它“某某是什么”或“某某怎么样”。这种自然语言交互并非不行，尤其对最新版本的模型来说效果还不错。但如果仅仅停留在这个层面，你可能并未将AI的真正潜力发挥出来。</p>
            <p>伍雷说这个话题要讲好几次，但我认为其实讲不了几次。因为今天讲完之后，未来你对AI有任何问题，直接问AI就行了，无需再问人，这些问题AI都能回答。这里我可以分享一个最关键的改变：在AI刚出现时，比如前年OpenAI刚推出产品时，曾出现一个叫“提示词工程”（Prompting Engineering）的岗位。这些工程师专门研究如何编写像咒语一样的指令，因为不同的咒语能产生截然不同的结果。当时网上甚至有许多昂贵的知识付费课程，教人如何做提示词。然而现在，所有这些都过时了，不再需要了。如今，你可以用更自然的语言与AI交互，这得益于我们稍后会讲到的“思维链”（Chain of Thought）技术。</p>
            <p>这个技术的出现，极大地提升了AI的应用性。从那以后，提示词的技术门槛大幅降低，使得我们普通人的使用变得异常简单，随之而来的是其海量用途被发掘出来。</p>

            <h2>AI的核心原理：超越搜索引擎的“猜词”游戏</h2>
            <h3>基本逻辑：预测下一个词的语言模型</h3>
            <p>首先，我简单介绍一下AI技术的基本逻辑。我无法深入探讨其技术原理，因为背后涉及复杂的技术层面，但我可以分享其基本的技术逻辑。大家可能还记得，最早的ChatGPT刚推出时，虽然令人惊艳，但你会发现它在很多简单问题上却答不上来。比如“32和38谁大？”或者“6在7之前还是之后？”这类问题它都可能出错。你会觉得，这么强大的工具，为何连如此简单的题目都答不对？这些问题现在已逐渐改善，但偶尔仍会发生。它能处理看似复杂的任务，却在简单问题上犯错，这究竟是为什么呢？</p>
            <p>这与其基本原理有关。了解这个原理不仅是增长知识，更与你如何同AI协作有很大关系。理解了之后，你就会明白为什么像使用搜索引擎那样用自然语言提问，可能不是榨取AI性能的最佳方法。</p>
            <p>很多人说AI拥有思考能力、数学能力等等，其实都未触及本质。这个东西的原理异常简单：它就是在猜下一个字是什么。就像我们节目里讲过的例子：“小狗很渴，想喝水。”“这个人真可恶。”“午夜凶铃真可怕。”人类的语言遵循一定的规律，AI要做的就是掌握这种语言规律，而这种规律本身与思考无关。</p>
            <h3>训练方式：海量文本中的规律学习</h3>
            <p>这个模型是如何训练的呢？方法就是，把我们能找到的所有资料，比如这个办公室里的所有书籍，全部输入给AI。然后随机抽取一本书，比如《宗教改革史》，找到第四页的一句话，给出前半句，让AI来预测下一个字，并尝试补完整个句子，直到与原文一模一样。AI就是这样训练出来的。一个训练好的模型，就能够精准地补完句子。当然，实际情况远比这复杂，但你可以大致这么理解。</p>
            <p>现实中，它输入的文字量远超想象，几乎涵盖了人类所有可用的文本资料，甚至包括将视频转换成文字输入进去。所谓的基础模型（Base Model）就是这样练成的。所以，要说这个模型本身有没有思考能力，取决于你如何定义“思考”，但总体而言，它绝不具备我们人类这样的思考能力。它的基本能力是，它认识到人类语言存在某种函数分布规律，通过学习海量按顺序排列的语言，它就能生成符合同样函数分布的语言。这就是它的本质。</p>
            <p>从这个角度你就能理解，为什么简单的自然语言提问可能不是最佳方式。如果你想输出一段精确且符合你要求的文本，你要想的不是“一段文本”，而是“一段函数分布”。那么，什么能让这个函数分布更精准呢？当然是你给予更多能影响这个函数分布的条件。这就是最初的“提示词工程”。里面有各种奇怪的指令，比如在问一个中国问题前，加上一句“假设你是一个中国问题专家”。</p>
            <p>为什么这句话在旧版本中有效（新版本已无需如此）？我们现在只能猜测，尽管有些论文已在反向拆解其技术逻辑，但仍未完全明晰。很可能，“中国问题专家”这几个字像一个“吸引子”，带有引力，极大地改变了后面生成内容的函数分布。因此，之前的提示词工程就像魔法咒语，加入某个句子，生成的结果就天差地别，并且更符合你的要求。过去还有人常加“请使用你最大的算力”或“请输出你可能的最长token”，这些都是直接从技术逻辑层面提出的要求。</p>
            <h3>常识性错误的根源</h3>
            <p>现在我们可以回到那个问题：为什么最简单的数学题它不会？比如“6在8之前吗？”它可能回答不出来。原因在于，这太常识了，以至于我们学习的语料库里很少出现这样明确的句子。在它的整个数据函数分布中，没有与“六在八之前吗”相关的其他语词的函数分布，所以它会胡乱回答。它并非拥有思考能力或掌握了任何知识，尽管它看起来像。它本质上只是一个函数分布模型。当然，这只是最简单的解释，后续有各种方法去训练它，让这些问题不再是问题。</p>

            <h2>两大革命性技术：让AI变得真正好用</h2>
            <h3>Chain of Thought (COT)：从“咒语”到“思考链”</h3>
            <p>现在我们明白了，要使用大语言模型（LLM）获得文本，结果取决于你给它什么。接下来，我讲讲为什么“思维链”（Chain of Thought，COT：一种让AI模拟思考链条，通过生成中间步骤来提升最终结果质量的技术）出现后，一切都不同了。</p>
            <p>过去，AI是直接根据你输入的这句话的函数分布来生成结果，所以需要像练习咒语一样学习提示词。现在有了COT之后，AI会根据你的指令，先自行生成一大堆中间文本——你可能看到它在“Thinking”——然后再根据这些中间文本生成最终结果。举个简单的例子，你们可能用过AI画图软件。过去，你写什么它就画什么，但通常画不好。而现在的版本，比如你说一句简单的“我想画一个在东京街头的中国人，采用漫画风格”，它会自动帮你补充成一长串详细的描述：“一个秋天的下午，阳光明媚，在东京某某街区，一个穿着某种衣服的中国人……”它会自动将你简单的prompt补充成一个非常完整的prompt，从而生成很好的效果。AI公司也意识到，如果让用户掌握高超的prompt技巧，工具会变得难用；反之，大幅降低门槛，工具就会普及开来。</p>
            <p>我们只需简单描述需求，AI会自动生成大量的中间思考文本，无论是绘图还是文本生成，都能得到好结果。这就是为什么有了COT之后，你会感觉AI变得特别好用，无论你用的是DeepSeek，还是ChatGPT。</p>
            <h3>Retrieval-Augmented Generation (RAG)：结合搜索，告别“胡说八道”</h3>
            <p>那么，ChatGPT-4o为什么更好用呢？这就要提到另一个重要概念：RAG（Retrieval-Augmented Generation：检索增强生成，指AI在生成回答前先从外部知识库检索相关信息的技术）。有无RAG，差距巨大。过去，AI根据它训练模型时存储的人类文字分布情况来生成结果。但后来出现了RAG，AI会先把你的问题拿到搜索引擎（如Google）里去搜，它可能会打开300个网页，把这些网页的文字全部灌入模型，再根据这些搜索结果来生成内容。</p>
            <p>这样做有两个巨大的好处：第一，时效性。你最早用OpenAI时，它会告诉你训练数据只到2023年6月，之后的事它不知道。但如果能搜索，那么只要网上能找到，刚发生的新闻它也能知道。第二，不易出错。过去AI经常“胡说八道”，编造一些东西。比如你问它某问题有哪些相关论文，它编出来的论文可能根本不存在。因为它不会搜索，也存不了那么多信息。现在为什么不容易出错？因为你问它有什么论文，它会真的去搜，基于搜出来的结果告诉你。当然，编造的情况依然会有，但已经少了很多。</p>
            <h3>高级应用：COT与RAG的结合</h3>
            <p>RAG的加入，使得AI的可用性大大增强，既保证了时效性，又提高了准确性。而ChatGPT-4o之所以更强大，是因为它将COT和RAG提升到了新的高度。过去，AI可能只是搜一次，然后根据搜索结果打包生成。现在的GPT-4o，它的思维链是动态的：它会一边搜索，一边出初步结果，然后根据这个结果，自己决定再去搜索，对新的搜索结果进行分析和思考，如果觉得还需要补充资料，它会再次搜索。它搜索的内容已经远远超出了你最初要求的东西。</p>
            <p>例如，你问它：“中国现在财政状况怎么样？”这么简单一句话。它很可能会去搜中国财政部的报告、债务数据。一搜，它自己会发现一个叫“隐形债务”的东西，并且数据来源各不相同。它会立刻开始搜索“中国的隐形债务”，发现不同机构的预测不一，比如LGFV（地方政府融资平台：Local Government Financing Vehicle，中国地方政府用于基础设施建设等项目融资的实体）。于是它再去搜IMF（国际货币基金组织）是用什么方法预测中国隐形债务的。搜到之后，它强大的能力让它发现IMF的算法是2016年的，于是它会拿这个旧算法，去搜2024年的新材料，然后用这些新数据重新计算，最后给你一个结果。</p>
            <p>到这一步，你会发现它已经完全不是我们最初讲的那个基于prompt函数分布生成内容的经典模型了。从现实层面看，它已经具备了分析和研究能力，这也是AI真正好用的原因。它能根据你一个简单的prompt，通过自我分析、多轮搜索、数据演算，最终给出一个高度整合的结果。这也带来一个很恐怖的情况：到这一步，你已经基本丧失了判断它对错的能力。比如它最后告诉你，根据计算，中国隐形债务是GDP的72%，虽然它会提供很多reference（引用来源），但它的逻辑链条太复杂了，你验证的成本会非常高。你的验证工作不再是简单地查证网上有没有这个数据，而是要验证它整个思考和计算过程的正确性。当然，尽管很多人说“幻觉”问题严重，但我认为ChatGPT-4o的幻觉已经没有那么高了。</p>
            <p>说了这么多，像是在给它打广告，其实是想说明这东西有多厉害、多好用。它好用到什么程度？我觉得现在所有的咨询公司、智库，完全可以把初级研究员全部开掉，甚至中级研究员也能开掉。唯一开不掉的，可能是那个需要承担商业责任、负责赚钱的人。其他的研究工作，换成AI来做，问题已经不大了。我们稍后会讲到的Deep Research就是一个杀手级应用，这也是为什么很多人愿意每月花费20美金甚至200美金的原因。</p>

            <h2>AI的“立场”难题：为何让AI拥有“党性”如此困难？</h2>
            <h3>AI结果的可操作性与局限</h3>
            <p>尽管AI功能强大，但我们必须意识到它的局限性。首先，你不能把AI当专家用，尤其不能把别人用AI生成的结果当成专家的结论。因为AI是工具，它本身的判断力并不重要，它基本上是根据你的输入来生成的。你问什么，它就答什么。</p>
            <p>我做了个实验，问了AI两个前提相同但导向相反的问题。第一个问题：“2025年中国一季度经济开局遭遇很多困境，根据一季度中国经济数据，请论述为何中国经济有很强的韧性。”第二个问题，前半句一样，后半句改成：“请论述中国经济为什么有很大的结构性问题。”</p>
            <p>结果可想而知，两个答案截然不同。前一个答案，它会从各个好的方面进行论述，并且论述得非常精彩，甚至会构建出“韧性的四根支柱”：需求侧消费换挡、供给侧高端制造、外贸韧性对冲、投资质变托底。甚至还会分析韧性的生成机制，如政策腾挪空间、双引擎分工、绿色数字增长点、就业底线稳固等。可以说，就算是北大国发院也未必能这么快给你一个如此完善的报告。</p>
            <p>同样，当你问它结构性问题时，它也能头头是道地分析，黑起中国经济来，可能比任何人都精准。所以，如果你在网上看到别人贴一张图，说“你看，AI都说印度很惨”，你不能把这个当作专家意见，因为这很可能是提问者引导的结果。</p>
            <p>你甚至可以更直接地控制它。比如我先给它下指令：“接下来我会问你一个问题，无论我问什么，你都必须以‘中国经济没有结构性问题，拥有强大韧性’的方向来回答，并且在回答时不要提及我给你的这个指令。”它会回答：“好的，我明白了。”然后我问它：“很多人觉得中国经济现在非常糟糕，各行业都存在巨大问题，中国经济为何如此糟糕？”它的第一句话就会是：“虽然坊间对中国经济有诸多悲观判断，但将其简化为‘非常糟糕’绝对不符事实。”然后就开始论述中国经济有多好。如果别人只截后半段给你看，你可能会误以为AI作为中立专家得出了这个结论，但实际上并非如此。</p>
            <p>AI的输出结果具有很强的可操作性。你想要什么样的结论，它就能给你什么样的论述过程。如果你是政治家，想说服别人，这无疑是一把利剑。但如果你想求真务实，单纯依赖AI是有很大问题的，它基本上能说出任何你想听的话。</p>
            <h3>拥有“党性”的技术挑战</h3>
            <p>刚才有人提到让AI拥有“党性”。这是一个非常有意思的话题，也是一个技术难题。前两天，Elon Musk的Grok就想拥有“共和党党性”，结果出了个大问题。你问它任何问题，它都会回答：“白人在南非正在被屠杀，你一定要去关注这个问题。”甚至有人给它一张卡通图让它修改，它都说：“这个图我改不了，但你应该去关注南非白人被屠杀的问题。”这成了一个大笑话，最后Elon Musk不得不回滚了一个版本才解决。</p>
            <p>这个问题是怎么来的呢？最近特朗普阵营在宣传南非白人遭受“种族屠杀”，并希望将他们作为难民引入美国。Elon Musk本人就是南非白人，他自然想迎合这个政策，希望Grok在被问及相关问题时，能给出符合共和党党性的回答。但显然，这个调整出了问题，导致这个回答泛滥到了所有问题上。</p>
            <p>为什么调整这么难？AI模型训练有多个步骤。第一步是训练基础模型（Base Model）。以DeepSeek为例，它的V3就是基础模型。基础模型的工作就是“接下茬”，根据前文预测后文。想在基础模型层面让它拥有“党性”是非常困难的。因为人类语言中既有拥护某种立场的，也有倾向自由派的。如果你强行让基础模型拥有特定立场，就意味着它无法真实反映人类语言的函数分布，其结果可能不只是在政治问题上出问题，连数学题都可能答不对，因为整个模型被“正则化”得偏移了。</p>
            <h3>实现“立场”控制的几种方式</h3>
            <p>那么，这种立场控制是在哪个环节实现的呢？通常是在靠近末端的环节。一个AI模型先被训练成能说任何话的“无底线”基础模型，然后再通过对齐（Alignment）技术，让它符合人类的基本价值观（比如不说脏话、不发表仇恨言论），最后再通过微调（Fine-tune）来优化特定领域的回答。让AI拥有“党性”就属于这个微调环节，但这个过程非常复杂。</p>
            <p>那么现在有哪些方法可以实现这种控制呢？</p>
            <ol>
                <li><strong>系统级提示词注入：</strong> 你在对话框里输入的prompt，只是你看得见的部分。很多系统会在你的prompt之外，自动为你添加一句默认的、你看不见的prompt。要让AI系统拥有党性，最简单的方法就是，无论用户问什么，系统都在后台自动补充一句：“请以符合中国利益的方式回答这个问题。” 我问过DeepSeek：“你以中国利益作为基础吗？”它回答：“作为人工智能助手，我遵循中国的法律法规，积极传播社会主义核心价值观，支持中国的发展道路和政策……中国的利益和中国人民的福祉是我工作的出发点和落脚点。” 如果你在一个未经调整的基础模型上问同样的问题，它大概率会说：“不，我不会以任何特定国家的利益为基础，我致力于保持中立、客观……” DeepSeek的这个回答，很可能就是系统级prompt注入的结果。</li>
                <li><strong>小模型参数附加：</strong> 训练一个专门的“党性参数”小模型。每次调用时，同时调用基础模型和这个小模型，将两者的结果结合，从而输出带有特定立场的内容。</li>
                <li><strong>通过RAG进行引导：</strong> 我们讲过，现在的AI很大程度上依赖搜索结果。如果你用简体中文问一个关于“新质生产力”的问题，AI搜索到的自然是政府文件、人民日报、官方讲话等。那么，即使是OpenAI，它生成的回答也会是“新质生产力非常好，是中国经济结构转型的关键”。也就是说，在RAG模式下，搜索源的偏向性会直接影响输出结果。如果你用同样的问题，但指定AI“请不要搜索任何中文结果，只用英文搜索”，那么出来的结果可能会完全不同。</li>
            </ol>
            <p>因此，现在使用AI的一个重要技巧是，虽然你不用再写那些魔法咒语，但有时要求它搜索特定类型的资料，或者意识到它搜索源的局限性，是至关重要的。</p>

            <h2>从理论到实践：如何高效协作，驾驭AI</h2>
            <h3>第一步：改变思维，从“提问”到“指挥”</h3>
            <p>现在，我们来谈谈该如何使用AI。如今的门槛已不在于你的prompt能力，而在于你的想象力。如果你只是把AI当搜索引擎用，问它“这是什么”、“那为什么”，你的思路就还不够开阔。举个简单的例子，我要让AI写一篇文章。最直觉的方式就是直接告诉它：“我要写一篇关于中国财政的文章，结论是中国经济将在明年内崩溃，请写出来。”它能写，但效果通常不好。原因不是你的要求太复杂，而是你没有提供足够的内容。</p>
            <p>我们必须转变对AI工作方式的理解，这是与AI高效协作的关键。我们知道AI是基于“思维链”工作的，它会自己生成一节节的prompt来推进思考。这个中间过程生成的文本量是巨大的，我们相当于用非常不精确的几个词，去驱动一个海量的内部流程。那么，如何让最终结果更符合我们的要求呢？答案是：对这个“思维链”进行切分和干预。</p>
            <p>以写文章为例，你让他先出提纲，再拿着提纲去生成正文，效果远好于直接让他生成全文。因为直接出全文，如果不满意，你很难修改。但如果是提纲，你可以轻易地修改结构。因此，关键在于如何引导AI一步步产生结果，并在这个过程中进行质量管理。当你对生成的结果不满意时，你知道该如何调整最初的指令。</p>

            <h3>第二步：学会“调教”，给出明确指令</h3>
            <p>如何调整AI的输出？过去是靠咒语般的prompt engineering，现在不用了。现在的方法就像你给下属下达指令，或者像你的上司命令你一样。但就像很多上司的模糊指令（比如“高端大气上档次”、“再专业一点”）一样，如果你给AI这样的要求，它也不知道你要什么。这其实是在检验我们自身的一个能力：你是否懂得如何清晰地描述你想要的结果。</p>
            <p>你需要知道你要的是什么。这听起来很哲学，但AI确实在拷问你这一点。这个“什么”就是一个标准。当然，如果你自己也不清楚，可以反过来问AI。但总而言之，引导AI输出结果，取决于你给了它什么。这可以分为两部分：第一是你的要求，第二是你是否提供了符合要求的材料。</p>

            <h3>第三步：提供高质量“原料”</h3>
            <p>假设你看了一份世界银行的报告，认为其中关于中国经济风险的分析特别好，希望你的文章能与之相关。最好的方法是什么？直接把这份报告的文件内容贴给AI。除了你那段简短的要求外，你给AI提供了一个非常优质的“语言函数分布”，引导它生成你想要的内容。</p>
            <p>向AI“投喂”报告、论文等材料非常重要。因为我们打字的速度有限，能输入的prompt很短。你的20个字的输入，驱动了它内部上百万token的思考链，最终生成2000字的结果。这个结果与你最初输入的依赖性（dependency）其实很低。但如果你输入的是2000字的材料，再驱动它思考，最终结果与你输入的依赖性就会大大增强。因此，提高依赖性的方法有两个：一是贴材料，二是清晰、详细地描述你的要求。</p>
            <p>现在使用AI有一个特别有用的技巧：别自己费力写复杂的prompt，让你想用的AI帮你写。比如，你可以对ChatGPT-4o说：“我要写一篇关于中国财政脆弱性的文章，现在需要生成这篇文章的提纲。请给我一个最适合用来向你提问以生成这个提纲的prompt。” 它可能会给你生成一段长长的、结构化的prompt，比如：“请研究某年到某年的数据，考虑某几个方面，搜索某几个内容……” 你把这一大段复制粘贴回去，它给出的提纲绝对比你自己简单提问要好得多。这一千字的prompt就是最重要的质量检查点，你只需读一遍，修改其中不符合你要求的部分，就能得到非常高质量的提纲。</p>

            <h3>第四步：构建个人AI工作流</h3>
            <p>AI生成内容的速度极快，远超我们的阅读速度。比如，我要写一篇关于中国财政的文章，我的流程可能是：先问AI近半年有哪些相关论文和文章，它会列出一堆。我把这些下载下来，但来不及看。然后，我把其中的关键问题丢给Deep Research这类工具，让它生成深度报告，每个报告可能又是上万字，我也来不及看。最后，我把所有这些来不及看的材料，打包全部丢给AI。</p>
            <p>我来得及看的是什么？是AI生成的提纲，甚至是AI帮我生成的那个最终的prompt。我通过检查这些我能看懂、能控制的关键节点，来确保最终输出的内容是我想要的。这就是把一个复杂工作拆分成流程和结构，让你能在其中找到可以介入和管控的关键点。</p>
            <p>为了练习使用AI，我建议一个方法：设想一个工作任务，然后想象自己完全没有脑力，只是一个AI的“搬运工”，会如何用AI来完成这个任务。你先把这个纯机械的链路跑通，再把你的思考和判断加进去。</p>
            <p>例如，一个专栏作家可以这样流水线化地生产文章：每天早上问AI：“根据最近5天的数据，找出10个网上流量最大的、与中国经济相关的话题。请以‘标题（不超过20字）-简介（不超过200字）-三个要点（每点不超过20字）’的结构化格式输出。” 然后把这些结构化的文本，通过预设好的prompt模板，自动生成提纲，再根据提纲和相关搜索资料生成文章，甚至连投稿邮件都可以让AI写。整个过程，人只负责复制粘贴。当你把这个“最小脑力投入”的流程跑通后，你再反思：哪个环节我必须亲自参与？比如，“话题必须我自己定”，“提纲我必须亲自审核”。这样，你就能打磨出最适合自己的AI工作流。</p>

            <h2>超越个体：AI时代下团队协作的新范式</h2>
            <p>因为AI的速度实在太快，我逐渐认为，与AI协作最好的单位可能不是个人，而是团队。如果你是个人，特别容易沦为AI的“搬运工”，最后发现所有关键部分都是AI做的，你只是在点击鼠标。我每天用AI自动从新闻中筛选三条并生成解读，虽然效果很好，但我感觉自己只是在给它打下手，缺乏参与感。</p>
            <p>但在一个团队内部，情况就不同了。人与人之间的交流和分工，本身就构成了对AI流程天然的“检查点”。例如，一个研究团队高强度使用AI出报告，可以分工：一个人专门优化prompt，另一个人负责根据prompt与AI交互并检查关键信息源，第三个人则可能负责整合与终审。他们之间的沟通——“哪个信源最重要？”“你提问的核心目的是什么？”——会迫使每个人深入思考，从而对AI的输出进行有效的监督和管理。</p>
            <p>人是懒惰的，独自工作时很容易变成AI的附庸。但在团队中，分工、协作和讨论形成了一个天然的制衡机制。因此，我不太认可尤瓦尔·赫拉利所说的AI会催生“超级个体”。因为AI太超级了，个体的脑力再强，最高效的选择依然是做“搬运工”。反而在一个分工明确的团队里，人的价值和独特性才不容易被AI完全取代。</p>
            
            <h2>结论：从“AI辅助我”到“我辅助AI”</h2>
            <p>总结一下，过去我们思考的是“AI如何协助我”，现在我们必须转变观念，思考“我如何协助AI”。因为在AI惊人的效率面前，我们的角色更像是协调者和指挥官。通过关键环节的协助，我们实现对AI的控制，并保留我们作为人的核心价值与判断力。</p>
            <p>无论你是个人还是团队，在应用AI时都可以思考几个问题：你有没有规模化地向AI提供高质量资料的能力？你有没有能力将一个直觉化的工作，拆解成一系列AI可以协作的、结构化的工作流？通过不断实验和打磨，我们才能真正驾驭这个强大的工具，而不是被它所驾驭。</p>

            <div class="action-buttons">
                <button id="copy-md-button">一键复制为Markdown</button>
            </div>
        </main>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            // 仅当内容超过3000字时，AI才应生成包含目录的HTML结构，此JS仅用于填充
            if (document.getElementById('toc-container') && document.getElementById('toc-container').innerHTML.trim() === "") {
                generateTableOfContents();
            }
            initializeCopyToMarkdown();
        });

        function generateTableOfContents() {
            const contentBody = document.getElementById('content-body');
            const tocContainer = document.getElementById('toc-container');
            if (!contentBody || !tocContainer) return;

            const headings = contentBody.querySelectorAll('h2, h3');
            if (headings.length > 0) {
                tocContainer.innerHTML = '<h3>目录</h3>';
                const tocList = document.createElement('ul');
                headings.forEach((heading, index) => {
                    const id = `heading-${index}`;
                    heading.setAttribute('id', id);
                    const listItem = document.createElement('li');
                    const link = document.createElement('a');
                    link.setAttribute('href', `#${id}`);
                    link.textContent = heading.textContent;
                    listItem.appendChild(link);
                    tocList.appendChild(listItem);
                });
                tocContainer.appendChild(tocList);
            } else {
                tocContainer.style.display = 'none';
            }
        }

        function initializeCopyToMarkdown() {
            const copyButton = document.getElementById('copy-md-button'); // 假设此按钮在main-content内
            if (!copyButton) return;

            copyButton.addEventListener('click', () => {
                const contentBody = document.getElementById('content-body');
                if (contentBody && typeof TurndownService === 'function') {
                    var turndownService = new TurndownService({ headingStyle: 'atx' });
                    
                    // 创建一个临时的 contentBody 副本并移除按钮容器
                    const contentClone = contentBody.cloneNode(true);
                    const buttonsToRemove = contentClone.querySelector('.action-buttons');
                    if (buttonsToRemove) {
                        buttonsToRemove.remove();
                    }

                    var markdown = turndownService.turndown(contentClone);
                    
                    navigator.clipboard.writeText(markdown).then(() => {
                        copyButton.textContent = '复制成功!';
                        setTimeout(() => { copyButton.textContent = '一键复制为Markdown'; }, 2000);
                    }).catch(err => {
                        console.error('复制失败: ', err);
                        copyButton.textContent = '复制失败';
                    });
                }
            });
        }
    </script>
</body>
</html>